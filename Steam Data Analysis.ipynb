{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53039898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "096b3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawGames = pd.read_csv('SteamAppsInfo.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e97ed1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appId</th>\n",
       "      <th>name</th>\n",
       "      <th>developerName</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>price</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>positiveReviewPercentage</th>\n",
       "      <th>appGenre</th>\n",
       "      <th>tagsList</th>\n",
       "      <th>appType</th>\n",
       "      <th>dlcBool</th>\n",
       "      <th>appDesc</th>\n",
       "      <th>alteredTextBool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1688200</td>\n",
       "      <td>War Of Gold</td>\n",
       "      <td>Tero Lunkka,Valkeala Software</td>\n",
       "      <td>Aug 22, 2021</td>\n",
       "      <td>0.59</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66%</td>\n",
       "      <td>['Action', 'Casual', 'Indie']</td>\n",
       "      <td>['Casual', 'Action', '3D Fighter', 'Shooter', ...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>You super hero soldier need save robber gold b...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1688210</td>\n",
       "      <td>Utopia</td>\n",
       "      <td>Iconic Ideaz</td>\n",
       "      <td>Jan 7, 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'Adventure', 'Massively Multiplayer...</td>\n",
       "      <td>['Early Access', 'RPG', 'Survival', 'Colorful'...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>UTOPIA is an open world survival game set in a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1688220</td>\n",
       "      <td>Fire &amp; Reign</td>\n",
       "      <td>Siphon Shock</td>\n",
       "      <td>Jun 2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'Indie']</td>\n",
       "      <td>['Bullet Hell', 'Action', \"Shoot 'Em Up\", 'Sho...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Upgrade your warriors and shoot through waves ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1688240</td>\n",
       "      <td>Escape from the Office</td>\n",
       "      <td>ParachuteGames, ImperiumGame</td>\n",
       "      <td>Jul 26, 2021</td>\n",
       "      <td>2.99</td>\n",
       "      <td>12.0</td>\n",
       "      <td>91%</td>\n",
       "      <td>['Action', 'Indie']</td>\n",
       "      <td>['Action', 'Precision Platformer', 'Perma Deat...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Escape from the Office is a 2D side-scrolling ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1688250</td>\n",
       "      <td>PRINCESS IN AIRINESS</td>\n",
       "      <td>Broken Desk</td>\n",
       "      <td>Jul 26, 2021</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'Indie']</td>\n",
       "      <td>['Action', 'Point &amp; Click', '2D Platformer', '...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>To pray for peace, the princess once again fli...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113005</th>\n",
       "      <td>1972180</td>\n",
       "      <td>Dub Club</td>\n",
       "      <td>Cyberfunk Studios LLC</td>\n",
       "      <td>May 20, 2022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Casual', 'Free to Play']</td>\n",
       "      <td>['Casual', 'Rhythm', 'Exploration', 'Third Per...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>A third person multiplayer virtual music venue...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113006</th>\n",
       "      <td>1595760</td>\n",
       "      <td>ScreenSpace</td>\n",
       "      <td>Wave Project</td>\n",
       "      <td>Apr 23, 2021</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Casual', 'Indie']</td>\n",
       "      <td>['Casual', 'Clicker', 'Arcade', 'Point &amp; Click...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Test your focus and reflexes in this simplisti...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113007</th>\n",
       "      <td>1996680</td>\n",
       "      <td>Fowl Scourge</td>\n",
       "      <td>Void Cup Games</td>\n",
       "      <td>When its done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'Indie', 'RPG']</td>\n",
       "      <td>[]</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>In this Dark Fantasy Action-RPG you are part o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113008</th>\n",
       "      <td>1972250</td>\n",
       "      <td>Project: Maidenless</td>\n",
       "      <td>Grossly Incandescent Games</td>\n",
       "      <td>TBA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'Adventure', 'Indie', 'Massively Mu...</td>\n",
       "      <td>['Early Access', 'Action', 'Adventure', 'RPG',...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Scavenge for loot in an unforgiving world fill...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113009</th>\n",
       "      <td>457260</td>\n",
       "      <td>Omen of Sorrow</td>\n",
       "      <td>AOne Games</td>\n",
       "      <td>coming soon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action']</td>\n",
       "      <td>['PvP', '2D Fighter', '3D Fighter', 'Action', ...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Omen of Sorrow brings monsters of horror, lite...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113010 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          appId                    name                  developerName  \\\n",
       "0       1688200             War Of Gold  Tero Lunkka,Valkeala Software   \n",
       "1       1688210                  Utopia                   Iconic Ideaz   \n",
       "2       1688220            Fire & Reign                   Siphon Shock   \n",
       "3       1688240  Escape from the Office   ParachuteGames, ImperiumGame   \n",
       "4       1688250    PRINCESS IN AIRINESS                    Broken Desk   \n",
       "...         ...                     ...                            ...   \n",
       "113005  1972180                Dub Club          Cyberfunk Studios LLC   \n",
       "113006  1595760             ScreenSpace                   Wave Project   \n",
       "113007  1996680            Fowl Scourge                 Void Cup Games   \n",
       "113008  1972250     Project: Maidenless     Grossly Incandescent Games   \n",
       "113009   457260          Omen of Sorrow                     AOne Games   \n",
       "\n",
       "           releaseDate  price  numReviews positiveReviewPercentage  \\\n",
       "0         Aug 22, 2021   0.59        15.0                      66%   \n",
       "1          Jan 7, 2022    NaN         NaN                      NaN   \n",
       "2             Jun 2022    NaN         NaN                      NaN   \n",
       "3         Jul 26, 2021   2.99        12.0                      91%   \n",
       "4         Jul 26, 2021   3.99         2.0                      NaN   \n",
       "...                ...    ...         ...                      ...   \n",
       "113005    May 20, 2022   0.00         NaN                      NaN   \n",
       "113006    Apr 23, 2021   1.99         1.0                      NaN   \n",
       "113007  When its done    NaN         NaN                      NaN   \n",
       "113008             TBA    NaN         NaN                      NaN   \n",
       "113009     coming soon    NaN         NaN                      NaN   \n",
       "\n",
       "                                                 appGenre  \\\n",
       "0                           ['Action', 'Casual', 'Indie']   \n",
       "1       ['Action', 'Adventure', 'Massively Multiplayer...   \n",
       "2                                     ['Action', 'Indie']   \n",
       "3                                     ['Action', 'Indie']   \n",
       "4                                     ['Action', 'Indie']   \n",
       "...                                                   ...   \n",
       "113005                         ['Casual', 'Free to Play']   \n",
       "113006                                ['Casual', 'Indie']   \n",
       "113007                         ['Action', 'Indie', 'RPG']   \n",
       "113008  ['Action', 'Adventure', 'Indie', 'Massively Mu...   \n",
       "113009                                         ['Action']   \n",
       "\n",
       "                                                 tagsList    appType  dlcBool  \\\n",
       "0       ['Casual', 'Action', '3D Fighter', 'Shooter', ...  All Games    False   \n",
       "1       ['Early Access', 'RPG', 'Survival', 'Colorful'...  All Games    False   \n",
       "2       ['Bullet Hell', 'Action', \"Shoot 'Em Up\", 'Sho...  All Games    False   \n",
       "3       ['Action', 'Precision Platformer', 'Perma Deat...  All Games    False   \n",
       "4       ['Action', 'Point & Click', '2D Platformer', '...  All Games    False   \n",
       "...                                                   ...        ...      ...   \n",
       "113005  ['Casual', 'Rhythm', 'Exploration', 'Third Per...  All Games    False   \n",
       "113006  ['Casual', 'Clicker', 'Arcade', 'Point & Click...  All Games    False   \n",
       "113007                                                 []  All Games    False   \n",
       "113008  ['Early Access', 'Action', 'Adventure', 'RPG',...  All Games    False   \n",
       "113009  ['PvP', '2D Fighter', '3D Fighter', 'Action', ...  All Games    False   \n",
       "\n",
       "                                                  appDesc  alteredTextBool  \n",
       "0       You super hero soldier need save robber gold b...            False  \n",
       "1       UTOPIA is an open world survival game set in a...            False  \n",
       "2       Upgrade your warriors and shoot through waves ...            False  \n",
       "3       Escape from the Office is a 2D side-scrolling ...            False  \n",
       "4       To pray for peace, the princess once again fli...            False  \n",
       "...                                                   ...              ...  \n",
       "113005  A third person multiplayer virtual music venue...            False  \n",
       "113006  Test your focus and reflexes in this simplisti...            False  \n",
       "113007  In this Dark Fantasy Action-RPG you are part o...            False  \n",
       "113008  Scavenge for loot in an unforgiving world fill...            False  \n",
       "113009  Omen of Sorrow brings monsters of horror, lite...            False  \n",
       "\n",
       "[113010 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawGames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82ebc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113010"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawGames['appId'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef566a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee43bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to try and get the dates.\n",
    "#\n",
    "#Note that this script eliminates dates which don't fit certain date formats.\n",
    "#\n",
    "#For example, it converts \"Coming Soon\" to NaN.\n",
    "def datesCleaned(dataframe):\n",
    "    \n",
    "    datesCleaned = [];\n",
    "    \n",
    "    #Convert to dt format\n",
    "    for i in dataframe['releaseDate']:\n",
    "        try:\n",
    "            datesCleaned.append(dt.strptime(i, '%b %d, %Y'))\n",
    "        except:\n",
    "            try:\n",
    "                datesCleaned.append(dt.strptime(i, '%b, %Y'))\n",
    "                \n",
    "            except:\n",
    "                try: datesCleaned.append(dt.strptime(i, '%b %Y'))\n",
    "                    \n",
    "                except:\n",
    "                    datesCleaned.append(np.nan)\n",
    "            \n",
    "    datesCleanedSeries = pd.Series(datesCleaned)\n",
    "    \n",
    "    datesCleanedSeries.index = dataframe.index\n",
    "    \n",
    "    return datesCleanedSeries\n",
    "\n",
    "datesCleaned = datesCleaned(rawGames)\n",
    "\n",
    "#Replece release dates with cleaned dates\n",
    "rawGames['releaseDate'] = datesCleaned\n",
    "        \n",
    "# #Add cleaned release dates to dataframes\n",
    "# ncrpgs_df['releaseDate'] = rpgDatesCleaned[ncrpgs_df.index]\n",
    "# crpgs_df['releaseDate'] = rpgDatesCleaned[crpgs_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c518c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Casual', 'Action', '3D Fighter', 'Shooter', 'Runner', 'Real Time Tactics', 'Hero Shooter', '3D', 'Military', 'Stealth', 'Flight', 'Survival', 'Story Rich', 'Combat', 'Singleplayer', 'Third-Person Shooter', 'Vehicular Combat', 'Indie', 'First-Person', 'Character Customization']\n"
     ]
    }
   ],
   "source": [
    "#Clean all the game tags\n",
    "def tagsCleaned(games):\n",
    "    \n",
    "    tagsCleaned = []\n",
    "    \n",
    "    for k in games.index:\n",
    "        \n",
    "        #Get rid of \\' \\s \\em etc.\n",
    "        tagsRemovedSlashes = re.findall(r\"'(.*?)'[,\\]]\",games.tagsList[k]\\\n",
    "                                        .replace(\"\\'s\",\"s\").replace(\"\\'em\",\"em\")\\\n",
    "                                        .replace(\"\\'Em\",\"Em\").replace(\"\\'\",\"''\"))\n",
    "        \n",
    "        tagsCleaned.append([tagsRemovedSlashes[j].replace(\"'\",\"\") for j in range(len(tagsRemovedSlashes))])\n",
    "        \n",
    "    tagsCleanedSeries = pd.Series(tagsCleaned)\n",
    "    \n",
    "    tagsCleanedSeries.index = games.index\n",
    "        \n",
    "    return tagsCleanedSeries\n",
    "\n",
    "rawGames['tagsList'] = tagsCleaned(rawGames)\n",
    "\n",
    "print(rawGames['tagsList'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8c2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phyis\\AppData\\Local\\Temp\\ipykernel_33964\\183280176.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  rpgs = rawGames[[('RPG' in rawGames.tagsList[i]) or ('CRPG' in rawGames.tagsList[i])\n"
     ]
    }
   ],
   "source": [
    "#Find all non-DLC RPGs and CRPGs\n",
    "rpgs = rawGames[[('RPG' in rawGames.tagsList[i]) or ('CRPG' in rawGames.tagsList[i])\n",
    "                 for i in range(len(rawGames))]][rawGames['dlcBool'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c7da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagBool(games,tagNames):\n",
    "    \n",
    "    #Check for a tag name in every game in dataframe\n",
    "    tagBoolSeries = pd.Series([any([tagName in games['tagsList'][j] for tagName in tagNames]) for j in games.index])\n",
    "    \n",
    "    tagBoolSeries.index = games.index\n",
    "    return tagBoolSeries\n",
    "\n",
    "#Get list of Booleans corresponding to whether the game is a CRPG\n",
    "crpgBool = tagBool(rpgs, ['CRPG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d747aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All CRPGs\n",
    "crpgs_df = rpgs.copy()[crpgBool.tolist()]\n",
    "\n",
    "#All non-CRPG RPGs (nCRPGs)\n",
    "ncrpgs_df = rpgs.copy()[np.logical_not(crpgBool.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ac2cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cac91cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appId</th>\n",
       "      <th>name</th>\n",
       "      <th>developerName</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>price</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>positiveReviewPercentage</th>\n",
       "      <th>appGenre</th>\n",
       "      <th>tagsList</th>\n",
       "      <th>appType</th>\n",
       "      <th>dlcBool</th>\n",
       "      <th>appDesc</th>\n",
       "      <th>alteredTextBool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1688210</td>\n",
       "      <td>Utopia</td>\n",
       "      <td>Iconic Ideaz</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'Adventure', 'Massively Multiplayer...</td>\n",
       "      <td>[Early Access, RPG, Survival, Colorful, Base B...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>UTOPIA is an open world survival game set in a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1688320</td>\n",
       "      <td>OneBit Adventure</td>\n",
       "      <td>Galactic Slice, LLC</td>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Adventure', 'Casual', 'Free to Play', 'Indie...</td>\n",
       "      <td>[Roguelite, Roguelike, Class-Based, Dungeon Cr...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>OneBit Adventure is a casual turn-based roguel...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1688600</td>\n",
       "      <td>Emperial Knights</td>\n",
       "      <td>Yacine Kalache</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>9.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'RPG', 'Early Access']</td>\n",
       "      <td>[Action, RPG, Action RPG, Hack and Slash, 3D, ...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>You incarnate as a powerful knight to help the...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1688630</td>\n",
       "      <td>Emperial Knights</td>\n",
       "      <td>Yacine Kalache</td>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>9.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Action', 'RPG', 'Early Access']</td>\n",
       "      <td>[Action, RPG, Action RPG, Hack and Slash, 3D, ...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>You incarnate as a powerful knight to help the...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1688640</td>\n",
       "      <td>Cleanup on Isle Goblin</td>\n",
       "      <td>Kilowatt Games</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Adventure', 'Indie', 'RPG', 'Simulation']</td>\n",
       "      <td>[Life Sim, RPG, Pixel Graphics, Adventure, Cra...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Isle Goblin has been invaded by destructive hu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      appId                    name        developerName releaseDate  price  \\\n",
       "1   1688210                  Utopia         Iconic Ideaz  2022-01-07    NaN   \n",
       "8   1688320        OneBit Adventure  Galactic Slice, LLC  2022-08-05   0.00   \n",
       "26  1688600        Emperial Knights       Yacine Kalache  2022-04-20   9.99   \n",
       "27  1688630        Emperial Knights       Yacine Kalache  2022-04-20   9.99   \n",
       "28  1688640  Cleanup on Isle Goblin       Kilowatt Games         NaT    NaN   \n",
       "\n",
       "    numReviews positiveReviewPercentage  \\\n",
       "1          NaN                      NaN   \n",
       "8          NaN                      NaN   \n",
       "26         NaN                      NaN   \n",
       "27         NaN                      NaN   \n",
       "28         NaN                      NaN   \n",
       "\n",
       "                                             appGenre  \\\n",
       "1   ['Action', 'Adventure', 'Massively Multiplayer...   \n",
       "8   ['Adventure', 'Casual', 'Free to Play', 'Indie...   \n",
       "26                  ['Action', 'RPG', 'Early Access']   \n",
       "27                  ['Action', 'RPG', 'Early Access']   \n",
       "28        ['Adventure', 'Indie', 'RPG', 'Simulation']   \n",
       "\n",
       "                                             tagsList    appType  dlcBool  \\\n",
       "1   [Early Access, RPG, Survival, Colorful, Base B...  All Games    False   \n",
       "8   [Roguelite, Roguelike, Class-Based, Dungeon Cr...  All Games    False   \n",
       "26  [Action, RPG, Action RPG, Hack and Slash, 3D, ...  All Games    False   \n",
       "27  [Action, RPG, Action RPG, Hack and Slash, 3D, ...  All Games    False   \n",
       "28  [Life Sim, RPG, Pixel Graphics, Adventure, Cra...  All Games    False   \n",
       "\n",
       "                                              appDesc  alteredTextBool  \n",
       "1   UTOPIA is an open world survival game set in a...            False  \n",
       "8   OneBit Adventure is a casual turn-based roguel...            False  \n",
       "26  You incarnate as a powerful knight to help the...            False  \n",
       "27  You incarnate as a powerful knight to help the...            False  \n",
       "28  Isle Goblin has been invaded by destructive hu...            False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncrpgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ecb52a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appId</th>\n",
       "      <th>name</th>\n",
       "      <th>developerName</th>\n",
       "      <th>releaseDate</th>\n",
       "      <th>price</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>positiveReviewPercentage</th>\n",
       "      <th>appGenre</th>\n",
       "      <th>tagsList</th>\n",
       "      <th>appType</th>\n",
       "      <th>dlcBool</th>\n",
       "      <th>appDesc</th>\n",
       "      <th>alteredTextBool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1686130</td>\n",
       "      <td>Deep Despair 2</td>\n",
       "      <td>BekkerDev Studio</td>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>6.99</td>\n",
       "      <td>67.0</td>\n",
       "      <td>88%</td>\n",
       "      <td>['Adventure', 'Indie', 'RPG', 'Simulation']</td>\n",
       "      <td>[Sandbox, Crafting, Adventure, Survival, Simul...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Deep Despair 2 is an open world survival adven...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1684240</td>\n",
       "      <td>Metal Faith</td>\n",
       "      <td>Youth Game</td>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>9.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Adventure', 'Indie', 'RPG']</td>\n",
       "      <td>[Adventure, RPG, Action-Adventure, Shooter, Pu...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>A 3D adventure puzzle game</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1684250</td>\n",
       "      <td>The Evil Farming Game: Replanted</td>\n",
       "      <td>Jeremy Does Stupid Stuff</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Adventure', 'Free to Play', 'Indie', 'RPG']</td>\n",
       "      <td>[RPG, Psychological Horror, Horror, Multiple E...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>What will you do when you, an ordinary farmer,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1684310</td>\n",
       "      <td>The Evil Farming Game: Replanted</td>\n",
       "      <td>Jeremy Does Stupid Stuff</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Adventure', 'Free to Play', 'Indie', 'RPG']</td>\n",
       "      <td>[RPG, Psychological Horror, Horror, Multiple E...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>What will you do when you, an ordinary farmer,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1683870</td>\n",
       "      <td>Crystalreach Islands</td>\n",
       "      <td>Majao Games</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['RPG']</td>\n",
       "      <td>[RPG, Fantasy, Action RPG, Open World, Sandbox...</td>\n",
       "      <td>All Games</td>\n",
       "      <td>False</td>\n",
       "      <td>Crystalreach Islands is an open-world action R...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       appId                              name             developerName  \\\n",
       "218  1686130                    Deep Despair 2          BekkerDev Studio   \n",
       "458  1684240                       Metal Faith                Youth Game   \n",
       "459  1684250  The Evil Farming Game: Replanted  Jeremy Does Stupid Stuff   \n",
       "464  1684310  The Evil Farming Game: Replanted  Jeremy Does Stupid Stuff   \n",
       "479  1683870              Crystalreach Islands               Majao Games   \n",
       "\n",
       "    releaseDate  price  numReviews positiveReviewPercentage  \\\n",
       "218  2021-10-08   6.99        67.0                      88%   \n",
       "458  2021-08-02   9.99         NaN                      NaN   \n",
       "459         NaT   0.00         NaN                      NaN   \n",
       "464         NaT   0.00         NaN                      NaN   \n",
       "479         NaT    NaN         NaN                      NaN   \n",
       "\n",
       "                                          appGenre  \\\n",
       "218    ['Adventure', 'Indie', 'RPG', 'Simulation']   \n",
       "458                  ['Adventure', 'Indie', 'RPG']   \n",
       "459  ['Adventure', 'Free to Play', 'Indie', 'RPG']   \n",
       "464  ['Adventure', 'Free to Play', 'Indie', 'RPG']   \n",
       "479                                        ['RPG']   \n",
       "\n",
       "                                              tagsList    appType  dlcBool  \\\n",
       "218  [Sandbox, Crafting, Adventure, Survival, Simul...  All Games    False   \n",
       "458  [Adventure, RPG, Action-Adventure, Shooter, Pu...  All Games    False   \n",
       "459  [RPG, Psychological Horror, Horror, Multiple E...  All Games    False   \n",
       "464  [RPG, Psychological Horror, Horror, Multiple E...  All Games    False   \n",
       "479  [RPG, Fantasy, Action RPG, Open World, Sandbox...  All Games    False   \n",
       "\n",
       "                                               appDesc  alteredTextBool  \n",
       "218  Deep Despair 2 is an open world survival adven...            False  \n",
       "458                         A 3D adventure puzzle game            False  \n",
       "459  What will you do when you, an ordinary farmer,...            False  \n",
       "464  What will you do when you, an ordinary farmer,...            False  \n",
       "479  Crystalreach Islands is an open-world action R...            False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crpgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec193f30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e82a659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         [Early Access, RPG, Survival, Colorful, Base B...\n",
       "8         [Roguelite, Roguelike, Class-Based, Dungeon Cr...\n",
       "26        [Action, RPG, Action RPG, Hack and Slash, 3D, ...\n",
       "27        [Action, RPG, Action RPG, Hack and Slash, 3D, ...\n",
       "28        [Life Sim, RPG, Pixel Graphics, Adventure, Cra...\n",
       "                                ...                        \n",
       "112994    [Casual, Adventure, RPG, JRPG, Turn-Based Tact...\n",
       "112995    [RPG, Action RPG, 2D Platformer, Pixel Graphic...\n",
       "113003    [Strategy, Grand Strategy, Turn-Based Strategy...\n",
       "113004    [Action, RPG, 2D Fighter, 3D Fighter, JRPG, 3D...\n",
       "113008    [Early Access, Action, Adventure, RPG, Action ...\n",
       "Name: tagsList, Length: 15689, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rpgs.tagsList.replace(\"\\'s\",\"s\").replace(\"\\'em\",\"em\").replace(\"\\'Em\",\"Em\").replace(\"\\'\",\"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4720f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpgDates = datesCleaned[rpgs.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "f5504bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of games over the years\n",
    "def gameGrowth(games,start_date):\n",
    "    end_date = dt.now().year\n",
    "\n",
    "    dates = range(start_date,end_date+1)\n",
    "\n",
    "    gamesCount=[]\n",
    "    for date in dates:\n",
    "        #How many games were released before \"date\"?\n",
    "        gamesCount.append(len(games[[games['releaseDate'][i].year < date for i in games.index]].index))\n",
    "        \n",
    "    return gamesCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68d73d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b', 'a', 'c'}\n"
     ]
    }
   ],
   "source": [
    "array = [['a','b'], ['a', 'b','c'], ['a']]\n",
    "result = {x for l in array for x in l}\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a4514e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get game developer location data\n",
    "gameDevLocations = pd.read_csv('GameDevLocations.csv',skip_blank_lines=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d73e413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>state/province</th>\n",
       "      <th>country</th>\n",
       "      <th>alteredTextBool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0verflow</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Simple Game</td>\n",
       "      <td>Zapopan</td>\n",
       "      <td>Jalisco</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100 Stones Interactive</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1047 Games</td>\n",
       "      <td>Zephyr Cove</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10tons</td>\n",
       "      <td>Tampere</td>\n",
       "      <td>Tavastia</td>\n",
       "      <td>Finland</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  company         city state/province        country  \\\n",
       "1                0verflow        Tokyo          Tokyo          Japan   \n",
       "3           1 Simple Game      Zapopan        Jalisco         Mexico   \n",
       "5  100 Stones Interactive     Brisbane     Queensland      Australia   \n",
       "7              1047 Games  Zephyr Cove         Nevada  United States   \n",
       "9                  10tons      Tampere       Tavastia        Finland   \n",
       "\n",
       "  alteredTextBool  \n",
       "1           False  \n",
       "3           False  \n",
       "5           False  \n",
       "7           False  \n",
       "9           False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameDevLocations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "2390301e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all', 'nothing']"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intersection(list1, list2):\n",
    "    list3 = [value for value in list1 if value in list2]\n",
    "    return list3\n",
    "\n",
    "intersection(['all','or','nothing'],['all','nothing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8af58e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split location names into lists of strings to compare between datasets\n",
    "\n",
    "import re\n",
    "\n",
    "def locationSplitter(string):\n",
    "    strings = re.split(r',| |-', string)\n",
    "\n",
    "    unwantedStrings = ['', 'And', 'The', 'Games', 'Studios', 'Studio', 'Game', 'Games',\\\n",
    "                           'and', 'the', 'games', 'studios', 'studio', 'game', 'games']\n",
    "    \n",
    "    newStrings = [i for i in strings if i not in unwantedStrings]\n",
    "    \n",
    "    return newStrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ad809b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get lists of split game developer name strings from each dataset\n",
    "\n",
    "steamGameDevLocationsSplit = [];\n",
    "gameDevLocationsSplit = []\n",
    "\n",
    "for string in rawGames.developerName.tolist():\n",
    "    \n",
    "    try:\n",
    "        steamGameDevLocationsSplit.append(locationSplitter(string))\n",
    "        \n",
    "    except TypeError:\n",
    "        steamGameDevLocationsSplit.append(np.nan)\n",
    "        pass\n",
    "    \n",
    "for string in gameDevLocations.company.tolist():\n",
    "    \n",
    "    try:\n",
    "        gameDevLocationsSplit.append(locationSplitter(string))\n",
    "        \n",
    "    except TypeError:\n",
    "        gameDevLocationsSplit.append(np.nan)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6fdcfc5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                     1\n",
       "company            0verflow\n",
       "city                  Tokyo\n",
       "state/province        Tokyo\n",
       "country               Japan\n",
       "alteredTextBool       False\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameDevLocations.reset_index().loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a380a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty lists to fill with info about game developer locations\n",
    "gameDevNamesList = [];\n",
    "gameDevCityList = [];\n",
    "gameDevStateProvinceList = [];\n",
    "gameDevCountryList = [];\n",
    "\n",
    "for steamDevNameWords in steamGameDevLocationsSplit:\n",
    "    \n",
    "    loop = 0\n",
    "    \n",
    "    for gameDevNameWords in gameDevLocationsSplit:\n",
    "        \n",
    "        try:\n",
    "            if len(intersection(steamDevNameWords, gameDevNameWords))/len(steamDevNameWords) >= 0.75:\n",
    "\n",
    "                locationIndex = gameDevLocationsSplit.index(gameDevNameWords)\n",
    "\n",
    "                gameDev = gameDevLocations.reset_index().loc[locationIndex]\n",
    "\n",
    "                gameDevNamesList.append(gameDev[1])\n",
    "                gameDevCityList.append(gameDev[2])\n",
    "                gameDevStateProvinceList.append(gameDev[3])\n",
    "                gameDevCountryList.append(gameDev[4])\n",
    "\n",
    "                pass\n",
    "            \n",
    "        except (ZeroDivisionError, TypeError):\n",
    "            pass\n",
    "        \n",
    "        loop += 1\n",
    "        \n",
    "    if loop == len(gameDevLocationsSplit):\n",
    "        gameDevNamesList.append(np.nan)\n",
    "        gameDevCityList.append(np.nan)\n",
    "        gameDevStateProvinceList.append(np.nan)\n",
    "        gameDevCountryList.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dcae9b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854498574701519"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameDevStateProvinceList.count(np.nan)/len(gameDevStateProvinceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "89ffb034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19569"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameDevStateProvinceList.count(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf8a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add developer location to rawGames\n",
    "# gameDevCityList = [];\n",
    "# gameDevStateProvinceList = [];\n",
    "# gameDevCountryList = [];\n",
    "# for i in range(len(rawGames)):\n",
    "#     if rawGames.loc[i].developerName in gameDevLocations.company.tolist():\n",
    "        \n",
    "#         gameDev = gameDevLocations[gameDevLocations.company == rawGames.loc[i].developerName]\n",
    "        \n",
    "#         gameDevCityList.append([gameDev.loc[j][1] for j in gameDev.index])\n",
    "#         gameDevStateProvinceList.append([gameDev.loc[j][2] for j in gameDev.index])\n",
    "#         gameDevCountryList.append([gameDev.loc[j][3] for j in gameDev.index])\n",
    "        \n",
    "#     else:\n",
    "#         gameDevCityList.append([np.nan])\n",
    "#         gameDevStateProvinceList.append([np.nan])\n",
    "#         gameDevCountryList.append([np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "253b2df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9243695248208124"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameDevCountryList.count([np.nan])/len(gameDevCountryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c14302c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43280"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rawGames.developerName.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "79e31b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29808/2068584871.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lon\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "address = 'St. Catherines, Ontario, Canada'\n",
    "url = 'https://nominatim.openstreetmap.org/search/' + urllib.parse.quote(address) +'?format=json'\n",
    "\n",
    "response = requests.get(url).json()\n",
    "print(response[0][\"lat\"])\n",
    "print(response[0][\"lon\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "10ec1690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132579"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gameDevCountryList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8ebf5c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4503d9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates data already exists.\n"
     ]
    }
   ],
   "source": [
    "#Check if we already have a csv file containing game dev lat/long coordinates\n",
    "if exists('coordinates.csv'):\n",
    "    gamesTimeSeries = pd.read_csv('coordinates.csv')\n",
    "    print('Coordinates data already exists.')\n",
    "\n",
    "#If not, get the coordinates by querying nominatim.openstreetmap.org with the city/state/country of the game devs\n",
    "else:    \n",
    "    latitudes = [];\n",
    "    longitudes = [];\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    for i in range(len(gameDevCountryList)):\n",
    "        \n",
    "        #Print progress every 1000 iterations\n",
    "        if i%1000 == 0:\n",
    "            print('{} iterations completed in {} seconds.'.format(i,time.time() - startTime))\n",
    "\n",
    "        address = ''\n",
    "        \n",
    "        #Try to add the country, state/province, and city names to the query string\n",
    "        if str(gameDevCountryList[i]) != 'nan':\n",
    "            address = gameDevCountryList[i]\n",
    "\n",
    "        if str(gameDevStateProvinceList[i]) != 'nan':\n",
    "            address = gameDevStateProvinceList[i] + ', ' + address\n",
    "\n",
    "        if str(gameDevCityList[i]) != 'nan':\n",
    "            address += gameDevCityList[i] + ', ' + address\n",
    "        \n",
    "        #If we don't have any location information, append NaN to the lists\n",
    "        if address == '':\n",
    "            latitudes.append(np.nan)\n",
    "            longitudes.append(np.nan)\n",
    "        \n",
    "        #Otherwise, ask for the coordinates and append them to the lists\n",
    "        else:\n",
    "            address = '{}, {}, {}'.format(gameDevCityList[i],gameDevStateProvinceList[i],gameDevCountryList[i])\n",
    "            url = 'https://nominatim.openstreetmap.org/search/' + urllib.parse.quote(address) +'?format=json'\n",
    "\n",
    "            response = requests.get(url).json()\n",
    "\n",
    "            try:\n",
    "                latitudes.append(response[0][\"lat\"])\n",
    "                longitudes.append(response[0][\"lon\"])\n",
    "\n",
    "            except IndexError:\n",
    "                latitudes.append(np.nan)\n",
    "                longitudes.append(np.nan)\n",
    "    \n",
    "    #Cache this information so we don't need to run this twice!\n",
    "    csvFile = open('coordinates.csv', 'w+')\n",
    "\n",
    "    writer = csv.writer(csvFile, lineterminator = '\\n')\n",
    "\n",
    "    writer.writerow(['Latitudes','Longitudes'])\n",
    "    \n",
    "    for latitude,longitude in zip(latitudes,longitudes):\n",
    "        writer.writerow([latitude,longitude])\n",
    "\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b060b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = open('latitudes.csv', 'w+')\n",
    "\n",
    "writer = csv.writer(csvFile, lineterminator = '\\n')\n",
    "\n",
    "for latitude in latitudes:\n",
    "    writer.writerow([latitude])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3db518d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = [np.nan]+pd.read_csv('latitudes.csv')['nan'].tolist()\n",
    "longitudes = [np.nan]+pd.read_csv('longitudes.csv')['nan'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f83f8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = open('coordinates.csv', 'w+')\n",
    "\n",
    "writer = csv.writer(csvFile, lineterminator = '\\n')\n",
    "\n",
    "writer.writerow(['Latitudes','Longitudes'])\n",
    "\n",
    "for latitude,longitude in zip(latitudes,longitudes):\n",
    "    writer.writerow([latitude,longitude])\n",
    "\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d1ebd59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitudes</th>\n",
       "      <th>Longitudes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Latitudes  Longitudes\n",
       "0        NaN         NaN\n",
       "1        NaN         NaN\n",
       "2        NaN         NaN\n",
       "3        NaN         NaN\n",
       "4        NaN         NaN"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates = pd.read_csv('coordinates.csv')\n",
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4e581224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "worldmap = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "df = pd.read_csv('coordinates.csv')\n",
    "\n",
    "#Creating axes and plotting world map\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "worldmap.plot(color=\"lightgrey\", ax=ax)\n",
    "\n",
    "#Plot game dev locations\n",
    "Longitudes = df['Longitudes']\n",
    "Latitudes = df['Latitudes']\n",
    "plt.scatter(x, y, alpha=0.4, vmin=0, cmap='autumn')\n",
    "\n",
    "#Creating axis limits\n",
    "plt.xlim([-180, 180])\n",
    "plt.ylim([-90, 90])\n",
    "\n",
    "\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e371f",
   "metadata": {},
   "source": [
    "We now have a map of the game developers in the Steam games dataset whose locations we could find in the gameDevMap dataset. Now I want to combine this data with the original Steam games dataset and create visualizations of how the production of different game genres is distributed within countries around the world.\n",
    "\n",
    "We can see from this plot that game production is heavily concentrated in the USA and Europe, so it would be somewhat uninteresting to plot the distribution, of say, RPG production, since it is likely to follow a similar distribution. What would be perhaps more interesting is to investigate what makes each country's game industry unique. To that end, I will create a map of countries which shows what genre is produced in that country more than any other genre when compared to the distribution across genres for all countries. In other words, I will label each country with the game genre in which that country \"punches above its weight\" to the greatest degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "3a6e83db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>state/province</th>\n",
       "      <th>country</th>\n",
       "      <th>alteredTextBool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0verflow</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Simple Game</td>\n",
       "      <td>Zapopan</td>\n",
       "      <td>Jalisco</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100 Stones Interactive</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1047 Games</td>\n",
       "      <td>Zephyr Cove</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10tons</td>\n",
       "      <td>Tampere</td>\n",
       "      <td>Tavastia</td>\n",
       "      <td>Finland</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8153</th>\n",
       "      <td>Zwift</td>\n",
       "      <td>Long Beach</td>\n",
       "      <td>California</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>Zwift</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>Zynga Eugene</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>Zynga New York</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>Zynga With Friends</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>Texas</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4079 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company            city  state/province        country  \\\n",
       "1                   0verflow           Tokyo           Tokyo          Japan   \n",
       "3              1 Simple Game         Zapopan         Jalisco         Mexico   \n",
       "5     100 Stones Interactive        Brisbane      Queensland      Australia   \n",
       "7                 1047 Games     Zephyr Cove          Nevada  United States   \n",
       "9                     10tons         Tampere        Tavastia        Finland   \n",
       "...                      ...             ...             ...            ...   \n",
       "8153                   Zwift      Long Beach      California  United States   \n",
       "8155                   Zwift  Rio de Janeiro  Rio de Janeiro         Brazil   \n",
       "8157            Zynga Eugene          Eugene          Oregon  United States   \n",
       "8159          Zynga New York   New York City        New York  United States   \n",
       "8161      Zynga With Friends        McKinney           Texas  United States   \n",
       "\n",
       "     alteredTextBool  \n",
       "1              False  \n",
       "3              False  \n",
       "5              False  \n",
       "7              False  \n",
       "9              False  \n",
       "...              ...  \n",
       "8153           False  \n",
       "8155           False  \n",
       "8157           False  \n",
       "8159           False  \n",
       "8161           False  \n",
       "\n",
       "[4079 rows x 5 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameDevLocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8509580",
   "metadata": {},
   "source": [
    "# Plotting proportions of game genres\n",
    "I am now going to make a little function that can generate plots of proportions of games of certain genres over time. This will provide an interesting visualization of how the Steam market for games has varied over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c79018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SteamGamesTimeSeries already exists.\n",
      "0.015651702880859375\n"
     ]
    }
   ],
   "source": [
    "#Find number of games with each tag in every year since oldest game on Steam\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "startDate = min(rawGames['releaseDate']).year\n",
    "endDate = dt.now().year\n",
    "\n",
    "#All unique tag names\n",
    "uniqueTagNames = pd.Series([j for i in range(len(rawGames.tagsList)) for j in rawGames.tagsList[i]]).unique()\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "#Check if we have already created a .csv file of time series for all the game tags\n",
    "if exists('SteamGamesTimeSeries.csv'):\n",
    "    gamesTimeSeries = pd.read_csv('SteamGamesTimeSeries.csv')\n",
    "    print('SteamGamesTimeSeries already exists.')\n",
    "\n",
    "#If not, generate the time series for all game tags\n",
    "else:\n",
    "    timeSeriesCSV = open('SteamGamesTimeSeries.csv','w+')\n",
    "    writer = csv.writer(timeSeriesCSV)\n",
    "    writer.writerow(tuple(['tagName']+[i for i in range(startDate,endDate+1)]))\n",
    "    \n",
    "    for tag in uniqueTagNames:\n",
    "        dates = range(startDate,endDate+1)\n",
    "\n",
    "        gamesCount=[]\n",
    "        for date in dates:\n",
    "            #How many games with this tag were released before \"date\"?\n",
    "            \n",
    "            tagGames = rawGames[tagBool(rawGames,[tag])]\n",
    "\n",
    "            gamesCount.append(len(tagGames[[tagGames['releaseDate'][i].year < date for i in tagGames.index]].index))\n",
    "            \n",
    "        writer.writerow(tuple([tag] + gamesCount))\n",
    "        \n",
    "    timeSeriesCSV.close()\n",
    "    \n",
    "print(time.time() - startTime)\n",
    "            \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7c3272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allGamesCount = gameGrowth(rawGames,min(ncrpgs_df['releaseDate']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e382b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncrpgCount = gameGrowth(ncrpgs_df,min(ncrpgs_df['releaseDate']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85cb8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crpgCount = gameGrowth(crpgs_df,min(ncrpgs_df['releaseDate']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c64855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagTS = pd.read_csv('SteamGamesTimeSeries.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "id": "3fcb571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 53)"
      ]
     },
     "execution_count": 1162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagTS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "467aa5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot number of games with certain tags over time\n",
    "def tagNumberPlot(tagNameList):\n",
    "    plt.figure()\n",
    "\n",
    "    #Define time range: oldest game on steam to current year\n",
    "    startDate = min(rawGames['releaseDate']).year\n",
    "    endDate = dt.now().year\n",
    "    \n",
    "    dates = range(startDate,endDate+1)\n",
    "    \n",
    "    #Plot all tag time series\n",
    "    for tag in tagNameList:\n",
    "        plt.plot(dates, tagTS.loc[tag].values, label=tag)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Number games')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b73a3825",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalGamesCount = gameGrowth(rawGames,min(rawGames['releaseDate']).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "id": "47c0e26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2021-08-22\n",
       "1        2022-01-07\n",
       "2        2022-06-01\n",
       "3        2021-07-26\n",
       "4        2021-07-26\n",
       "            ...    \n",
       "113005   2022-05-20\n",
       "113006   2021-04-23\n",
       "113007          NaT\n",
       "113008          NaT\n",
       "113009          NaT\n",
       "Name: releaseDate, Length: 113010, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawGames['releaseDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "c314480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot proportion of games with certain tags over time\n",
    "def tagProportionPlot(tagNameList,startDate=1970,endDate=2022):\n",
    "    plt.figure()\n",
    "\n",
    "    #Define time range: oldest game on steam to current year\n",
    "    #\n",
    "    #startDate = min(rawGames['releaseDate']).year\n",
    "    #endDate = dt.now().year\n",
    "    \n",
    "    dates = range(startDate,endDate)\n",
    "    \n",
    "    #Plot all tag time series\n",
    "    for tag in tagNameList:\n",
    "        plt.plot(dates, [tagTS.loc[tag].values[i]/totalGamesCount[i] for i in np.arange(startDate-1970,endDate-1970)], label=tag)\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Proportion of games')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "7cefa111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagProportionPlot(['RPG','CRPG'],startDate=1985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "a18ec83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ffde745550>"
      ]
     },
     "execution_count": 1060,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot change in proportion of RPGs over time\n",
    "plt.figure()\n",
    "\n",
    "dates = range(min(ncrpgs_df['releaseDate']).year,dt.now().year)\n",
    "\n",
    "plt.plot([dates[i] for i in range(len(dates)) if allGamesCount[i]>0], [ncrpgCount[i]/allGamesCount[i] for i in range(len(dates)) if allGamesCount[i]>0],label='non-CRPGs')\n",
    "plt.plot([dates[i] for i in range(len(dates)) if allGamesCount[i]>0], [crpgCount[i]/allGamesCount[i] for i in range(len(dates)) if allGamesCount[i]>0],label='CRPGs')\n",
    "# plt.plot(dates, crpgCount)\n",
    "\n",
    "plt.title('RPG proportions over time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Fraction of all contemporary games')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64682cf8",
   "metadata": {},
   "source": [
    "# Review Data and Game Recommender (Explicit Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50662d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get reviews data\n",
    "reviews = pd.read_json('SteamReviewsData.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0220e",
   "metadata": {},
   "source": [
    "Per the discussion at https://github.com/lyst/lightfm/issues/204, when you have positive and negative interactions and are trying to fit a LightFM model, it is useful to encode the data differently depending on the loss function. For 'logistic' loss, positive and negative interactions should be encoded as 1 and -1 respectively; for other loss functions, the encoding should be 1 and 0. Since my data has positive and negative reviews, I will generate two different data matrices for these two cases before fitting any models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "960821d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'recommendationid': '98147510',\n",
       "  'author': {'steamid': '76561198974872127',\n",
       "   'num_games_owned': 39,\n",
       "   'num_reviews': 19,\n",
       "   'playtime_forever': 237,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 237,\n",
       "   'last_played': 1629809168},\n",
       "  'language': 'english',\n",
       "  'review': \"The game is good, but I did not like it because of the strange networking. The controls are terrible, the graphics are good. The optimization is terrible. The engine is disgusting. \\nSo it's not worth spending your money on something like this…\",\n",
       "  'timestamp_created': 1629809492,\n",
       "  'timestamp_updated': 1629809492,\n",
       "  'voted_up': False,\n",
       "  'votes_up': 12,\n",
       "  'votes_funny': 1,\n",
       "  'weighted_vote_score': '0.623708605766296387',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '101029172',\n",
       "  'author': {'steamid': '76561198022964310',\n",
       "   'num_games_owned': 1783,\n",
       "   'num_reviews': 67,\n",
       "   'playtime_forever': 161,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 51,\n",
       "   'last_played': 1636802994},\n",
       "  'language': 'english',\n",
       "  'review': 'worst Tero Lunkka game yet.\\n\\nGame is so close to unplayable.\\n\\n- lags hard\\n- mouse skips around due to lag\\n- Gold looks like a pile of wood.\\n- Weapons stop shooting\\n- without weapon you are done and should restart\\n- enjoy walking 30 minutes if you die but won\\'t restart\\n- Tank can\\'t kill Soldiers\\n- Vehicles can\\'t kill enemies by driving them over (they literally will block your Vehicle)\\n- try to fly Planes without being instantly shot down by Missile spam\\n- game hangs itself when you drop out of the map\\n- Vehicle bug out and drive in a straight line, you can\\'t do anything other than shooting --> you have to restart.\\n- Music is awful, same 2 second on a loop\\n- Inventory seems pretty useless\\n- useless Crafting menu\\n- I had several \"fatal errors\" without any information \\n- You spawn right infront of several enemies, yea good luck with that\\n- no idea how to change weapons from your Bag to your active ones (doesn\\'t seem to work)\\n- you will die randomly\\n\\n\\n\\n+ well you can chose between different vision (night, thermal etc)\\n+ stock weapons look good\\n+ can be uninstalled\\n\\n\\n\\n\\nOverall I thinks its a bit scammy to put such a game up especially with all the other games Tero Lunkka had made. \\nBigfryTV would not approve.\\n83% gave a positive Review, sounds not fishy at all.',\n",
       "  'timestamp_created': 1634200489,\n",
       "  'timestamp_updated': 1634203064,\n",
       "  'voted_up': False,\n",
       "  'votes_up': 4,\n",
       "  'votes_funny': 0,\n",
       "  'weighted_vote_score': '0.581649601459503174',\n",
       "  'comment_count': 2,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False,\n",
       "  'timestamp_dev_responded': 1634223630,\n",
       "  'developer_response': 'thanks for feedback. Game might lack if not too good specs. i have 16gm ram and rtx 3060. One map has lags. weapons stop shooting if no ammos. after death level will restart 100% sure. Yes tanks have bugs they can drive over soldiers, but I can shoot soldiers with tanks and soldiers die, maybe you not shoot correctly . Yes car and tanks have that bug that cant drive over soldier\\n\\nIt is rather easy to drive plane without dying. \\n-cant say why you have fatal errors, no others reported it, might because computer specs\\n- In my opinion it is one of my best/biggest games just my opinion'},\n",
       " {'recommendationid': '98102692',\n",
       "  'author': {'steamid': '76561198148613379',\n",
       "   'num_games_owned': 275,\n",
       "   'num_reviews': 71,\n",
       "   'playtime_forever': 2733,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 392,\n",
       "   'last_played': 1629876062},\n",
       "  'language': 'english',\n",
       "  'review': \"a very interesting game, a shooter in which you can have a lot of fun.  The game has a lot of weapons and equipment .. it's a pity that the movements and many things are not drawn at the highest level ...  And it was very pleasant to spend the time)\",\n",
       "  'timestamp_created': 1629737165,\n",
       "  'timestamp_updated': 1629737165,\n",
       "  'voted_up': True,\n",
       "  'votes_up': 0,\n",
       "  'votes_funny': 0,\n",
       "  'weighted_vote_score': '0.476190477609634399',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '98089029',\n",
       "  'author': {'steamid': '76561198138503881',\n",
       "   'num_games_owned': 277,\n",
       "   'num_reviews': 13,\n",
       "   'playtime_forever': 71,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 60,\n",
       "   'last_played': 1629719365},\n",
       "  'language': 'english',\n",
       "  'review': \"Opponents are very stupid lol. Graphics are 3/5.\\nNo storyline. Just a bro.\\nBut if the opponents weren't stupid enough to stand still when I attack, I'd give War Of Gold a positive rating\",\n",
       "  'timestamp_created': 1629719426,\n",
       "  'timestamp_updated': 1629719426,\n",
       "  'voted_up': True,\n",
       "  'votes_up': 2,\n",
       "  'votes_funny': 5,\n",
       "  'weighted_vote_score': '0.470177948474884033',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '98209545',\n",
       "  'author': {'steamid': '76561198862088568',\n",
       "   'num_games_owned': 42,\n",
       "   'num_reviews': 21,\n",
       "   'playtime_forever': 138,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 109,\n",
       "   'last_played': 1629901171},\n",
       "  'language': 'english',\n",
       "  'review': 'An excellent game that I quickly got used to.  I thought it would take me a long time to get used to the mechanics of the game, but after half an hour I already felt confident',\n",
       "  'timestamp_created': 1629899874,\n",
       "  'timestamp_updated': 1629899874,\n",
       "  'voted_up': True,\n",
       "  'votes_up': 0,\n",
       "  'votes_funny': 0,\n",
       "  'weighted_vote_score': '0.467980295419692993',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '98140286',\n",
       "  'author': {'steamid': '76561199133967346',\n",
       "   'num_games_owned': 1147,\n",
       "   'num_reviews': 62,\n",
       "   'playtime_forever': 448,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 448,\n",
       "   'last_played': 1629672931},\n",
       "  'language': 'english',\n",
       "  'review': \"I encountered some flaws in the game, but they were not too rough and it did not stop me from spending a few hours in it. I don't recommend buying it for full price but I got it at a 40% discount ;)\",\n",
       "  'timestamp_created': 1629798700,\n",
       "  'timestamp_updated': 1629798700,\n",
       "  'voted_up': True,\n",
       "  'votes_up': 0,\n",
       "  'votes_funny': 0,\n",
       "  'weighted_vote_score': '0.464480876922607422',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '98049185',\n",
       "  'author': {'steamid': '76561198111968405',\n",
       "   'num_games_owned': 2254,\n",
       "   'num_reviews': 203,\n",
       "   'playtime_forever': 8,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 8,\n",
       "   'last_played': 1629654058},\n",
       "  'language': 'english',\n",
       "  'review': 'The models and animations are amazing, but on some maps lack of foliage can really kill the  ambient of the game.\\nIn short notes it can give you pretty good fps time for cheap price.',\n",
       "  'timestamp_created': 1629654295,\n",
       "  'timestamp_updated': 1629654295,\n",
       "  'voted_up': True,\n",
       "  'votes_up': 3,\n",
       "  'votes_funny': 1,\n",
       "  'weighted_vote_score': '0.434559494256973267',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '98091332',\n",
       "  'author': {'steamid': '76561198313702233',\n",
       "   'num_games_owned': 139,\n",
       "   'num_reviews': 44,\n",
       "   'playtime_forever': 114,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 114,\n",
       "   'last_played': 1629678395},\n",
       "  'language': 'english',\n",
       "  'review': 'realistic war simulator, convenient control, realistic recoil of weapons and good graphics, good handling of equipment, for my small price I got a good product, I recommend buying it',\n",
       "  'timestamp_created': 1629722732,\n",
       "  'timestamp_updated': 1629722732,\n",
       "  'voted_up': True,\n",
       "  'votes_up': 0,\n",
       "  'votes_funny': 1,\n",
       "  'weighted_vote_score': '0.378285109996795654',\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False},\n",
       " {'recommendationid': '101242562',\n",
       "  'author': {'steamid': '76561198078304402',\n",
       "   'num_games_owned': 110,\n",
       "   'num_reviews': 7,\n",
       "   'playtime_forever': 202,\n",
       "   'playtime_last_two_weeks': 0,\n",
       "   'playtime_at_review': 167,\n",
       "   'last_played': 1637632099},\n",
       "  'language': 'english',\n",
       "  'review': 'Against my better judgement, I have completed each level in this game and have acquired the gold in each individual level. This is my assessment of this game:\\n\\n1.5/10\\n\\nStory:\\nWhile there is a story displayed here in the description of the game, there is no story given in game. There are level selections from the main menu that you chose to play. Each level you play as an unnamed soldier that runs and guns through the level to collect a pile of gold. Each level has their own map, but no contiguous story attached.\\n\\nGameplay:\\nAs said before, you play as a soldier that runs through the level, shoots the bad guys, and collects a pile of gold. The gameplay can be best compared to ARMA 3, but stripped bare to its most basic elements - third/first person firefighting, an inventory system, and infrared/night vision modes.\\nThe inventory system gives you a whopping 6 inventory slots. You will only use it to stache ammo and grenades, as there is no reason to carry weapons with you. Each throwable can be stacked, ammo can be stacked. There is no way to pick up ammo from enemies. The only way to retrieve ammo is by looting it from random tables with preset items strewn across it in a very not so pretty fashion. There is a slot for a backpack, but in my experience playing, there is no way to either loot or craft a backpack.\\nSpeaking of crafting, there is an entire crafting system I assume is not implemented that I found by accident by pressing the M key. As far as I found, there are no items to pick up off of the ground or from enemies, so I could not craft any items during gameplay.\\nYou have 3 meters at the top left of your screen:\\n- Stamina\\n- Unknown meter A\\n- Unknown meter B\\nStamina regenerates extremely slowly. Unknown meter B seemingly drains over time. I\\'m unsure what Unknown meter A does.\\nYou are a bullet sponge, and you\\'ll never know how much health you have left. The screen will go fuzzy, and then you will flop over and die when you absorb enough damage. There is no indicator other than the fuzzy screen that will tell you that you are low on health.\\nYou can blow up tanks with land mines, when they decide to work. Otherwise, you can blow them up with grenades. Otherwise, you can blow them up with other tanks after the game RNG rolls to decide that you hit them.\\nSpeaking of tanks, you can use vehicles in this game.\\n- The Fighter Jet:\\nWill explode on contact with anything, and is useless except for transportation. You will NOT be able to combat anyone in the plane. You will fly it at top speed and then promptly receive constant incoming damage from unavoidable missiles and a constant barrage of machine gunning from behind until you either explode or eject from the plane. Upon ejecting, you\\'ll free fall like a piece of paper until you either hit the ground or press F to open your parachute. There is no warning, you must KNOW the button to open the parachute. Good luck.\\n- The Tank:\\nMoves at the equivalent of walking speed. The reload speed for shells is painfully slow. The tank shells can only blow up vehicles, and will not kill enemy soldiers unless they explode from a nearby vehicle. The machine gun will decimate soldiers, but you\\'ll never figure out it\\'s the Spacebar key until you visit the training level. It will never explode with you in it, because it has a ton of health and nothing will threaten you inside of it, as other tanks only barely dent your health.\\n- The Car:\\nYou will move at the speed of the jet, and you will not be able to brake unless you use the handbrake which you\\'ll never know is the Spacebar key until you visit the training level. If you do not use the handbrake, you will slip and slide as though you were driving on ice. Due to the awful physics in the game, you will go flying in the car if you hit anything sloped, and also flip around if you hit a wall or an enemy. Yes, that\\'s correct. You cannot run over enemies. They are solid as stone if you attempt to drive over them. It\\'s awful when they break your momentum. You also cannot fix your car when it\\'s lifted off the ground or flipped upside down. It is stuck forever then.\\n\\nThe guns that are available in the game is as follows:\\n- Machine gun\\n- Machine gun, but more ammo?\\n- Pistol (Desert Eagle quality)\\n- Sniper\\n\\nYou\\'ll always kill an enemy instantly if you headshot them. The sniper will kill on body shot.\\nThere is a First Person Mode, if you press the Z key. It is completely unnecessary, and you won\\'t use it. If you do, and if you even attempt to scope in to shoot, you won\\'t be able to see where you\\'re shooting after the first shot, as the recoil on the gun throws your reticle all over the place.\\nIn 3rd person mode, the reticle does not accurately show where your bullets fly.\\nIf you die, you will respawn at the beginning of the level, and the level will not respawn vehicles or enemies killed. Some levels require vehicles, so you will end up restarting the level anyways, and restarting the level anyways will respawn enemies and NOT enemy vehicles. Huge oversight.\\nThere is no way to heal in this game. You will \"heal\" over time, but I can\\'t tell if you really do or not, because if the screen gets fuzzy, it\\'ll unfuzz, but then immediately fuzz up again when an enemy shoots me.\\nEnemies have hawkeye accuracy, and they will NOT miss. Enemy tanks have the worst accuracy and sometimes do not shoot downwards, until they decide they have master accuracy and will hit you with every bullet killing you instantly.\\nThere are no markers for where to go. You will be walking around for a while just trying to figure out where the heck you\\'re supposed to be going. Sometimes it\\'s possible to just drop out of a plane directly atop of the gold and win instantly. Either it\\'s extremely hard to win or extremely easy, no in betweens.\\n\\n\\nGraphics:\\nThe graphics in the game are stock, and I have no doubt about it. The mountains clip into themselves, and some just aren\\'t even on the ground, and you can walk underneath them. All duplicated assets appear identical to each other. Water will simply stop existing where the developer decided they didn\\'t want to put water anymore. Some levels will have identical assets to other levels, and some levels will have flat expanses of land that will simply cease existing. The quality of the textures are not so great. There were many levels I got stuck in and had to restart the mission.\\nAnimations are janky as all hell. When you kill an enemy, their head will spin around constantly as they\\'re on the floor. When you die, if you were pressing a direction, your camera will stop and you\\'ll see your body flip around all over the place and roll about on the floor. Ragdoll physics gone wrong.\\nBroken vehicles are simply vehicles with a black texture over them to \"look burnt\". It looks awful.\\nSometimes, my grenades simply do not explode, resulting in them just disappearing.\\nThe win screen is a static image basically saying, \"You got the gold, you win!\" and then back to menu. No fanfare, just an achievement.\\nIn each level, your only hint on what to do is a text box asset telling you loosely where to go in broken English.\\nThe main menu is garbage and bare minimum, the level select screen bugs out the Credits option, the Credits option does not work and only shows Valkeala Software and then stops working.\\nAnimations on your character look extremely funny.\\n\\n\\nMusic/Sound design:\\nRepetitive and boring. There is more than one track in the game, but the track loops constantly and drones on. It is not cool or enticing. One time, my music didn\\'t even load, so the level was played in ultimate silence.\\nThe sound of the machine gun is awful and it will be the only sound you hear in the game besides your own gun, since all enemies use the machine gun.\\nThere are pretty much no other sounds or music in the game.\\n\\n\\nThis game is clearly a scam and thrown together to appear better than it is. Please do not purchase it. It is not even worth $0.59.',\n",
       "  'timestamp_created': 1634553588,\n",
       "  'timestamp_updated': 1634553588,\n",
       "  'voted_up': False,\n",
       "  'votes_up': 0,\n",
       "  'votes_funny': 0,\n",
       "  'weighted_vote_score': 0,\n",
       "  'comment_count': 0,\n",
       "  'steam_purchase': True,\n",
       "  'received_for_free': False,\n",
       "  'written_during_early_access': False}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['reviews'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a46b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes (one for logistic loss, one for all other loss functions) containing all review info, with columns for\n",
    "#author IDs, app IDs, and ratings (Boolean variable, 1 = positive rating, 0 = negative rating).\n",
    "authorIDs = [];\n",
    "gameIDs = [];\n",
    "ratings = [];\n",
    "ratingsLogistic = [];\n",
    "\n",
    "#Create dataframe for later construction of author features matrix\n",
    "authorFeatures = [];\n",
    "authorCount = 0;\n",
    "\n",
    "for index, game in reviews.iterrows():\n",
    "    for recommendation in game['reviews']:\n",
    "        authorIDs.append(recommendation['author']['steamid'])\n",
    "        gameIDs.append(game['appId'])\n",
    "        \n",
    "        gameRating = recommendation['voted_up']\n",
    "        #numReviews = len(game['reviews'])\n",
    "        \n",
    "        #Create ratings data for fitting models with loss functions other than logistic\n",
    "        #Append gameRating = 1 if voted_up == True, and = 0 if voted_up == False\n",
    "        ratings.append(int(gameRating))\n",
    "        \n",
    "        #Create ratings data for fitting model with logistic loss function\n",
    "        #Append gameRating = 1 if voted_up == True, and = -1 if voted_up == False\n",
    "        ratingsLogistic.append(gameRating + (1 - gameRating)*-1)\n",
    "        \n",
    "        #Also weight this value by number of reviews this game received\n",
    "        #ratings.append((gameRating + (1 - gameRating)*-1)/numReviews)\n",
    "        \n",
    "        #Add info about author to dataframe\n",
    "        authorFeatures.append({'authorID': recommendation['author']['steamid'],\n",
    "                               'num_games_owned': recommendation['author']['num_games_owned'],\n",
    "                               'num_reviews': recommendation['author']['num_reviews']})\n",
    "        \n",
    "reviewsDict = {'authorID': authorIDs, 'appID': gameIDs, 'rating': ratings};\n",
    "reviewsDictLogistic = {'authorID': authorIDs, 'appID': gameIDs, 'rating': ratingsLogistic};\n",
    "\n",
    "reviewsData = pd.DataFrame(data=reviewsDict).sort_values(by=['authorID']).drop_duplicates(['authorID','appID'])\n",
    "reviewsDataLogistic = pd.DataFrame(data=reviewsDictLogistic).sort_values(by=['authorID']).drop_duplicates(['authorID','appID'])\n",
    "\n",
    "#Create dataframe of authorFeatures; sort and drop duplicate authors\n",
    "authorFeaturesData = pd.DataFrame.from_dict(authorFeatures).sort_values(by=['authorID']).drop_duplicates(['authorID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7e9e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create game features dataframe\n",
    "gameFeatures = [];\n",
    "\n",
    "for game in rawGames.iterrows():\n",
    "    gameFeatures.append({'appID': game[1]['appId'], 'tag': game[1]['tagsList'], 'numReviews': game[1]['numReviews'], 'dlcBool': 1*(game[1]['dlcBool'] == 'True')})\n",
    "        \n",
    "gameFeaturesData = pd.DataFrame.from_dict(gameFeatures).sort_values(by=['appID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82287750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247703"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviewsData.authorID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddc69efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nLargest = 50\n",
    "\n",
    "gameFeaturesTagList = []\n",
    "\n",
    "for game in gameFeaturesData.iterrows():\n",
    "    gameFeaturesTagList += game[1]['tag']\n",
    "    \n",
    "gameTagsCountList = pd.Series(gameFeaturesTagList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9bc06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of top N tags\n",
    "nLargest = 50\n",
    "\n",
    "topTags = pd.Series(gameTagsCountList).value_counts().nlargest(n=nLargest).index.to_list()\n",
    "\n",
    "gameFeaturesTagsUpdate = []\n",
    "\n",
    "#Remove tags from tagsList features that are not in the topTags list\n",
    "for game in gameFeaturesData.iterrows():\n",
    "    gameFeaturesTagsUpdate.append(np.array(game[1]['tag'])[np.in1d(game[1]['tag'],topTags)].tolist())\n",
    "\n",
    "#Update game features with trimmed tags\n",
    "gameFeaturesData.update(pd.DataFrame({'tag': gameFeaturesTagsUpdate}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca37940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topTags)\n",
    "gameFeaturesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ca5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty list for collecting the counts of reviews for each author\n",
    "authorReviewsCount = {}\n",
    "\n",
    "#Create dictionary of review counts for each author, initialized to zero\n",
    "for uniqueAuthor in reviewsData['authorID'].unique():\n",
    "    \n",
    "    #Append to dictionary\n",
    "    authorReviewsCount[uniqueAuthor] = 0\n",
    "    \n",
    "#Iterate through review data\n",
    "for review in reviewsData.iterrows():\n",
    "    \n",
    "    #Add to review count\n",
    "    authorReviewsCount[review[1]['authorID']] = authorReviewsCount[review[1]['authorID']] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9a7e928a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of reviews')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Make a histogram of review numbers\n",
    "plt.hist(authorReviewsCount.values(), bins = 500)\n",
    "\n",
    "plt.xlim(5,500)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of reviews per game\n",
    "plt.hist(gameFeaturesData['numReviews'].values, bins = 500)\n",
    "\n",
    "plt.xlim(1,500000)\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ceee0f",
   "metadata": {},
   "source": [
    "There are >100,000 reviewers (accounting for about about 40% of all reviews) who have left only 1 review, and about half of users left fewer than 2 reviews. We can try training on this data and try another model only including reviewers with 2 or more reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a93a6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restrict dataset to reviewers with more than some number of reviews\n",
    "\n",
    "reviewNumberCutoff = 5\n",
    "\n",
    "reviewsDataCutoff = {}\n",
    "reviewsDataCutoffLogistic = {}\n",
    "\n",
    "for review in reviewsData.iterrows():\n",
    "    \n",
    "    if authorReviewsCount[review[1]['authorID']] >= reviewNumberCutoff:\n",
    "        reviewsDataCutoff[review[0]] = True\n",
    "        \n",
    "    else:\n",
    "        reviewsDataCutoff[review[0]] = False\n",
    "\n",
    "for review in reviewsDataLogistic.iterrows():\n",
    "    \n",
    "    if authorReviewsCount[review[1]['authorID']] >= reviewNumberCutoff:\n",
    "        reviewsDataCutoffLogistic[review[0]] = True\n",
    "        \n",
    "    else:\n",
    "        reviewsDataCutoffLogistic[review[0]] = False        \n",
    "\n",
    "#Create Boolean indexing array\n",
    "reviewsCutoffBool = pd.Series(reviewsDataCutoff)\n",
    "reviewsCutoffBoolLogistic = pd.Series(reviewsDataCutoffLogistic)\n",
    "\n",
    "#Remove reviewers with review counts below the cutoff\n",
    "reviewsDataCutoff = reviewsData[reviewsCutoffBool]\n",
    "reviewsDataCutoffLogistic = reviewsData[reviewsCutoffBoolLogistic]\n",
    "\n",
    "reviewsDataCutoff.reset_index(inplace=True)\n",
    "reviewsDataCutoffLogistic.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d4359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82157a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueTagList = uniqueTagNames.tolist()\n",
    "\n",
    "# for feature in ['numReviews','dlcBool']:\n",
    "#     uniqueTagList.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35b4fe3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phyis\\miniconda3\\envs\\phd_env\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Add tag, numReviews, and dlcBool to feature mapping\n",
    "from lightfm.data import Dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "dataset.fit_partial(users=[authorFeature[1]['authorID'] for authorFeature in authorFeaturesData.iterrows()],\n",
    "                    user_features=None,\n",
    "                    items=[gameFeature[1]['appID'] for gameFeature in gameFeaturesData.iterrows()],\n",
    "                    item_features=topTags)\n",
    "\n",
    "# dataset.fit_partial(items=(gameFeature[1]['appID'] for gameFeature in gameFeaturesData.iterrows()),\n",
    "#                     item_features=(gameFeature[1]['numReviews'] for gameFeature in gameFeaturesData.iterrows()))\n",
    "                    \n",
    "# dataset.fit_partial(items=(gameFeature[1]['appID'] for gameFeature in gameFeaturesData.iterrows()),\n",
    "#                     item_features=(gameFeature[1]['dlcBool'] for gameFeature in gameFeaturesData.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c728c821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<113010x113060 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 800287 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "tagFeatures = dataset.build_item_features([(gameFeature[1]['appID'],\n",
    "                                            gameFeature[1]['tag'])\n",
    "                                            for gameFeature in gameFeaturesData.iterrows()],normalize=True)\n",
    "\n",
    "# userFeatures = dataset.build_user_features([(authorFeature[1]['authorID'],\n",
    "#                                             {'num_games_owned': authorFeature[1]['num_games_owned']})\n",
    "#                                             for authorFeature in authorFeaturesData.iterrows()],normalize=True)\n",
    "\n",
    "# #Now build the interaction COO matrix\n",
    "# (reviewSparseMatrix, weights) = dataset.build_interactions(((reviewsDataCutoff['authorID'].iloc[index],\n",
    "#                                                              reviewsDataCutoff['appID'].iloc[index])\n",
    "#                                                              for index in reviewsDataCutoff.index))\n",
    "\n",
    "print(repr(tagFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "596d0fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     10,      20,      30, ..., 2001710, 2028023, 2028850],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameFeaturesData.appID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b255c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorID</th>\n",
       "      <th>appID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106503</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>1825540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299147</th>\n",
       "      <td>76561197960265942</td>\n",
       "      <td>310110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258749</th>\n",
       "      <td>76561197960268079</td>\n",
       "      <td>446110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30044</th>\n",
       "      <td>76561197960268765</td>\n",
       "      <td>1542040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71200</th>\n",
       "      <td>76561197960268765</td>\n",
       "      <td>1081870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107385</th>\n",
       "      <td>76561199367992022</td>\n",
       "      <td>1868050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360963</th>\n",
       "      <td>76561199368056737</td>\n",
       "      <td>356570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104381</th>\n",
       "      <td>76561199368683393</td>\n",
       "      <td>1806610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387657</th>\n",
       "      <td>76561199368686333</td>\n",
       "      <td>960990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134097</th>\n",
       "      <td>76561199369583748</td>\n",
       "      <td>1711420</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392703 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 authorID    appID  rating\n",
       "106503  76561197960265841  1825540       1\n",
       "299147  76561197960265942   310110       0\n",
       "258749  76561197960268079   446110       1\n",
       "30044   76561197960268765  1542040       1\n",
       "71200   76561197960268765  1081870       1\n",
       "...                   ...      ...     ...\n",
       "107385  76561199367992022  1868050       1\n",
       "360963  76561199368056737   356570       1\n",
       "104381  76561199368683393  1806610       1\n",
       "387657  76561199368686333   960990       0\n",
       "134097  76561199369583748  1711420       1\n",
       "\n",
       "[392703 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c948a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247703"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviewsData['authorID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93b3784a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now build the interaction COO matrix\n",
    "(reviewSparseMatrix, weights) = dataset.build_interactions(((reviewsDataCutoff['authorID'].iloc[index],\n",
    "                                                             reviewsDataCutoff['appID'].iloc[index])\n",
    "                                                             for index in reviewsDataCutoff.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b63f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now build the interaction COO matrix for logistic loss function\n",
    "(reviewSparseMatrixLogistic, weights) = dataset.build_interactions(((reviewsDataCutoffLogistic['authorID'].iloc[index],\n",
    "                                                             reviewsDataCutoffLogistic['appID'].iloc[index])\n",
    "                                                             for index in reviewsDataCutoffLogistic.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "id": "07d339a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ID mappings between authors and games\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "dataset.fit(reviewsDataCutoff['authorID'].to_list(),\n",
    "            reviewsDataCutoff['appID'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "5cf7f66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392702"
      ]
     },
     "execution_count": 1181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(reviewsDataCutoff.shape[0])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "id": "cef66261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "id": "f479bde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<247703x61313 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 392703 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(reviewSparseMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "126a3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the reviews dataframe to a sparse interactions matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "authorUnique = CategoricalDtype(sorted(reviewsDataCutoff.authorID.unique()), ordered=True)\n",
    "appUnique = CategoricalDtype(sorted(reviewsDataCutoff.appID.unique()), ordered=True)\n",
    "\n",
    "reviewRow = reviewsDataCutoff.authorID.astype(authorUnique).cat.codes\n",
    "reviewCol = reviewsDataCutoff.appID.astype(appUnique).cat.codes\n",
    "\n",
    "# reviewCol = reviewsDataCutoff.authorID.astype(authorUnique).cat.codes\n",
    "# reviewRow = reviewsDataCutoff.appID.astype(appUnique).cat.codes\n",
    "\n",
    "reviewSparseMatrix = csr_matrix((reviewsDataCutoff['rating'], (reviewRow, reviewCol)), \\\n",
    "                                shape=(authorUnique.categories.size, appUnique.categories.size))\n",
    "\n",
    "reviewSparseMatrixLogistic = csr_matrix((reviewsDataCutoffLogistic['rating'], (reviewRow, reviewCol)), \\\n",
    "                                shape=(authorUnique.categories.size, appUnique.categories.size))\n",
    "\n",
    "# reviewSparseMatrix = csr_matrix((reviewsDataCutoff['rating'], (reviewRow, reviewCol)), \\\n",
    "#                                 shape=(appUnique.categories.size, authorUnique.categories.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "914d7d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247703, 61313)"
      ]
     },
     "execution_count": 1146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewSparseMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "id": "f3203e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "userDict = {};\n",
    "counter = 0\n",
    "\n",
    "for authorID in reviewsDataCutoff['authorID'].unique():\n",
    "    userDict[authorID] = counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "id": "21e6ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemDict ={}\n",
    "\n",
    "reviewGameNames = [rawGames[rawGames['appId'] == appID]['name'].to_string(index=False) \\\n",
    "                  for appID in reviewsData['appID'].to_list()]\n",
    "\n",
    "itemDictDF = pd.DataFrame({'appID': reviewsData['appID'].to_list(), 'appName': reviewGameNames}).sort_values('appID').reset_index()\n",
    "\n",
    "for i in range(itemDictDF.shape[0]):\n",
    "    itemDict[(itemDictDF.loc[i,'appID'])] = itemDictDF.loc[i,'appName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda939eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "\n",
    "#Remove some of the data to speed up training during hyperparameter tuning\n",
    "# reviewSparseMatrix_shrink, reviewSparseMatrix_nonshrink = random_train_test_split(reviewSparseMatrix, test_percentage=0.7, random_state=43)\n",
    "# reviewSparseMatrixLogistic_shrink, reviewSparseMatrixLogistic_nonshrink = random_train_test_split(reviewSparseMatrixLogistic, test_percentage=0.7, random_state=43)\n",
    "\n",
    "reviewSparseMatrix_train, reviewSparseMatrix_nontrain = random_train_test_split(reviewSparseMatrix, random_state=43)\n",
    "reviewSparseMatrixLogistic_train, reviewSparseMatrixLogistic_nontrain = random_train_test_split(reviewSparseMatrixLogistic, random_state=43)\n",
    "\n",
    "reviewSparseMatrix_validation, reviewSparseMatrix_test = random_train_test_split(reviewSparseMatrix_nontrain, random_state=43,test_percentage=0.5)\n",
    "reviewSparseMatrixLogistic_validation, reviewSparseMatrixLogistic_test = random_train_test_split(reviewSparseMatrixLogistic_nontrain, random_state=43,test_percentage=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09b63e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2114504063333929\n"
     ]
    }
   ],
   "source": [
    "#Find best possible value of precision at k for a given k\n",
    "k = 10\n",
    "\n",
    "precisionAtKMax = 0\n",
    "highestReviewCount = max(list(authorReviewsCount.values()))\n",
    "numReviewers = len(list(authorReviewsCount.values()))\n",
    "\n",
    "for ki in np.arange(1,highestReviewCount+1):\n",
    "    \n",
    "    if ki<=k:\n",
    "        precisionAtKMax += (1 - (ki==1))*ki*len(np.array(list(authorReviewsCount.values()))[np.array(list(authorReviewsCount.values())) == ki])/k/numReviewers\n",
    "        \n",
    "    else:\n",
    "        precisionAtKMax += len(np.array(list(authorReviewsCount.values()))[np.array(list(authorReviewsCount.values())) > ki])/numReviewers\n",
    "   \n",
    "\n",
    "print(precisionAtKMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36999e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Train set AUC score: 0.8759492\n",
      "Test set AUC score: 0.55725884\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "model = LightFM(**hyperparameters)\n",
    "model = model.fit(reviewSparseMatrix_train,\n",
    "                  user_features=None,\n",
    "                  item_features=tagFeatures,\n",
    "                  epochs=31,\n",
    "                  num_threads=4, verbose=True)\n",
    "\n",
    "print(\"Train set AUC score:\",auc_score(model, reviewSparseMatrix_train, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "print(\"Test set AUC score:\",auc_score(model, reviewSparseMatrix_test, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "# hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "\n",
    "hyperparameters = {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686, 'item_alpha': 9.259837751692955e-05, 'user_alpha': 7.950089746289809e-05, 'max_sampled': 9}\n",
    "\n",
    "model = LightFM(**hyperparameters)\n",
    "\n",
    "for epoch in np.arange(20):\n",
    "    model.fit_partial(reviewSparseMatrix_train,\n",
    "                  user_features=None,\n",
    "                  item_features=tagFeatures,\n",
    "                  epochs=1,\n",
    "                  num_threads=4, verbose=True)\n",
    "    print(\"Train set precision at k (epoch {}):\".format(epoch),precision_at_k(model, reviewSparseMatrix_train, k=5 train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "    print(\"Test set precision at k (epoch {}):\".format(epoch),precision_at_k(model, reviewSparseMatrix_test, k=5 train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d8814c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Train set precision at k (epoch 25): 0.0018159206\n",
      "Test set precision at k (epoch 25): 4.1710115e-05\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epoch 26): 0.07654229\n",
      "Test set precision at k (epoch 26): 0.002502607\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Train set precision at k (epoch 27): 0.26741293\n",
      "Test set precision at k (epoch 27): 0.0052554747\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Train set precision at k (epoch 28): 0.44119406\n",
      "Test set precision at k (epoch 28): 0.0077580814\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Train set precision at k (epoch 29): 0.5741792\n",
      "Test set precision at k (epoch 29): 0.009635036\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "hyperparameters = {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686, 'item_alpha': 9.259837751692955e-05, 'user_alpha': 7.950089746289809e-05, 'max_sampled': 9}\n",
    "model = LightFM(**hyperparameters)\n",
    "\n",
    "for epoch in np.arange(25,30):\n",
    "    \n",
    "    if epoch == 25:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=25,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epoch {}):\".format(epoch),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epoch {}):\".format(epoch),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        \n",
    "    else:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=(epoch-25 + 1)*25,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epoch {}):\".format(epoch),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epoch {}):\".format(epoch),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f81fbc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Train set precision at k (epoch 125): 0.33099505\n",
      "Test set precision at k (epoch 125): 0.006339938\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Train set precision at k (epoch 150): 0.5960199\n",
      "Test set precision at k (epoch 150): 0.010260688\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Train set precision at k (epoch 175): 0.7030349\n",
      "Test set precision at k (epoch 175): 0.011428572\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Train set precision at k (epoch 200): 0.7611692\n",
      "Test set precision at k (epoch 200): 0.011970803\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set precision at k (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((epoch\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m125\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m),precision_at_k(model, reviewSparseMatrix_test, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, train_interactions\u001b[38;5;241m=\u001b[39mreviewSparseMatrix_train, user_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, item_features\u001b[38;5;241m=\u001b[39mtagFeatures,num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviewSparseMatrix_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                  \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtagFeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m125\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain set precision at k (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((epoch\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m125\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m),precision_at_k(model, reviewSparseMatrix_train, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, train_interactions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, item_features\u001b[38;5;241m=\u001b[39mtagFeatures,num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set precision at k (epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat((epoch\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m125\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m),precision_at_k(model, reviewSparseMatrix_test, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, train_interactions\u001b[38;5;241m=\u001b[39mreviewSparseMatrix_train, user_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, item_features\u001b[38;5;241m=\u001b[39mtagFeatures,num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd_env\\lib\\site-packages\\lightfm\\lightfm.py:638\u001b[0m, in \u001b[0;36mLightFM.fit_partial\u001b[1;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of threads must be 1 or larger.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress(epochs, verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[1;32m--> 638\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_finite()\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "hyperparameters = {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686, 'item_alpha': 9.259837751692955e-05, 'user_alpha': 7.950089746289809e-05, 'max_sampled': 9}\n",
    "model = LightFM(**hyperparameters)\n",
    "\n",
    "for epoch in np.arange(125,135):\n",
    "    \n",
    "    if epoch == 125:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=125,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epoch {}):\".format((epoch-125 + 1)*25+100),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epoch {}):\".format((epoch-125 + 1)*25+100),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        \n",
    "    else:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=(epoch-125 + 1)*25+100,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epoch {}):\".format((epoch-125 + 1)*25+100),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epoch {}):\".format((epoch-125 + 1)*25+100),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1638ccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Train set precision at k (epochs 1): 0.0012189054\n",
      "Test set precision at k (epochs 1): 8.342023e-05\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 26): 0.0012189054\n",
      "Test set precision at k (epochs 26): 0.00016684046\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     epochCount\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreviewSparseMatrix_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                  \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtagFeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain set precision at k (epochs \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epochCount),precision_at_k(model, reviewSparseMatrix_train, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, train_interactions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, item_features\u001b[38;5;241m=\u001b[39mtagFeatures,num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest set precision at k (epochs \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epochCount),precision_at_k(model, reviewSparseMatrix_test, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, train_interactions\u001b[38;5;241m=\u001b[39mreviewSparseMatrix_train, user_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, item_features\u001b[38;5;241m=\u001b[39mtagFeatures,num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd_env\\lib\\site-packages\\lightfm\\lightfm.py:638\u001b[0m, in \u001b[0;36mLightFM.fit_partial\u001b[1;34m(self, interactions, user_features, item_features, sample_weight, epochs, num_threads, verbose)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of threads must be 1 or larger.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_progress(epochs, verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[1;32m--> 638\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_finite()\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\phd_env\\lib\\site-packages\\lightfm\\lightfm.py:679\u001b[0m, in \u001b[0;36mLightFM._run_epoch\u001b[1;34m(self, item_features, user_features, interactions, sample_weight, num_threads, loss)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;66;03m# Call the estimation routines.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 679\u001b[0m     \u001b[43mfit_warp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCSRMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCSRMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpositives_lookup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43minteractions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlightfm_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m loss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbpr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    696\u001b[0m     fit_bpr(\n\u001b[0;32m    697\u001b[0m         CSRMatrix(item_features),\n\u001b[0;32m    698\u001b[0m         CSRMatrix(user_features),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m    711\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "hyperparameters = {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686*2, 'item_alpha': 9.259837751692955e-05*100, 'user_alpha': 7.950089746289809e-05*100, 'max_sampled': 9}\n",
    "model = LightFM(**hyperparameters)\n",
    "\n",
    "epochCount = 1\n",
    "\n",
    "for epoch in np.arange(125,135):\n",
    "    \n",
    "    if epoch == 125:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=125,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        \n",
    "        epochCount+=125\n",
    "        \n",
    "    else:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=(epoch-125 + 1)*125,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "\n",
    "        epochCount+=125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "864cdf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Train set precision at k (epochs 100): 0.0048756218\n",
      "Test set precision at k (epochs 100): 0.0005005214\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Train set precision at k (epochs 200): 0.0033830847\n",
      "Test set precision at k (epochs 200): 0.00037539104\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Train set precision at k (epochs 300): 0.002189055\n",
      "Test set precision at k (epochs 300): 0.00029197082\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n",
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Train set precision at k (epochs 400): 0.0020149255\n",
      "Test set precision at k (epochs 400): 0.0002502607\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n",
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Epoch 400\n",
      "Epoch 401\n",
      "Epoch 402\n",
      "Epoch 403\n",
      "Epoch 404\n",
      "Epoch 405\n",
      "Epoch 406\n",
      "Epoch 407\n",
      "Epoch 408\n",
      "Epoch 409\n",
      "Epoch 410\n",
      "Epoch 411\n",
      "Epoch 412\n",
      "Epoch 413\n",
      "Epoch 414\n",
      "Epoch 415\n",
      "Epoch 416\n",
      "Epoch 417\n",
      "Epoch 418\n",
      "Epoch 419\n",
      "Epoch 420\n",
      "Epoch 421\n",
      "Epoch 422\n",
      "Epoch 423\n",
      "Epoch 424\n",
      "Epoch 425\n",
      "Epoch 426\n",
      "Epoch 427\n",
      "Epoch 428\n",
      "Epoch 429\n",
      "Epoch 430\n",
      "Epoch 431\n",
      "Epoch 432\n",
      "Epoch 433\n",
      "Epoch 434\n",
      "Epoch 435\n",
      "Epoch 436\n",
      "Epoch 437\n",
      "Epoch 438\n",
      "Epoch 439\n",
      "Epoch 440\n",
      "Epoch 441\n",
      "Epoch 442\n",
      "Epoch 443\n",
      "Epoch 444\n",
      "Epoch 445\n",
      "Epoch 446\n",
      "Epoch 447\n",
      "Epoch 448\n",
      "Epoch 449\n",
      "Epoch 450\n",
      "Epoch 451\n",
      "Epoch 452\n",
      "Epoch 453\n",
      "Epoch 454\n",
      "Epoch 455\n",
      "Epoch 456\n",
      "Epoch 457\n",
      "Epoch 458\n",
      "Epoch 459\n",
      "Epoch 460\n",
      "Epoch 461\n",
      "Epoch 462\n",
      "Epoch 463\n",
      "Epoch 464\n",
      "Epoch 465\n",
      "Epoch 466\n",
      "Epoch 467\n",
      "Epoch 468\n",
      "Epoch 469\n",
      "Epoch 470\n",
      "Epoch 471\n",
      "Epoch 472\n",
      "Epoch 473\n",
      "Epoch 474\n",
      "Epoch 475\n",
      "Epoch 476\n",
      "Epoch 477\n",
      "Epoch 478\n",
      "Epoch 479\n",
      "Epoch 480\n",
      "Epoch 481\n",
      "Epoch 482\n",
      "Epoch 483\n",
      "Epoch 484\n",
      "Epoch 485\n",
      "Epoch 486\n",
      "Epoch 487\n",
      "Epoch 488\n",
      "Epoch 489\n",
      "Epoch 490\n",
      "Epoch 491\n",
      "Epoch 492\n",
      "Epoch 493\n",
      "Epoch 494\n",
      "Epoch 495\n",
      "Epoch 496\n",
      "Epoch 497\n",
      "Epoch 498\n",
      "Epoch 499\n",
      "Train set precision at k (epochs 500): 0.0014179106\n",
      "Test set precision at k (epochs 500): 0.00016684046\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n",
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Epoch 400\n",
      "Epoch 401\n",
      "Epoch 402\n",
      "Epoch 403\n",
      "Epoch 404\n",
      "Epoch 405\n",
      "Epoch 406\n",
      "Epoch 407\n",
      "Epoch 408\n",
      "Epoch 409\n",
      "Epoch 410\n",
      "Epoch 411\n",
      "Epoch 412\n",
      "Epoch 413\n",
      "Epoch 414\n",
      "Epoch 415\n",
      "Epoch 416\n",
      "Epoch 417\n",
      "Epoch 418\n",
      "Epoch 419\n",
      "Epoch 420\n",
      "Epoch 421\n",
      "Epoch 422\n",
      "Epoch 423\n",
      "Epoch 424\n",
      "Epoch 425\n",
      "Epoch 426\n",
      "Epoch 427\n",
      "Epoch 428\n",
      "Epoch 429\n",
      "Epoch 430\n",
      "Epoch 431\n",
      "Epoch 432\n",
      "Epoch 433\n",
      "Epoch 434\n",
      "Epoch 435\n",
      "Epoch 436\n",
      "Epoch 437\n",
      "Epoch 438\n",
      "Epoch 439\n",
      "Epoch 440\n",
      "Epoch 441\n",
      "Epoch 442\n",
      "Epoch 443\n",
      "Epoch 444\n",
      "Epoch 445\n",
      "Epoch 446\n",
      "Epoch 447\n",
      "Epoch 448\n",
      "Epoch 449\n",
      "Epoch 450\n",
      "Epoch 451\n",
      "Epoch 452\n",
      "Epoch 453\n",
      "Epoch 454\n",
      "Epoch 455\n",
      "Epoch 456\n",
      "Epoch 457\n",
      "Epoch 458\n",
      "Epoch 459\n",
      "Epoch 460\n",
      "Epoch 461\n",
      "Epoch 462\n",
      "Epoch 463\n",
      "Epoch 464\n",
      "Epoch 465\n",
      "Epoch 466\n",
      "Epoch 467\n",
      "Epoch 468\n",
      "Epoch 469\n",
      "Epoch 470\n",
      "Epoch 471\n",
      "Epoch 472\n",
      "Epoch 473\n",
      "Epoch 474\n",
      "Epoch 475\n",
      "Epoch 476\n",
      "Epoch 477\n",
      "Epoch 478\n",
      "Epoch 479\n",
      "Epoch 480\n",
      "Epoch 481\n",
      "Epoch 482\n",
      "Epoch 483\n",
      "Epoch 484\n",
      "Epoch 485\n",
      "Epoch 486\n",
      "Epoch 487\n",
      "Epoch 488\n",
      "Epoch 489\n",
      "Epoch 490\n",
      "Epoch 491\n",
      "Epoch 492\n",
      "Epoch 493\n",
      "Epoch 494\n",
      "Epoch 495\n",
      "Epoch 496\n",
      "Epoch 497\n",
      "Epoch 498\n",
      "Epoch 499\n",
      "Epoch 500\n",
      "Epoch 501\n",
      "Epoch 502\n",
      "Epoch 503\n",
      "Epoch 504\n",
      "Epoch 505\n",
      "Epoch 506\n",
      "Epoch 507\n",
      "Epoch 508\n",
      "Epoch 509\n",
      "Epoch 510\n",
      "Epoch 511\n",
      "Epoch 512\n",
      "Epoch 513\n",
      "Epoch 514\n",
      "Epoch 515\n",
      "Epoch 516\n",
      "Epoch 517\n",
      "Epoch 518\n",
      "Epoch 519\n",
      "Epoch 520\n",
      "Epoch 521\n",
      "Epoch 522\n",
      "Epoch 523\n",
      "Epoch 524\n",
      "Epoch 525\n",
      "Epoch 526\n",
      "Epoch 527\n",
      "Epoch 528\n",
      "Epoch 529\n",
      "Epoch 530\n",
      "Epoch 531\n",
      "Epoch 532\n",
      "Epoch 533\n",
      "Epoch 534\n",
      "Epoch 535\n",
      "Epoch 536\n",
      "Epoch 537\n",
      "Epoch 538\n",
      "Epoch 539\n",
      "Epoch 540\n",
      "Epoch 541\n",
      "Epoch 542\n",
      "Epoch 543\n",
      "Epoch 544\n",
      "Epoch 545\n",
      "Epoch 546\n",
      "Epoch 547\n",
      "Epoch 548\n",
      "Epoch 549\n",
      "Epoch 550\n",
      "Epoch 551\n",
      "Epoch 552\n",
      "Epoch 553\n",
      "Epoch 554\n",
      "Epoch 555\n",
      "Epoch 556\n",
      "Epoch 557\n",
      "Epoch 558\n",
      "Epoch 559\n",
      "Epoch 560\n",
      "Epoch 561\n",
      "Epoch 562\n",
      "Epoch 563\n",
      "Epoch 564\n",
      "Epoch 565\n",
      "Epoch 566\n",
      "Epoch 567\n",
      "Epoch 568\n",
      "Epoch 569\n",
      "Epoch 570\n",
      "Epoch 571\n",
      "Epoch 572\n",
      "Epoch 573\n",
      "Epoch 574\n",
      "Epoch 575\n",
      "Epoch 576\n",
      "Epoch 577\n",
      "Epoch 578\n",
      "Epoch 579\n",
      "Epoch 580\n",
      "Epoch 581\n",
      "Epoch 582\n",
      "Epoch 583\n",
      "Epoch 584\n",
      "Epoch 585\n",
      "Epoch 586\n",
      "Epoch 587\n",
      "Epoch 588\n",
      "Epoch 589\n",
      "Epoch 590\n",
      "Epoch 591\n",
      "Epoch 592\n",
      "Epoch 593\n",
      "Epoch 594\n",
      "Epoch 595\n",
      "Epoch 596\n",
      "Epoch 597\n",
      "Epoch 598\n",
      "Epoch 599\n",
      "Train set precision at k (epochs 600): 0.0012686568\n",
      "Test set precision at k (epochs 600): 0.00020855057\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Epoch 400\n",
      "Epoch 401\n",
      "Epoch 402\n",
      "Epoch 403\n",
      "Epoch 404\n",
      "Epoch 405\n",
      "Epoch 406\n",
      "Epoch 407\n",
      "Epoch 408\n",
      "Epoch 409\n",
      "Epoch 410\n",
      "Epoch 411\n",
      "Epoch 412\n",
      "Epoch 413\n",
      "Epoch 414\n",
      "Epoch 415\n",
      "Epoch 416\n",
      "Epoch 417\n",
      "Epoch 418\n",
      "Epoch 419\n",
      "Epoch 420\n",
      "Epoch 421\n",
      "Epoch 422\n",
      "Epoch 423\n",
      "Epoch 424\n",
      "Epoch 425\n",
      "Epoch 426\n",
      "Epoch 427\n",
      "Epoch 428\n",
      "Epoch 429\n",
      "Epoch 430\n",
      "Epoch 431\n",
      "Epoch 432\n",
      "Epoch 433\n",
      "Epoch 434\n",
      "Epoch 435\n",
      "Epoch 436\n",
      "Epoch 437\n",
      "Epoch 438\n",
      "Epoch 439\n",
      "Epoch 440\n",
      "Epoch 441\n",
      "Epoch 442\n",
      "Epoch 443\n",
      "Epoch 444\n",
      "Epoch 445\n",
      "Epoch 446\n",
      "Epoch 447\n",
      "Epoch 448\n",
      "Epoch 449\n",
      "Epoch 450\n",
      "Epoch 451\n",
      "Epoch 452\n",
      "Epoch 453\n",
      "Epoch 454\n",
      "Epoch 455\n",
      "Epoch 456\n",
      "Epoch 457\n",
      "Epoch 458\n",
      "Epoch 459\n",
      "Epoch 460\n",
      "Epoch 461\n",
      "Epoch 462\n",
      "Epoch 463\n",
      "Epoch 464\n",
      "Epoch 465\n",
      "Epoch 466\n",
      "Epoch 467\n",
      "Epoch 468\n",
      "Epoch 469\n",
      "Epoch 470\n",
      "Epoch 471\n",
      "Epoch 472\n",
      "Epoch 473\n",
      "Epoch 474\n",
      "Epoch 475\n",
      "Epoch 476\n",
      "Epoch 477\n",
      "Epoch 478\n",
      "Epoch 479\n",
      "Epoch 480\n",
      "Epoch 481\n",
      "Epoch 482\n",
      "Epoch 483\n",
      "Epoch 484\n",
      "Epoch 485\n",
      "Epoch 486\n",
      "Epoch 487\n",
      "Epoch 488\n",
      "Epoch 489\n",
      "Epoch 490\n",
      "Epoch 491\n",
      "Epoch 492\n",
      "Epoch 493\n",
      "Epoch 494\n",
      "Epoch 495\n",
      "Epoch 496\n",
      "Epoch 497\n",
      "Epoch 498\n",
      "Epoch 499\n",
      "Epoch 500\n",
      "Epoch 501\n",
      "Epoch 502\n",
      "Epoch 503\n",
      "Epoch 504\n",
      "Epoch 505\n",
      "Epoch 506\n",
      "Epoch 507\n",
      "Epoch 508\n",
      "Epoch 509\n",
      "Epoch 510\n",
      "Epoch 511\n",
      "Epoch 512\n",
      "Epoch 513\n",
      "Epoch 514\n",
      "Epoch 515\n",
      "Epoch 516\n",
      "Epoch 517\n",
      "Epoch 518\n",
      "Epoch 519\n",
      "Epoch 520\n",
      "Epoch 521\n",
      "Epoch 522\n",
      "Epoch 523\n",
      "Epoch 524\n",
      "Epoch 525\n",
      "Epoch 526\n",
      "Epoch 527\n",
      "Epoch 528\n",
      "Epoch 529\n",
      "Epoch 530\n",
      "Epoch 531\n",
      "Epoch 532\n",
      "Epoch 533\n",
      "Epoch 534\n",
      "Epoch 535\n",
      "Epoch 536\n",
      "Epoch 537\n",
      "Epoch 538\n",
      "Epoch 539\n",
      "Epoch 540\n",
      "Epoch 541\n",
      "Epoch 542\n",
      "Epoch 543\n",
      "Epoch 544\n",
      "Epoch 545\n",
      "Epoch 546\n",
      "Epoch 547\n",
      "Epoch 548\n",
      "Epoch 549\n",
      "Epoch 550\n",
      "Epoch 551\n",
      "Epoch 552\n",
      "Epoch 553\n",
      "Epoch 554\n",
      "Epoch 555\n",
      "Epoch 556\n",
      "Epoch 557\n",
      "Epoch 558\n",
      "Epoch 559\n",
      "Epoch 560\n",
      "Epoch 561\n",
      "Epoch 562\n",
      "Epoch 563\n",
      "Epoch 564\n",
      "Epoch 565\n",
      "Epoch 566\n",
      "Epoch 567\n",
      "Epoch 568\n",
      "Epoch 569\n",
      "Epoch 570\n",
      "Epoch 571\n",
      "Epoch 572\n",
      "Epoch 573\n",
      "Epoch 574\n",
      "Epoch 575\n",
      "Epoch 576\n",
      "Epoch 577\n",
      "Epoch 578\n",
      "Epoch 579\n",
      "Epoch 580\n",
      "Epoch 581\n",
      "Epoch 582\n",
      "Epoch 583\n",
      "Epoch 584\n",
      "Epoch 585\n",
      "Epoch 586\n",
      "Epoch 587\n",
      "Epoch 588\n",
      "Epoch 589\n",
      "Epoch 590\n",
      "Epoch 591\n",
      "Epoch 592\n",
      "Epoch 593\n",
      "Epoch 594\n",
      "Epoch 595\n",
      "Epoch 596\n",
      "Epoch 597\n",
      "Epoch 598\n",
      "Epoch 599\n",
      "Epoch 600\n",
      "Epoch 601\n",
      "Epoch 602\n",
      "Epoch 603\n",
      "Epoch 604\n",
      "Epoch 605\n",
      "Epoch 606\n",
      "Epoch 607\n",
      "Epoch 608\n",
      "Epoch 609\n",
      "Epoch 610\n",
      "Epoch 611\n",
      "Epoch 612\n",
      "Epoch 613\n",
      "Epoch 614\n",
      "Epoch 615\n",
      "Epoch 616\n",
      "Epoch 617\n",
      "Epoch 618\n",
      "Epoch 619\n",
      "Epoch 620\n",
      "Epoch 621\n",
      "Epoch 622\n",
      "Epoch 623\n",
      "Epoch 624\n",
      "Epoch 625\n",
      "Epoch 626\n",
      "Epoch 627\n",
      "Epoch 628\n",
      "Epoch 629\n",
      "Epoch 630\n",
      "Epoch 631\n",
      "Epoch 632\n",
      "Epoch 633\n",
      "Epoch 634\n",
      "Epoch 635\n",
      "Epoch 636\n",
      "Epoch 637\n",
      "Epoch 638\n",
      "Epoch 639\n",
      "Epoch 640\n",
      "Epoch 641\n",
      "Epoch 642\n",
      "Epoch 643\n",
      "Epoch 644\n",
      "Epoch 645\n",
      "Epoch 646\n",
      "Epoch 647\n",
      "Epoch 648\n",
      "Epoch 649\n",
      "Epoch 650\n",
      "Epoch 651\n",
      "Epoch 652\n",
      "Epoch 653\n",
      "Epoch 654\n",
      "Epoch 655\n",
      "Epoch 656\n",
      "Epoch 657\n",
      "Epoch 658\n",
      "Epoch 659\n",
      "Epoch 660\n",
      "Epoch 661\n",
      "Epoch 662\n",
      "Epoch 663\n",
      "Epoch 664\n",
      "Epoch 665\n",
      "Epoch 666\n",
      "Epoch 667\n",
      "Epoch 668\n",
      "Epoch 669\n",
      "Epoch 670\n",
      "Epoch 671\n",
      "Epoch 672\n",
      "Epoch 673\n",
      "Epoch 674\n",
      "Epoch 675\n",
      "Epoch 676\n",
      "Epoch 677\n",
      "Epoch 678\n",
      "Epoch 679\n",
      "Epoch 680\n",
      "Epoch 681\n",
      "Epoch 682\n",
      "Epoch 683\n",
      "Epoch 684\n",
      "Epoch 685\n",
      "Epoch 686\n",
      "Epoch 687\n",
      "Epoch 688\n",
      "Epoch 689\n",
      "Epoch 690\n",
      "Epoch 691\n",
      "Epoch 692\n",
      "Epoch 693\n",
      "Epoch 694\n",
      "Epoch 695\n",
      "Epoch 696\n",
      "Epoch 697\n",
      "Epoch 698\n",
      "Epoch 699\n",
      "Train set precision at k (epochs 700): 0.0013184082\n",
      "Test set precision at k (epochs 700): 0.00016684046\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n",
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Epoch 400\n",
      "Epoch 401\n",
      "Epoch 402\n",
      "Epoch 403\n",
      "Epoch 404\n",
      "Epoch 405\n",
      "Epoch 406\n",
      "Epoch 407\n",
      "Epoch 408\n",
      "Epoch 409\n",
      "Epoch 410\n",
      "Epoch 411\n",
      "Epoch 412\n",
      "Epoch 413\n",
      "Epoch 414\n",
      "Epoch 415\n",
      "Epoch 416\n",
      "Epoch 417\n",
      "Epoch 418\n",
      "Epoch 419\n",
      "Epoch 420\n",
      "Epoch 421\n",
      "Epoch 422\n",
      "Epoch 423\n",
      "Epoch 424\n",
      "Epoch 425\n",
      "Epoch 426\n",
      "Epoch 427\n",
      "Epoch 428\n",
      "Epoch 429\n",
      "Epoch 430\n",
      "Epoch 431\n",
      "Epoch 432\n",
      "Epoch 433\n",
      "Epoch 434\n",
      "Epoch 435\n",
      "Epoch 436\n",
      "Epoch 437\n",
      "Epoch 438\n",
      "Epoch 439\n",
      "Epoch 440\n",
      "Epoch 441\n",
      "Epoch 442\n",
      "Epoch 443\n",
      "Epoch 444\n",
      "Epoch 445\n",
      "Epoch 446\n",
      "Epoch 447\n",
      "Epoch 448\n",
      "Epoch 449\n",
      "Epoch 450\n",
      "Epoch 451\n",
      "Epoch 452\n",
      "Epoch 453\n",
      "Epoch 454\n",
      "Epoch 455\n",
      "Epoch 456\n",
      "Epoch 457\n",
      "Epoch 458\n",
      "Epoch 459\n",
      "Epoch 460\n",
      "Epoch 461\n",
      "Epoch 462\n",
      "Epoch 463\n",
      "Epoch 464\n",
      "Epoch 465\n",
      "Epoch 466\n",
      "Epoch 467\n",
      "Epoch 468\n",
      "Epoch 469\n",
      "Epoch 470\n",
      "Epoch 471\n",
      "Epoch 472\n",
      "Epoch 473\n",
      "Epoch 474\n",
      "Epoch 475\n",
      "Epoch 476\n",
      "Epoch 477\n",
      "Epoch 478\n",
      "Epoch 479\n",
      "Epoch 480\n",
      "Epoch 481\n",
      "Epoch 482\n",
      "Epoch 483\n",
      "Epoch 484\n",
      "Epoch 485\n",
      "Epoch 486\n",
      "Epoch 487\n",
      "Epoch 488\n",
      "Epoch 489\n",
      "Epoch 490\n",
      "Epoch 491\n",
      "Epoch 492\n",
      "Epoch 493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494\n",
      "Epoch 495\n",
      "Epoch 496\n",
      "Epoch 497\n",
      "Epoch 498\n",
      "Epoch 499\n",
      "Epoch 500\n",
      "Epoch 501\n",
      "Epoch 502\n",
      "Epoch 503\n",
      "Epoch 504\n",
      "Epoch 505\n",
      "Epoch 506\n",
      "Epoch 507\n",
      "Epoch 508\n",
      "Epoch 509\n",
      "Epoch 510\n",
      "Epoch 511\n",
      "Epoch 512\n",
      "Epoch 513\n",
      "Epoch 514\n",
      "Epoch 515\n",
      "Epoch 516\n",
      "Epoch 517\n",
      "Epoch 518\n",
      "Epoch 519\n",
      "Epoch 520\n",
      "Epoch 521\n",
      "Epoch 522\n",
      "Epoch 523\n",
      "Epoch 524\n",
      "Epoch 525\n",
      "Epoch 526\n",
      "Epoch 527\n",
      "Epoch 528\n",
      "Epoch 529\n",
      "Epoch 530\n",
      "Epoch 531\n",
      "Epoch 532\n",
      "Epoch 533\n",
      "Epoch 534\n",
      "Epoch 535\n",
      "Epoch 536\n",
      "Epoch 537\n",
      "Epoch 538\n",
      "Epoch 539\n",
      "Epoch 540\n",
      "Epoch 541\n",
      "Epoch 542\n",
      "Epoch 543\n",
      "Epoch 544\n",
      "Epoch 545\n",
      "Epoch 546\n",
      "Epoch 547\n",
      "Epoch 548\n",
      "Epoch 549\n",
      "Epoch 550\n",
      "Epoch 551\n",
      "Epoch 552\n",
      "Epoch 553\n",
      "Epoch 554\n",
      "Epoch 555\n",
      "Epoch 556\n",
      "Epoch 557\n",
      "Epoch 558\n",
      "Epoch 559\n",
      "Epoch 560\n",
      "Epoch 561\n",
      "Epoch 562\n",
      "Epoch 563\n",
      "Epoch 564\n",
      "Epoch 565\n",
      "Epoch 566\n",
      "Epoch 567\n",
      "Epoch 568\n",
      "Epoch 569\n",
      "Epoch 570\n",
      "Epoch 571\n",
      "Epoch 572\n",
      "Epoch 573\n",
      "Epoch 574\n",
      "Epoch 575\n",
      "Epoch 576\n",
      "Epoch 577\n",
      "Epoch 578\n",
      "Epoch 579\n",
      "Epoch 580\n",
      "Epoch 581\n",
      "Epoch 582\n",
      "Epoch 583\n",
      "Epoch 584\n",
      "Epoch 585\n",
      "Epoch 586\n",
      "Epoch 587\n",
      "Epoch 588\n",
      "Epoch 589\n",
      "Epoch 590\n",
      "Epoch 591\n",
      "Epoch 592\n",
      "Epoch 593\n",
      "Epoch 594\n",
      "Epoch 595\n",
      "Epoch 596\n",
      "Epoch 597\n",
      "Epoch 598\n",
      "Epoch 599\n",
      "Epoch 600\n",
      "Epoch 601\n",
      "Epoch 602\n",
      "Epoch 603\n",
      "Epoch 604\n",
      "Epoch 605\n",
      "Epoch 606\n",
      "Epoch 607\n",
      "Epoch 608\n",
      "Epoch 609\n",
      "Epoch 610\n",
      "Epoch 611\n",
      "Epoch 612\n",
      "Epoch 613\n",
      "Epoch 614\n",
      "Epoch 615\n",
      "Epoch 616\n",
      "Epoch 617\n",
      "Epoch 618\n",
      "Epoch 619\n",
      "Epoch 620\n",
      "Epoch 621\n",
      "Epoch 622\n",
      "Epoch 623\n",
      "Epoch 624\n",
      "Epoch 625\n",
      "Epoch 626\n",
      "Epoch 627\n",
      "Epoch 628\n",
      "Epoch 629\n",
      "Epoch 630\n",
      "Epoch 631\n",
      "Epoch 632\n",
      "Epoch 633\n",
      "Epoch 634\n",
      "Epoch 635\n",
      "Epoch 636\n",
      "Epoch 637\n",
      "Epoch 638\n",
      "Epoch 639\n",
      "Epoch 640\n",
      "Epoch 641\n",
      "Epoch 642\n",
      "Epoch 643\n",
      "Epoch 644\n",
      "Epoch 645\n",
      "Epoch 646\n",
      "Epoch 647\n",
      "Epoch 648\n",
      "Epoch 649\n",
      "Epoch 650\n",
      "Epoch 651\n",
      "Epoch 652\n",
      "Epoch 653\n",
      "Epoch 654\n",
      "Epoch 655\n",
      "Epoch 656\n",
      "Epoch 657\n",
      "Epoch 658\n",
      "Epoch 659\n",
      "Epoch 660\n",
      "Epoch 661\n",
      "Epoch 662\n",
      "Epoch 663\n",
      "Epoch 664\n",
      "Epoch 665\n",
      "Epoch 666\n",
      "Epoch 667\n",
      "Epoch 668\n",
      "Epoch 669\n",
      "Epoch 670\n",
      "Epoch 671\n",
      "Epoch 672\n",
      "Epoch 673\n",
      "Epoch 674\n",
      "Epoch 675\n",
      "Epoch 676\n",
      "Epoch 677\n",
      "Epoch 678\n",
      "Epoch 679\n",
      "Epoch 680\n",
      "Epoch 681\n",
      "Epoch 682\n",
      "Epoch 683\n",
      "Epoch 684\n",
      "Epoch 685\n",
      "Epoch 686\n",
      "Epoch 687\n",
      "Epoch 688\n",
      "Epoch 689\n",
      "Epoch 690\n",
      "Epoch 691\n",
      "Epoch 692\n",
      "Epoch 693\n",
      "Epoch 694\n",
      "Epoch 695\n",
      "Epoch 696\n",
      "Epoch 697\n",
      "Epoch 698\n",
      "Epoch 699\n",
      "Epoch 700\n",
      "Epoch 701\n",
      "Epoch 702\n",
      "Epoch 703\n",
      "Epoch 704\n",
      "Epoch 705\n",
      "Epoch 706\n",
      "Epoch 707\n",
      "Epoch 708\n",
      "Epoch 709\n",
      "Epoch 710\n",
      "Epoch 711\n",
      "Epoch 712\n",
      "Epoch 713\n",
      "Epoch 714\n",
      "Epoch 715\n",
      "Epoch 716\n",
      "Epoch 717\n",
      "Epoch 718\n",
      "Epoch 719\n",
      "Epoch 720\n",
      "Epoch 721\n",
      "Epoch 722\n",
      "Epoch 723\n",
      "Epoch 724\n",
      "Epoch 725\n",
      "Epoch 726\n",
      "Epoch 727\n",
      "Epoch 728\n",
      "Epoch 729\n",
      "Epoch 730\n",
      "Epoch 731\n",
      "Epoch 732\n",
      "Epoch 733\n",
      "Epoch 734\n",
      "Epoch 735\n",
      "Epoch 736\n",
      "Epoch 737\n",
      "Epoch 738\n",
      "Epoch 739\n",
      "Epoch 740\n",
      "Epoch 741\n",
      "Epoch 742\n",
      "Epoch 743\n",
      "Epoch 744\n",
      "Epoch 745\n",
      "Epoch 746\n",
      "Epoch 747\n",
      "Epoch 748\n",
      "Epoch 749\n",
      "Epoch 750\n",
      "Epoch 751\n",
      "Epoch 752\n",
      "Epoch 753\n",
      "Epoch 754\n",
      "Epoch 755\n",
      "Epoch 756\n",
      "Epoch 757\n",
      "Epoch 758\n",
      "Epoch 759\n",
      "Epoch 760\n",
      "Epoch 761\n",
      "Epoch 762\n",
      "Epoch 763\n",
      "Epoch 764\n",
      "Epoch 765\n",
      "Epoch 766\n",
      "Epoch 767\n",
      "Epoch 768\n",
      "Epoch 769\n",
      "Epoch 770\n",
      "Epoch 771\n",
      "Epoch 772\n",
      "Epoch 773\n",
      "Epoch 774\n",
      "Epoch 775\n",
      "Epoch 776\n",
      "Epoch 777\n",
      "Epoch 778\n",
      "Epoch 779\n",
      "Epoch 780\n",
      "Epoch 781\n",
      "Epoch 782\n",
      "Epoch 783\n",
      "Epoch 784\n",
      "Epoch 785\n",
      "Epoch 786\n",
      "Epoch 787\n",
      "Epoch 788\n",
      "Epoch 789\n",
      "Epoch 790\n",
      "Epoch 791\n",
      "Epoch 792\n",
      "Epoch 793\n",
      "Epoch 794\n",
      "Epoch 795\n",
      "Epoch 796\n",
      "Epoch 797\n",
      "Epoch 798\n",
      "Epoch 799\n",
      "Train set precision at k (epochs 800): 0.0012686568\n",
      "Test set precision at k (epochs 800): 0.00016684046\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n",
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Epoch 400\n",
      "Epoch 401\n",
      "Epoch 402\n",
      "Epoch 403\n",
      "Epoch 404\n",
      "Epoch 405\n",
      "Epoch 406\n",
      "Epoch 407\n",
      "Epoch 408\n",
      "Epoch 409\n",
      "Epoch 410\n",
      "Epoch 411\n",
      "Epoch 412\n",
      "Epoch 413\n",
      "Epoch 414\n",
      "Epoch 415\n",
      "Epoch 416\n",
      "Epoch 417\n",
      "Epoch 418\n",
      "Epoch 419\n",
      "Epoch 420\n",
      "Epoch 421\n",
      "Epoch 422\n",
      "Epoch 423\n",
      "Epoch 424\n",
      "Epoch 425\n",
      "Epoch 426\n",
      "Epoch 427\n",
      "Epoch 428\n",
      "Epoch 429\n",
      "Epoch 430\n",
      "Epoch 431\n",
      "Epoch 432\n",
      "Epoch 433\n",
      "Epoch 434\n",
      "Epoch 435\n",
      "Epoch 436\n",
      "Epoch 437\n",
      "Epoch 438\n",
      "Epoch 439\n",
      "Epoch 440\n",
      "Epoch 441\n",
      "Epoch 442\n",
      "Epoch 443\n",
      "Epoch 444\n",
      "Epoch 445\n",
      "Epoch 446\n",
      "Epoch 447\n",
      "Epoch 448\n",
      "Epoch 449\n",
      "Epoch 450\n",
      "Epoch 451\n",
      "Epoch 452\n",
      "Epoch 453\n",
      "Epoch 454\n",
      "Epoch 455\n",
      "Epoch 456\n",
      "Epoch 457\n",
      "Epoch 458\n",
      "Epoch 459\n",
      "Epoch 460\n",
      "Epoch 461\n",
      "Epoch 462\n",
      "Epoch 463\n",
      "Epoch 464\n",
      "Epoch 465\n",
      "Epoch 466\n",
      "Epoch 467\n",
      "Epoch 468\n",
      "Epoch 469\n",
      "Epoch 470\n",
      "Epoch 471\n",
      "Epoch 472\n",
      "Epoch 473\n",
      "Epoch 474\n",
      "Epoch 475\n",
      "Epoch 476\n",
      "Epoch 477\n",
      "Epoch 478\n",
      "Epoch 479\n",
      "Epoch 480\n",
      "Epoch 481\n",
      "Epoch 482\n",
      "Epoch 483\n",
      "Epoch 484\n",
      "Epoch 485\n",
      "Epoch 486\n",
      "Epoch 487\n",
      "Epoch 488\n",
      "Epoch 489\n",
      "Epoch 490\n",
      "Epoch 491\n",
      "Epoch 492\n",
      "Epoch 493\n",
      "Epoch 494\n",
      "Epoch 495\n",
      "Epoch 496\n",
      "Epoch 497\n",
      "Epoch 498\n",
      "Epoch 499\n",
      "Epoch 500\n",
      "Epoch 501\n",
      "Epoch 502\n",
      "Epoch 503\n",
      "Epoch 504\n",
      "Epoch 505\n",
      "Epoch 506\n",
      "Epoch 507\n",
      "Epoch 508\n",
      "Epoch 509\n",
      "Epoch 510\n",
      "Epoch 511\n",
      "Epoch 512\n",
      "Epoch 513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514\n",
      "Epoch 515\n",
      "Epoch 516\n",
      "Epoch 517\n",
      "Epoch 518\n",
      "Epoch 519\n",
      "Epoch 520\n",
      "Epoch 521\n",
      "Epoch 522\n",
      "Epoch 523\n",
      "Epoch 524\n",
      "Epoch 525\n",
      "Epoch 526\n",
      "Epoch 527\n",
      "Epoch 528\n",
      "Epoch 529\n",
      "Epoch 530\n",
      "Epoch 531\n",
      "Epoch 532\n",
      "Epoch 533\n",
      "Epoch 534\n",
      "Epoch 535\n",
      "Epoch 536\n",
      "Epoch 537\n",
      "Epoch 538\n",
      "Epoch 539\n",
      "Epoch 540\n",
      "Epoch 541\n",
      "Epoch 542\n",
      "Epoch 543\n",
      "Epoch 544\n",
      "Epoch 545\n",
      "Epoch 546\n",
      "Epoch 547\n",
      "Epoch 548\n",
      "Epoch 549\n",
      "Epoch 550\n",
      "Epoch 551\n",
      "Epoch 552\n",
      "Epoch 553\n",
      "Epoch 554\n",
      "Epoch 555\n",
      "Epoch 556\n",
      "Epoch 557\n",
      "Epoch 558\n",
      "Epoch 559\n",
      "Epoch 560\n",
      "Epoch 561\n",
      "Epoch 562\n",
      "Epoch 563\n",
      "Epoch 564\n",
      "Epoch 565\n",
      "Epoch 566\n",
      "Epoch 567\n",
      "Epoch 568\n",
      "Epoch 569\n",
      "Epoch 570\n",
      "Epoch 571\n",
      "Epoch 572\n",
      "Epoch 573\n",
      "Epoch 574\n",
      "Epoch 575\n",
      "Epoch 576\n",
      "Epoch 577\n",
      "Epoch 578\n",
      "Epoch 579\n",
      "Epoch 580\n",
      "Epoch 581\n",
      "Epoch 582\n",
      "Epoch 583\n",
      "Epoch 584\n",
      "Epoch 585\n",
      "Epoch 586\n",
      "Epoch 587\n",
      "Epoch 588\n",
      "Epoch 589\n",
      "Epoch 590\n",
      "Epoch 591\n",
      "Epoch 592\n",
      "Epoch 593\n",
      "Epoch 594\n",
      "Epoch 595\n",
      "Epoch 596\n",
      "Epoch 597\n",
      "Epoch 598\n",
      "Epoch 599\n",
      "Epoch 600\n",
      "Epoch 601\n",
      "Epoch 602\n",
      "Epoch 603\n",
      "Epoch 604\n",
      "Epoch 605\n",
      "Epoch 606\n",
      "Epoch 607\n",
      "Epoch 608\n",
      "Epoch 609\n",
      "Epoch 610\n",
      "Epoch 611\n",
      "Epoch 612\n",
      "Epoch 613\n",
      "Epoch 614\n",
      "Epoch 615\n",
      "Epoch 616\n",
      "Epoch 617\n",
      "Epoch 618\n",
      "Epoch 619\n",
      "Epoch 620\n",
      "Epoch 621\n",
      "Epoch 622\n",
      "Epoch 623\n",
      "Epoch 624\n",
      "Epoch 625\n",
      "Epoch 626\n",
      "Epoch 627\n",
      "Epoch 628\n",
      "Epoch 629\n",
      "Epoch 630\n",
      "Epoch 631\n",
      "Epoch 632\n",
      "Epoch 633\n",
      "Epoch 634\n",
      "Epoch 635\n",
      "Epoch 636\n",
      "Epoch 637\n",
      "Epoch 638\n",
      "Epoch 639\n",
      "Epoch 640\n",
      "Epoch 641\n",
      "Epoch 642\n",
      "Epoch 643\n",
      "Epoch 644\n",
      "Epoch 645\n",
      "Epoch 646\n",
      "Epoch 647\n",
      "Epoch 648\n",
      "Epoch 649\n",
      "Epoch 650\n",
      "Epoch 651\n",
      "Epoch 652\n",
      "Epoch 653\n",
      "Epoch 654\n",
      "Epoch 655\n",
      "Epoch 656\n",
      "Epoch 657\n",
      "Epoch 658\n",
      "Epoch 659\n",
      "Epoch 660\n",
      "Epoch 661\n",
      "Epoch 662\n",
      "Epoch 663\n",
      "Epoch 664\n",
      "Epoch 665\n",
      "Epoch 666\n",
      "Epoch 667\n",
      "Epoch 668\n",
      "Epoch 669\n",
      "Epoch 670\n",
      "Epoch 671\n",
      "Epoch 672\n",
      "Epoch 673\n",
      "Epoch 674\n",
      "Epoch 675\n",
      "Epoch 676\n",
      "Epoch 677\n",
      "Epoch 678\n",
      "Epoch 679\n",
      "Epoch 680\n",
      "Epoch 681\n",
      "Epoch 682\n",
      "Epoch 683\n",
      "Epoch 684\n",
      "Epoch 685\n",
      "Epoch 686\n",
      "Epoch 687\n",
      "Epoch 688\n",
      "Epoch 689\n",
      "Epoch 690\n",
      "Epoch 691\n",
      "Epoch 692\n",
      "Epoch 693\n",
      "Epoch 694\n",
      "Epoch 695\n",
      "Epoch 696\n",
      "Epoch 697\n",
      "Epoch 698\n",
      "Epoch 699\n",
      "Epoch 700\n",
      "Epoch 701\n",
      "Epoch 702\n",
      "Epoch 703\n",
      "Epoch 704\n",
      "Epoch 705\n",
      "Epoch 706\n",
      "Epoch 707\n",
      "Epoch 708\n",
      "Epoch 709\n",
      "Epoch 710\n",
      "Epoch 711\n",
      "Epoch 712\n",
      "Epoch 713\n",
      "Epoch 714\n",
      "Epoch 715\n",
      "Epoch 716\n",
      "Epoch 717\n",
      "Epoch 718\n",
      "Epoch 719\n",
      "Epoch 720\n",
      "Epoch 721\n",
      "Epoch 722\n",
      "Epoch 723\n",
      "Epoch 724\n",
      "Epoch 725\n",
      "Epoch 726\n",
      "Epoch 727\n",
      "Epoch 728\n",
      "Epoch 729\n",
      "Epoch 730\n",
      "Epoch 731\n",
      "Epoch 732\n",
      "Epoch 733\n",
      "Epoch 734\n",
      "Epoch 735\n",
      "Epoch 736\n",
      "Epoch 737\n",
      "Epoch 738\n",
      "Epoch 739\n",
      "Epoch 740\n",
      "Epoch 741\n",
      "Epoch 742\n",
      "Epoch 743\n",
      "Epoch 744\n",
      "Epoch 745\n",
      "Epoch 746\n",
      "Epoch 747\n",
      "Epoch 748\n",
      "Epoch 749\n",
      "Epoch 750\n",
      "Epoch 751\n",
      "Epoch 752\n",
      "Epoch 753\n",
      "Epoch 754\n",
      "Epoch 755\n",
      "Epoch 756\n",
      "Epoch 757\n",
      "Epoch 758\n",
      "Epoch 759\n",
      "Epoch 760\n",
      "Epoch 761\n",
      "Epoch 762\n",
      "Epoch 763\n",
      "Epoch 764\n",
      "Epoch 765\n",
      "Epoch 766\n",
      "Epoch 767\n",
      "Epoch 768\n",
      "Epoch 769\n",
      "Epoch 770\n",
      "Epoch 771\n",
      "Epoch 772\n",
      "Epoch 773\n",
      "Epoch 774\n",
      "Epoch 775\n",
      "Epoch 776\n",
      "Epoch 777\n",
      "Epoch 778\n",
      "Epoch 779\n",
      "Epoch 780\n",
      "Epoch 781\n",
      "Epoch 782\n",
      "Epoch 783\n",
      "Epoch 784\n",
      "Epoch 785\n",
      "Epoch 786\n",
      "Epoch 787\n",
      "Epoch 788\n",
      "Epoch 789\n",
      "Epoch 790\n",
      "Epoch 791\n",
      "Epoch 792\n",
      "Epoch 793\n",
      "Epoch 794\n",
      "Epoch 795\n",
      "Epoch 796\n",
      "Epoch 797\n",
      "Epoch 798\n",
      "Epoch 799\n",
      "Epoch 800\n",
      "Epoch 801\n",
      "Epoch 802\n",
      "Epoch 803\n",
      "Epoch 804\n",
      "Epoch 805\n",
      "Epoch 806\n",
      "Epoch 807\n",
      "Epoch 808\n",
      "Epoch 809\n",
      "Epoch 810\n",
      "Epoch 811\n",
      "Epoch 812\n",
      "Epoch 813\n",
      "Epoch 814\n",
      "Epoch 815\n",
      "Epoch 816\n",
      "Epoch 817\n",
      "Epoch 818\n",
      "Epoch 819\n",
      "Epoch 820\n",
      "Epoch 821\n",
      "Epoch 822\n",
      "Epoch 823\n",
      "Epoch 824\n",
      "Epoch 825\n",
      "Epoch 826\n",
      "Epoch 827\n",
      "Epoch 828\n",
      "Epoch 829\n",
      "Epoch 830\n",
      "Epoch 831\n",
      "Epoch 832\n",
      "Epoch 833\n",
      "Epoch 834\n",
      "Epoch 835\n",
      "Epoch 836\n",
      "Epoch 837\n",
      "Epoch 838\n",
      "Epoch 839\n",
      "Epoch 840\n",
      "Epoch 841\n",
      "Epoch 842\n",
      "Epoch 843\n",
      "Epoch 844\n",
      "Epoch 845\n",
      "Epoch 846\n",
      "Epoch 847\n",
      "Epoch 848\n",
      "Epoch 849\n",
      "Epoch 850\n",
      "Epoch 851\n",
      "Epoch 852\n",
      "Epoch 853\n",
      "Epoch 854\n",
      "Epoch 855\n",
      "Epoch 856\n",
      "Epoch 857\n",
      "Epoch 858\n",
      "Epoch 859\n",
      "Epoch 860\n",
      "Epoch 861\n",
      "Epoch 862\n",
      "Epoch 863\n",
      "Epoch 864\n",
      "Epoch 865\n",
      "Epoch 866\n",
      "Epoch 867\n",
      "Epoch 868\n",
      "Epoch 869\n",
      "Epoch 870\n",
      "Epoch 871\n",
      "Epoch 872\n",
      "Epoch 873\n",
      "Epoch 874\n",
      "Epoch 875\n",
      "Epoch 876\n",
      "Epoch 877\n",
      "Epoch 878\n",
      "Epoch 879\n",
      "Epoch 880\n",
      "Epoch 881\n",
      "Epoch 882\n",
      "Epoch 883\n",
      "Epoch 884\n",
      "Epoch 885\n",
      "Epoch 886\n",
      "Epoch 887\n",
      "Epoch 888\n",
      "Epoch 889\n",
      "Epoch 890\n",
      "Epoch 891\n",
      "Epoch 892\n",
      "Epoch 893\n",
      "Epoch 894\n",
      "Epoch 895\n",
      "Epoch 896\n",
      "Epoch 897\n",
      "Epoch 898\n",
      "Epoch 899\n",
      "Train set precision at k (epochs 900): 0.0012686568\n",
      "Test set precision at k (epochs 900): 0.00020855057\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Epoch 51\n",
      "Epoch 52\n",
      "Epoch 53\n",
      "Epoch 54\n",
      "Epoch 55\n",
      "Epoch 56\n",
      "Epoch 57\n",
      "Epoch 58\n",
      "Epoch 59\n",
      "Epoch 60\n",
      "Epoch 61\n",
      "Epoch 62\n",
      "Epoch 63\n",
      "Epoch 64\n",
      "Epoch 65\n",
      "Epoch 66\n",
      "Epoch 67\n",
      "Epoch 68\n",
      "Epoch 69\n",
      "Epoch 70\n",
      "Epoch 71\n",
      "Epoch 72\n",
      "Epoch 73\n",
      "Epoch 74\n",
      "Epoch 75\n",
      "Epoch 76\n",
      "Epoch 77\n",
      "Epoch 78\n",
      "Epoch 79\n",
      "Epoch 80\n",
      "Epoch 81\n",
      "Epoch 82\n",
      "Epoch 83\n",
      "Epoch 84\n",
      "Epoch 85\n",
      "Epoch 86\n",
      "Epoch 87\n",
      "Epoch 88\n",
      "Epoch 89\n",
      "Epoch 90\n",
      "Epoch 91\n",
      "Epoch 92\n",
      "Epoch 93\n",
      "Epoch 94\n",
      "Epoch 95\n",
      "Epoch 96\n",
      "Epoch 97\n",
      "Epoch 98\n",
      "Epoch 99\n",
      "Epoch 100\n",
      "Epoch 101\n",
      "Epoch 102\n",
      "Epoch 103\n",
      "Epoch 104\n",
      "Epoch 105\n",
      "Epoch 106\n",
      "Epoch 107\n",
      "Epoch 108\n",
      "Epoch 109\n",
      "Epoch 110\n",
      "Epoch 111\n",
      "Epoch 112\n",
      "Epoch 113\n",
      "Epoch 114\n",
      "Epoch 115\n",
      "Epoch 116\n",
      "Epoch 117\n",
      "Epoch 118\n",
      "Epoch 119\n",
      "Epoch 120\n",
      "Epoch 121\n",
      "Epoch 122\n",
      "Epoch 123\n",
      "Epoch 124\n",
      "Epoch 125\n",
      "Epoch 126\n",
      "Epoch 127\n",
      "Epoch 128\n",
      "Epoch 129\n",
      "Epoch 130\n",
      "Epoch 131\n",
      "Epoch 132\n",
      "Epoch 133\n",
      "Epoch 134\n",
      "Epoch 135\n",
      "Epoch 136\n",
      "Epoch 137\n",
      "Epoch 138\n",
      "Epoch 139\n",
      "Epoch 140\n",
      "Epoch 141\n",
      "Epoch 142\n",
      "Epoch 143\n",
      "Epoch 144\n",
      "Epoch 145\n",
      "Epoch 146\n",
      "Epoch 147\n",
      "Epoch 148\n",
      "Epoch 149\n",
      "Epoch 150\n",
      "Epoch 151\n",
      "Epoch 152\n",
      "Epoch 153\n",
      "Epoch 154\n",
      "Epoch 155\n",
      "Epoch 156\n",
      "Epoch 157\n",
      "Epoch 158\n",
      "Epoch 159\n",
      "Epoch 160\n",
      "Epoch 161\n",
      "Epoch 162\n",
      "Epoch 163\n",
      "Epoch 164\n",
      "Epoch 165\n",
      "Epoch 166\n",
      "Epoch 167\n",
      "Epoch 168\n",
      "Epoch 169\n",
      "Epoch 170\n",
      "Epoch 171\n",
      "Epoch 172\n",
      "Epoch 173\n",
      "Epoch 174\n",
      "Epoch 175\n",
      "Epoch 176\n",
      "Epoch 177\n",
      "Epoch 178\n",
      "Epoch 179\n",
      "Epoch 180\n",
      "Epoch 181\n",
      "Epoch 182\n",
      "Epoch 183\n",
      "Epoch 184\n",
      "Epoch 185\n",
      "Epoch 186\n",
      "Epoch 187\n",
      "Epoch 188\n",
      "Epoch 189\n",
      "Epoch 190\n",
      "Epoch 191\n",
      "Epoch 192\n",
      "Epoch 193\n",
      "Epoch 194\n",
      "Epoch 195\n",
      "Epoch 196\n",
      "Epoch 197\n",
      "Epoch 198\n",
      "Epoch 199\n",
      "Epoch 200\n",
      "Epoch 201\n",
      "Epoch 202\n",
      "Epoch 203\n",
      "Epoch 204\n",
      "Epoch 205\n",
      "Epoch 206\n",
      "Epoch 207\n",
      "Epoch 208\n",
      "Epoch 209\n",
      "Epoch 210\n",
      "Epoch 211\n",
      "Epoch 212\n",
      "Epoch 213\n",
      "Epoch 214\n",
      "Epoch 215\n",
      "Epoch 216\n",
      "Epoch 217\n",
      "Epoch 218\n",
      "Epoch 219\n",
      "Epoch 220\n",
      "Epoch 221\n",
      "Epoch 222\n",
      "Epoch 223\n",
      "Epoch 224\n",
      "Epoch 225\n",
      "Epoch 226\n",
      "Epoch 227\n",
      "Epoch 228\n",
      "Epoch 229\n",
      "Epoch 230\n",
      "Epoch 231\n",
      "Epoch 232\n",
      "Epoch 233\n",
      "Epoch 234\n",
      "Epoch 235\n",
      "Epoch 236\n",
      "Epoch 237\n",
      "Epoch 238\n",
      "Epoch 239\n",
      "Epoch 240\n",
      "Epoch 241\n",
      "Epoch 242\n",
      "Epoch 243\n",
      "Epoch 244\n",
      "Epoch 245\n",
      "Epoch 246\n",
      "Epoch 247\n",
      "Epoch 248\n",
      "Epoch 249\n",
      "Epoch 250\n",
      "Epoch 251\n",
      "Epoch 252\n",
      "Epoch 253\n",
      "Epoch 254\n",
      "Epoch 255\n",
      "Epoch 256\n",
      "Epoch 257\n",
      "Epoch 258\n",
      "Epoch 259\n",
      "Epoch 260\n",
      "Epoch 261\n",
      "Epoch 262\n",
      "Epoch 263\n",
      "Epoch 264\n",
      "Epoch 265\n",
      "Epoch 266\n",
      "Epoch 267\n",
      "Epoch 268\n",
      "Epoch 269\n",
      "Epoch 270\n",
      "Epoch 271\n",
      "Epoch 272\n",
      "Epoch 273\n",
      "Epoch 274\n",
      "Epoch 275\n",
      "Epoch 276\n",
      "Epoch 277\n",
      "Epoch 278\n",
      "Epoch 279\n",
      "Epoch 280\n",
      "Epoch 281\n",
      "Epoch 282\n",
      "Epoch 283\n",
      "Epoch 284\n",
      "Epoch 285\n",
      "Epoch 286\n",
      "Epoch 287\n",
      "Epoch 288\n",
      "Epoch 289\n",
      "Epoch 290\n",
      "Epoch 291\n",
      "Epoch 292\n",
      "Epoch 293\n",
      "Epoch 294\n",
      "Epoch 295\n",
      "Epoch 296\n",
      "Epoch 297\n",
      "Epoch 298\n",
      "Epoch 299\n",
      "Epoch 300\n",
      "Epoch 301\n",
      "Epoch 302\n",
      "Epoch 303\n",
      "Epoch 304\n",
      "Epoch 305\n",
      "Epoch 306\n",
      "Epoch 307\n",
      "Epoch 308\n",
      "Epoch 309\n",
      "Epoch 310\n",
      "Epoch 311\n",
      "Epoch 312\n",
      "Epoch 313\n",
      "Epoch 314\n",
      "Epoch 315\n",
      "Epoch 316\n",
      "Epoch 317\n",
      "Epoch 318\n",
      "Epoch 319\n",
      "Epoch 320\n",
      "Epoch 321\n",
      "Epoch 322\n",
      "Epoch 323\n",
      "Epoch 324\n",
      "Epoch 325\n",
      "Epoch 326\n",
      "Epoch 327\n",
      "Epoch 328\n",
      "Epoch 329\n",
      "Epoch 330\n",
      "Epoch 331\n",
      "Epoch 332\n",
      "Epoch 333\n",
      "Epoch 334\n",
      "Epoch 335\n",
      "Epoch 336\n",
      "Epoch 337\n",
      "Epoch 338\n",
      "Epoch 339\n",
      "Epoch 340\n",
      "Epoch 341\n",
      "Epoch 342\n",
      "Epoch 343\n",
      "Epoch 344\n",
      "Epoch 345\n",
      "Epoch 346\n",
      "Epoch 347\n",
      "Epoch 348\n",
      "Epoch 349\n",
      "Epoch 350\n",
      "Epoch 351\n",
      "Epoch 352\n",
      "Epoch 353\n",
      "Epoch 354\n",
      "Epoch 355\n",
      "Epoch 356\n",
      "Epoch 357\n",
      "Epoch 358\n",
      "Epoch 359\n",
      "Epoch 360\n",
      "Epoch 361\n",
      "Epoch 362\n",
      "Epoch 363\n",
      "Epoch 364\n",
      "Epoch 365\n",
      "Epoch 366\n",
      "Epoch 367\n",
      "Epoch 368\n",
      "Epoch 369\n",
      "Epoch 370\n",
      "Epoch 371\n",
      "Epoch 372\n",
      "Epoch 373\n",
      "Epoch 374\n",
      "Epoch 375\n",
      "Epoch 376\n",
      "Epoch 377\n",
      "Epoch 378\n",
      "Epoch 379\n",
      "Epoch 380\n",
      "Epoch 381\n",
      "Epoch 382\n",
      "Epoch 383\n",
      "Epoch 384\n",
      "Epoch 385\n",
      "Epoch 386\n",
      "Epoch 387\n",
      "Epoch 388\n",
      "Epoch 389\n",
      "Epoch 390\n",
      "Epoch 391\n",
      "Epoch 392\n",
      "Epoch 393\n",
      "Epoch 394\n",
      "Epoch 395\n",
      "Epoch 396\n",
      "Epoch 397\n",
      "Epoch 398\n",
      "Epoch 399\n",
      "Epoch 400\n",
      "Epoch 401\n",
      "Epoch 402\n",
      "Epoch 403\n",
      "Epoch 404\n",
      "Epoch 405\n",
      "Epoch 406\n",
      "Epoch 407\n",
      "Epoch 408\n",
      "Epoch 409\n",
      "Epoch 410\n",
      "Epoch 411\n",
      "Epoch 412\n",
      "Epoch 413\n",
      "Epoch 414\n",
      "Epoch 415\n",
      "Epoch 416\n",
      "Epoch 417\n",
      "Epoch 418\n",
      "Epoch 419\n",
      "Epoch 420\n",
      "Epoch 421\n",
      "Epoch 422\n",
      "Epoch 423\n",
      "Epoch 424\n",
      "Epoch 425\n",
      "Epoch 426\n",
      "Epoch 427\n",
      "Epoch 428\n",
      "Epoch 429\n",
      "Epoch 430\n",
      "Epoch 431\n",
      "Epoch 432\n",
      "Epoch 433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434\n",
      "Epoch 435\n",
      "Epoch 436\n",
      "Epoch 437\n",
      "Epoch 438\n",
      "Epoch 439\n",
      "Epoch 440\n",
      "Epoch 441\n",
      "Epoch 442\n",
      "Epoch 443\n",
      "Epoch 444\n",
      "Epoch 445\n",
      "Epoch 446\n",
      "Epoch 447\n",
      "Epoch 448\n",
      "Epoch 449\n",
      "Epoch 450\n",
      "Epoch 451\n",
      "Epoch 452\n",
      "Epoch 453\n",
      "Epoch 454\n",
      "Epoch 455\n",
      "Epoch 456\n",
      "Epoch 457\n",
      "Epoch 458\n",
      "Epoch 459\n",
      "Epoch 460\n",
      "Epoch 461\n",
      "Epoch 462\n",
      "Epoch 463\n",
      "Epoch 464\n",
      "Epoch 465\n",
      "Epoch 466\n",
      "Epoch 467\n",
      "Epoch 468\n",
      "Epoch 469\n",
      "Epoch 470\n",
      "Epoch 471\n",
      "Epoch 472\n",
      "Epoch 473\n",
      "Epoch 474\n",
      "Epoch 475\n",
      "Epoch 476\n",
      "Epoch 477\n",
      "Epoch 478\n",
      "Epoch 479\n",
      "Epoch 480\n",
      "Epoch 481\n",
      "Epoch 482\n",
      "Epoch 483\n",
      "Epoch 484\n",
      "Epoch 485\n",
      "Epoch 486\n",
      "Epoch 487\n",
      "Epoch 488\n",
      "Epoch 489\n",
      "Epoch 490\n",
      "Epoch 491\n",
      "Epoch 492\n",
      "Epoch 493\n",
      "Epoch 494\n",
      "Epoch 495\n",
      "Epoch 496\n",
      "Epoch 497\n",
      "Epoch 498\n",
      "Epoch 499\n",
      "Epoch 500\n",
      "Epoch 501\n",
      "Epoch 502\n",
      "Epoch 503\n",
      "Epoch 504\n",
      "Epoch 505\n",
      "Epoch 506\n",
      "Epoch 507\n",
      "Epoch 508\n",
      "Epoch 509\n",
      "Epoch 510\n",
      "Epoch 511\n",
      "Epoch 512\n",
      "Epoch 513\n",
      "Epoch 514\n",
      "Epoch 515\n",
      "Epoch 516\n",
      "Epoch 517\n",
      "Epoch 518\n",
      "Epoch 519\n",
      "Epoch 520\n",
      "Epoch 521\n",
      "Epoch 522\n",
      "Epoch 523\n",
      "Epoch 524\n",
      "Epoch 525\n",
      "Epoch 526\n",
      "Epoch 527\n",
      "Epoch 528\n",
      "Epoch 529\n",
      "Epoch 530\n",
      "Epoch 531\n",
      "Epoch 532\n",
      "Epoch 533\n",
      "Epoch 534\n",
      "Epoch 535\n",
      "Epoch 536\n",
      "Epoch 537\n",
      "Epoch 538\n",
      "Epoch 539\n",
      "Epoch 540\n",
      "Epoch 541\n",
      "Epoch 542\n",
      "Epoch 543\n",
      "Epoch 544\n",
      "Epoch 545\n",
      "Epoch 546\n",
      "Epoch 547\n",
      "Epoch 548\n",
      "Epoch 549\n",
      "Epoch 550\n",
      "Epoch 551\n",
      "Epoch 552\n",
      "Epoch 553\n",
      "Epoch 554\n",
      "Epoch 555\n",
      "Epoch 556\n",
      "Epoch 557\n",
      "Epoch 558\n",
      "Epoch 559\n",
      "Epoch 560\n",
      "Epoch 561\n",
      "Epoch 562\n",
      "Epoch 563\n",
      "Epoch 564\n",
      "Epoch 565\n",
      "Epoch 566\n",
      "Epoch 567\n",
      "Epoch 568\n",
      "Epoch 569\n",
      "Epoch 570\n",
      "Epoch 571\n",
      "Epoch 572\n",
      "Epoch 573\n",
      "Epoch 574\n",
      "Epoch 575\n",
      "Epoch 576\n",
      "Epoch 577\n",
      "Epoch 578\n",
      "Epoch 579\n",
      "Epoch 580\n",
      "Epoch 581\n",
      "Epoch 582\n",
      "Epoch 583\n",
      "Epoch 584\n",
      "Epoch 585\n",
      "Epoch 586\n",
      "Epoch 587\n",
      "Epoch 588\n",
      "Epoch 589\n",
      "Epoch 590\n",
      "Epoch 591\n",
      "Epoch 592\n",
      "Epoch 593\n",
      "Epoch 594\n",
      "Epoch 595\n",
      "Epoch 596\n",
      "Epoch 597\n",
      "Epoch 598\n",
      "Epoch 599\n",
      "Epoch 600\n",
      "Epoch 601\n",
      "Epoch 602\n",
      "Epoch 603\n",
      "Epoch 604\n",
      "Epoch 605\n",
      "Epoch 606\n",
      "Epoch 607\n",
      "Epoch 608\n",
      "Epoch 609\n",
      "Epoch 610\n",
      "Epoch 611\n",
      "Epoch 612\n",
      "Epoch 613\n",
      "Epoch 614\n",
      "Epoch 615\n",
      "Epoch 616\n",
      "Epoch 617\n",
      "Epoch 618\n",
      "Epoch 619\n",
      "Epoch 620\n",
      "Epoch 621\n",
      "Epoch 622\n",
      "Epoch 623\n",
      "Epoch 624\n",
      "Epoch 625\n",
      "Epoch 626\n",
      "Epoch 627\n",
      "Epoch 628\n",
      "Epoch 629\n",
      "Epoch 630\n",
      "Epoch 631\n",
      "Epoch 632\n",
      "Epoch 633\n",
      "Epoch 634\n",
      "Epoch 635\n",
      "Epoch 636\n",
      "Epoch 637\n",
      "Epoch 638\n",
      "Epoch 639\n",
      "Epoch 640\n",
      "Epoch 641\n",
      "Epoch 642\n",
      "Epoch 643\n",
      "Epoch 644\n",
      "Epoch 645\n",
      "Epoch 646\n",
      "Epoch 647\n",
      "Epoch 648\n",
      "Epoch 649\n",
      "Epoch 650\n",
      "Epoch 651\n",
      "Epoch 652\n",
      "Epoch 653\n",
      "Epoch 654\n",
      "Epoch 655\n",
      "Epoch 656\n",
      "Epoch 657\n",
      "Epoch 658\n",
      "Epoch 659\n",
      "Epoch 660\n",
      "Epoch 661\n",
      "Epoch 662\n",
      "Epoch 663\n",
      "Epoch 664\n",
      "Epoch 665\n",
      "Epoch 666\n",
      "Epoch 667\n",
      "Epoch 668\n",
      "Epoch 669\n",
      "Epoch 670\n",
      "Epoch 671\n",
      "Epoch 672\n",
      "Epoch 673\n",
      "Epoch 674\n",
      "Epoch 675\n",
      "Epoch 676\n",
      "Epoch 677\n",
      "Epoch 678\n",
      "Epoch 679\n",
      "Epoch 680\n",
      "Epoch 681\n",
      "Epoch 682\n",
      "Epoch 683\n",
      "Epoch 684\n",
      "Epoch 685\n",
      "Epoch 686\n",
      "Epoch 687\n",
      "Epoch 688\n",
      "Epoch 689\n",
      "Epoch 690\n",
      "Epoch 691\n",
      "Epoch 692\n",
      "Epoch 693\n",
      "Epoch 694\n",
      "Epoch 695\n",
      "Epoch 696\n",
      "Epoch 697\n",
      "Epoch 698\n",
      "Epoch 699\n",
      "Epoch 700\n",
      "Epoch 701\n",
      "Epoch 702\n",
      "Epoch 703\n",
      "Epoch 704\n",
      "Epoch 705\n",
      "Epoch 706\n",
      "Epoch 707\n",
      "Epoch 708\n",
      "Epoch 709\n",
      "Epoch 710\n",
      "Epoch 711\n",
      "Epoch 712\n",
      "Epoch 713\n",
      "Epoch 714\n",
      "Epoch 715\n",
      "Epoch 716\n",
      "Epoch 717\n",
      "Epoch 718\n",
      "Epoch 719\n",
      "Epoch 720\n",
      "Epoch 721\n",
      "Epoch 722\n",
      "Epoch 723\n",
      "Epoch 724\n",
      "Epoch 725\n",
      "Epoch 726\n",
      "Epoch 727\n",
      "Epoch 728\n",
      "Epoch 729\n",
      "Epoch 730\n",
      "Epoch 731\n",
      "Epoch 732\n",
      "Epoch 733\n",
      "Epoch 734\n",
      "Epoch 735\n",
      "Epoch 736\n",
      "Epoch 737\n",
      "Epoch 738\n",
      "Epoch 739\n",
      "Epoch 740\n",
      "Epoch 741\n",
      "Epoch 742\n",
      "Epoch 743\n",
      "Epoch 744\n",
      "Epoch 745\n",
      "Epoch 746\n",
      "Epoch 747\n",
      "Epoch 748\n",
      "Epoch 749\n",
      "Epoch 750\n",
      "Epoch 751\n",
      "Epoch 752\n",
      "Epoch 753\n",
      "Epoch 754\n",
      "Epoch 755\n",
      "Epoch 756\n",
      "Epoch 757\n",
      "Epoch 758\n",
      "Epoch 759\n",
      "Epoch 760\n",
      "Epoch 761\n",
      "Epoch 762\n",
      "Epoch 763\n",
      "Epoch 764\n",
      "Epoch 765\n",
      "Epoch 766\n",
      "Epoch 767\n",
      "Epoch 768\n",
      "Epoch 769\n",
      "Epoch 770\n",
      "Epoch 771\n",
      "Epoch 772\n",
      "Epoch 773\n",
      "Epoch 774\n",
      "Epoch 775\n",
      "Epoch 776\n",
      "Epoch 777\n",
      "Epoch 778\n",
      "Epoch 779\n",
      "Epoch 780\n",
      "Epoch 781\n",
      "Epoch 782\n",
      "Epoch 783\n",
      "Epoch 784\n",
      "Epoch 785\n",
      "Epoch 786\n",
      "Epoch 787\n",
      "Epoch 788\n",
      "Epoch 789\n",
      "Epoch 790\n",
      "Epoch 791\n",
      "Epoch 792\n",
      "Epoch 793\n",
      "Epoch 794\n",
      "Epoch 795\n",
      "Epoch 796\n",
      "Epoch 797\n",
      "Epoch 798\n",
      "Epoch 799\n",
      "Epoch 800\n",
      "Epoch 801\n",
      "Epoch 802\n",
      "Epoch 803\n",
      "Epoch 804\n",
      "Epoch 805\n",
      "Epoch 806\n",
      "Epoch 807\n",
      "Epoch 808\n",
      "Epoch 809\n",
      "Epoch 810\n",
      "Epoch 811\n",
      "Epoch 812\n",
      "Epoch 813\n",
      "Epoch 814\n",
      "Epoch 815\n",
      "Epoch 816\n",
      "Epoch 817\n",
      "Epoch 818\n",
      "Epoch 819\n",
      "Epoch 820\n",
      "Epoch 821\n",
      "Epoch 822\n",
      "Epoch 823\n",
      "Epoch 824\n",
      "Epoch 825\n",
      "Epoch 826\n",
      "Epoch 827\n",
      "Epoch 828\n",
      "Epoch 829\n",
      "Epoch 830\n",
      "Epoch 831\n",
      "Epoch 832\n",
      "Epoch 833\n",
      "Epoch 834\n",
      "Epoch 835\n",
      "Epoch 836\n",
      "Epoch 837\n",
      "Epoch 838\n",
      "Epoch 839\n",
      "Epoch 840\n",
      "Epoch 841\n",
      "Epoch 842\n",
      "Epoch 843\n",
      "Epoch 844\n",
      "Epoch 845\n",
      "Epoch 846\n",
      "Epoch 847\n",
      "Epoch 848\n",
      "Epoch 849\n",
      "Epoch 850\n",
      "Epoch 851\n",
      "Epoch 852\n",
      "Epoch 853\n",
      "Epoch 854\n",
      "Epoch 855\n",
      "Epoch 856\n",
      "Epoch 857\n",
      "Epoch 858\n",
      "Epoch 859\n",
      "Epoch 860\n",
      "Epoch 861\n",
      "Epoch 862\n",
      "Epoch 863\n",
      "Epoch 864\n",
      "Epoch 865\n",
      "Epoch 866\n",
      "Epoch 867\n",
      "Epoch 868\n",
      "Epoch 869\n",
      "Epoch 870\n",
      "Epoch 871\n",
      "Epoch 872\n",
      "Epoch 873\n",
      "Epoch 874\n",
      "Epoch 875\n",
      "Epoch 876\n",
      "Epoch 877\n",
      "Epoch 878\n",
      "Epoch 879\n",
      "Epoch 880\n",
      "Epoch 881\n",
      "Epoch 882\n",
      "Epoch 883\n",
      "Epoch 884\n",
      "Epoch 885\n",
      "Epoch 886\n",
      "Epoch 887\n",
      "Epoch 888\n",
      "Epoch 889\n",
      "Epoch 890\n",
      "Epoch 891\n",
      "Epoch 892\n",
      "Epoch 893\n",
      "Epoch 894\n",
      "Epoch 895\n",
      "Epoch 896\n",
      "Epoch 897\n",
      "Epoch 898\n",
      "Epoch 899\n",
      "Epoch 900\n",
      "Epoch 901\n",
      "Epoch 902\n",
      "Epoch 903\n",
      "Epoch 904\n",
      "Epoch 905\n",
      "Epoch 906\n",
      "Epoch 907\n",
      "Epoch 908\n",
      "Epoch 909\n",
      "Epoch 910\n",
      "Epoch 911\n",
      "Epoch 912\n",
      "Epoch 913\n",
      "Epoch 914\n",
      "Epoch 915\n",
      "Epoch 916\n",
      "Epoch 917\n",
      "Epoch 918\n",
      "Epoch 919\n",
      "Epoch 920\n",
      "Epoch 921\n",
      "Epoch 922\n",
      "Epoch 923\n",
      "Epoch 924\n",
      "Epoch 925\n",
      "Epoch 926\n",
      "Epoch 927\n",
      "Epoch 928\n",
      "Epoch 929\n",
      "Epoch 930\n",
      "Epoch 931\n",
      "Epoch 932\n",
      "Epoch 933\n",
      "Epoch 934\n",
      "Epoch 935\n",
      "Epoch 936\n",
      "Epoch 937\n",
      "Epoch 938\n",
      "Epoch 939\n",
      "Epoch 940\n",
      "Epoch 941\n",
      "Epoch 942\n",
      "Epoch 943\n",
      "Epoch 944\n",
      "Epoch 945\n",
      "Epoch 946\n",
      "Epoch 947\n",
      "Epoch 948\n",
      "Epoch 949\n",
      "Epoch 950\n",
      "Epoch 951\n",
      "Epoch 952\n",
      "Epoch 953\n",
      "Epoch 954\n",
      "Epoch 955\n",
      "Epoch 956\n",
      "Epoch 957\n",
      "Epoch 958\n",
      "Epoch 959\n",
      "Epoch 960\n",
      "Epoch 961\n",
      "Epoch 962\n",
      "Epoch 963\n",
      "Epoch 964\n",
      "Epoch 965\n",
      "Epoch 966\n",
      "Epoch 967\n",
      "Epoch 968\n",
      "Epoch 969\n",
      "Epoch 970\n",
      "Epoch 971\n",
      "Epoch 972\n",
      "Epoch 973\n",
      "Epoch 974\n",
      "Epoch 975\n",
      "Epoch 976\n",
      "Epoch 977\n",
      "Epoch 978\n",
      "Epoch 979\n",
      "Epoch 980\n",
      "Epoch 981\n",
      "Epoch 982\n",
      "Epoch 983\n",
      "Epoch 984\n",
      "Epoch 985\n",
      "Epoch 986\n",
      "Epoch 987\n",
      "Epoch 988\n",
      "Epoch 989\n",
      "Epoch 990\n",
      "Epoch 991\n",
      "Epoch 992\n",
      "Epoch 993\n",
      "Epoch 994\n",
      "Epoch 995\n",
      "Epoch 996\n",
      "Epoch 997\n",
      "Epoch 998\n",
      "Epoch 999\n",
      "Train set precision at k (epochs 1000): 0.0012437811\n",
      "Test set precision at k (epochs 1000): 0.00020855057\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "hyperparameters = {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686, 'item_alpha': 9.259837751692955e-05*4, 'user_alpha': 7.950089746289809e-05*4, 'max_sampled': 9}\n",
    "model = LightFM(**hyperparameters)\n",
    "\n",
    "epochCount = 100\n",
    "\n",
    "for epoch in np.arange(100,110):\n",
    "    \n",
    "    if epoch == 100:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=100,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        \n",
    "        epochCount+=100\n",
    "        \n",
    "    else:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=(epoch-100 + 1)*100,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "\n",
    "        epochCount+=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1c09bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 50): 0.046915423\n",
      "Test set precision at k (epochs 50): 0.0012513035\n",
      "Train set AUC score (epochs 50): 0.99969804\n",
      "Test set AUC score (epochs 50): 0.7099136\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 100): 0.19514927\n",
      "Test set precision at k (epochs 100): 0.004629823\n",
      "Train set AUC score (epochs 100): 0.9998716\n",
      "Test set AUC score (epochs 100): 0.71110594\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 150): 0.32435328\n",
      "Test set precision at k (epochs 150): 0.0067153284\n",
      "Train set AUC score (epochs 150): 0.99991906\n",
      "Test set AUC score (epochs 150): 0.7128064\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 200): 0.4187811\n",
      "Test set precision at k (epochs 200): 0.0077580814\n",
      "Train set AUC score (epochs 200): 0.99994135\n",
      "Test set AUC score (epochs 200): 0.712951\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 250): 0.48945272\n",
      "Test set precision at k (epochs 250): 0.008759124\n",
      "Train set AUC score (epochs 250): 0.99995387\n",
      "Test set AUC score (epochs 250): 0.7126774\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 300): 0.54748756\n",
      "Test set precision at k (epochs 300): 0.009176225\n",
      "Train set AUC score (epochs 300): 0.9999628\n",
      "Test set AUC score (epochs 300): 0.7120267\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 350): 0.58828354\n",
      "Test set precision at k (epochs 350): 0.01084463\n",
      "Train set AUC score (epochs 350): 0.9999683\n",
      "Test set AUC score (epochs 350): 0.7123207\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 400): 0.6244776\n",
      "Test set precision at k (epochs 400): 0.010677789\n",
      "Train set AUC score (epochs 400): 0.9999726\n",
      "Test set AUC score (epochs 400): 0.71277004\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 450): 0.6545771\n",
      "Test set precision at k (epochs 450): 0.01080292\n",
      "Train set AUC score (epochs 450): 0.999976\n",
      "Test set AUC score (epochs 450): 0.7126785\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 500): 0.67654234\n",
      "Test set precision at k (epochs 500): 0.011762253\n",
      "Train set AUC score (epochs 500): 0.99997824\n",
      "Test set AUC score (epochs 500): 0.71270466\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 550): 0.6955971\n",
      "Test set precision at k (epochs 550): 0.011553702\n",
      "Train set AUC score (epochs 550): 0.9999803\n",
      "Test set AUC score (epochs 550): 0.71304756\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 600): 0.7124627\n",
      "Test set precision at k (epochs 600): 0.011887383\n",
      "Train set AUC score (epochs 600): 0.9999819\n",
      "Test set AUC score (epochs 600): 0.7133561\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 650): 0.72713935\n",
      "Test set precision at k (epochs 650): 0.012137644\n",
      "Train set AUC score (epochs 650): 0.9999835\n",
      "Test set AUC score (epochs 650): 0.71276987\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 700): 0.7419154\n",
      "Test set precision at k (epochs 700): 0.012012512\n",
      "Train set AUC score (epochs 700): 0.99998486\n",
      "Test set AUC score (epochs 700): 0.71287024\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 750): 0.74910456\n",
      "Test set precision at k (epochs 750): 0.012137644\n",
      "Train set AUC score (epochs 750): 0.9999857\n",
      "Test set AUC score (epochs 750): 0.7136285\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 800): 0.76159215\n",
      "Test set precision at k (epochs 800): 0.012513034\n",
      "Train set AUC score (epochs 800): 0.9999867\n",
      "Test set AUC score (epochs 800): 0.71379226\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 850): 0.76972646\n",
      "Test set precision at k (epochs 850): 0.012471325\n",
      "Train set AUC score (epochs 850): 0.9999875\n",
      "Test set AUC score (epochs 850): 0.7140563\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 900): 0.7784827\n",
      "Test set precision at k (epochs 900): 0.012471325\n",
      "Train set AUC score (epochs 900): 0.99998814\n",
      "Test set AUC score (epochs 900): 0.71351874\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 950): 0.78445286\n",
      "Test set precision at k (epochs 950): 0.012137644\n",
      "Train set AUC score (epochs 950): 0.99998885\n",
      "Test set AUC score (epochs 950): 0.7136043\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Train set precision at k (epochs 1000): 0.7899006\n",
      "Test set precision at k (epochs 1000): 0.012554745\n",
      "Train set AUC score (epochs 1000): 0.9999894\n",
      "Test set AUC score (epochs 1000): 0.7135953\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "# hyperparameters = {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8}\n",
    "hyperparameters = {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686, 'item_alpha': 9.259837751692955e-05, 'user_alpha': 7.950089746289809e-05, 'max_sampled': 9}\n",
    "model = LightFM(**hyperparameters)\n",
    "\n",
    "epochCount = 50\n",
    "\n",
    "for epoch in np.arange(50,70):\n",
    "    \n",
    "    if epoch == 50:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=50,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        \n",
    "        print(\"Train set AUC score (epochs {}):\".format(epochCount),auc_score(model, reviewSparseMatrix_train, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set AUC score (epochs {}):\".format(epochCount),auc_score(model, reviewSparseMatrix_test, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "\n",
    "        \n",
    "        epochCount+=50\n",
    "        \n",
    "    else:\n",
    "        model.fit_partial(reviewSparseMatrix_train,\n",
    "                      user_features=None,\n",
    "                      item_features=tagFeatures,\n",
    "                      epochs=50,\n",
    "                      num_threads=4, verbose=True)\n",
    "        print(\"Train set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_train, k=5, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set precision at k (epochs {}):\".format(epochCount),precision_at_k(model, reviewSparseMatrix_test, k=5, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        \n",
    "        print(\"Train set AUC score (epochs {}):\".format(epochCount),auc_score(model, reviewSparseMatrix_train, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "        print(\"Test set AUC score (epochs {}):\".format(epochCount),auc_score(model, reviewSparseMatrix_test, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "\n",
    "        \n",
    "        epochCount+=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "036daf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133906\n",
      "4.926427\n",
      "['Shadow Warrior 2: The Way of the Wang DLC', 'Resident Evil 6: Survivors Mode', 'Shadow of the Tomb Raider - Deluxe Extras', 'Homefront®: The Revolution - Aftermath', 'Homefront®: The Revolution - The Voice of Freedom']\n",
      "28391\n",
      "0.56334585\n",
      "['FreakOut: Extreme Freeride', 'Insurgency: Sandstorm - Hunter Weapon Skin Set', 'Motorcycle Club', 'Pinball FX3 - Jurassic World\\x99 Pinball', 'Jelly in the sky']\n",
      "132967\n",
      "3.1568534\n",
      "['Alien Worms Invasion', 'CAPSULE', 'The Cassir Simulator', 'Defense of Roman Britain', 'Deep Cave']\n",
      "26108\n",
      "4.1418567\n",
      "['Colour Bind', 'Jacob Jones and the Bigfoot Mystery : Episode 2', 'RoboBlitz', 'Jacob Jones and the Bigfoot Mystery : Episode 1', 'Paradox Wrench']\n",
      "9256\n",
      "3.213053\n",
      "['Dark Train', 'DARK SOULS\\x99 II Crown of the Old Iron King', 'Fallout 3 - Point Lookout', 'The Watchers', 'DARK SOULS\\x99 II Crown of the Sunken King']\n",
      "37699\n",
      "3.5606294\n",
      "['Konung 3: Ties of the Dynasty', 'Indeep | The casual dungeon crawler', 'Ruzar - The Life Stone - Challenge Map', 'The Deep Paths: Labyrinth Of Andokost', 'Mysterious Realms RPG']\n",
      "176525\n",
      "4.0350666\n",
      "['Depth - Legendary Hammerhead Skin', 'Depth - Reef Stalker Tiger Skin', 'theHunter: Call of the Wild\\x99 - Weapon Pack 3', 'Wreckfest - Reckless Car Pack', 'Toro']\n",
      "21543\n",
      "3.1802053\n",
      "['Left 4 Dead 2 Dedicated Server', 'A Walk in the Woods', 'Absent', 'Wick', 'Dead by Daylight - The Halloween® Chapter']\n",
      "45869\n",
      "2.6114028\n",
      "['Llama Villa', 'Pierhead Arcade', 'Pierhead Arcade 2', 'Build-A-Lot', 'VR Flight Simulator New York - Cessna']\n",
      "172055\n",
      "1.7420508\n",
      "['Sleeping Dogs: Definitive Edition', 'Control Ultimate Edition', 'Advent Rising', 'STAR WARS\\x99 Battlefront (Classic, 2004)', 'Mafia: Definitive Edition']\n"
     ]
    }
   ],
   "source": [
    "#Predict top game for userX\n",
    "import random\n",
    "\n",
    "user = 0\n",
    "numUsers = 10\n",
    "iteration = 0\n",
    "\n",
    "while user < numUsers:\n",
    "    userIDMap = dataset.mapping()[0]\n",
    "    itemIDMap = dataset.mapping()[2]\n",
    "\n",
    "    userX = random.choice(list(dataset.mapping()[0].values()))\n",
    "    \n",
    "    authorID = list(userIDMap.keys())[userX]\n",
    "    \n",
    "    if authorReviewsCount[authorID] >= 5:\n",
    "        print(userX)\n",
    "\n",
    "        scores = np.array(model.predict(np.repeat(userX,len(itemIDMap)),list(itemIDMap.values()), item_features=tagFeatures, user_features=None))\n",
    "\n",
    "        print(scores.max())\n",
    "\n",
    "        top5GamesBool = pd.Series(scores).nlargest(n=5).index\n",
    "\n",
    "        top5List = []\n",
    "        for top5Game in top5GamesBool:\n",
    "\n",
    "            game = rawGames[rawGames['appId'] == list(itemIDMap.keys())[list(itemIDMap.values()).index(top5Game)]]['name'].values[0]\n",
    "            top5List.append(game)\n",
    "\n",
    "        print(top5List)\n",
    "\n",
    "        user += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "992ab1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Krater']\n",
      "['FIVE: Champions of Canaan']\n",
      "['Unforgiving - A Northern Hymn']\n",
      "['Toren']\n",
      "['Titan Attacks!']\n"
     ]
    }
   ],
   "source": [
    "def listReviews(LightFM_ID):\n",
    "    authorID = list(dataset.mapping()[0].keys())[LightFM_ID]\n",
    "    app_ID = reviewsData[reviewsData['authorID'] == authorID]['appID']\n",
    "\n",
    "    for game in app_ID.values:\n",
    "        print(rawGames[rawGames['appId'] == game].name.values)\n",
    "        \n",
    "listReviews(9256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9ffa47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model performance\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "performanceScore = auc_score(model, reviewSparseMatrix_test, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4f41d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6633947"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(performanceScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2617505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 completed 563.5711710453033 seconds after start. Precision at k for this model: 7.007217936916277e-05\n",
      "Hyperparameters for this model: {'no_components': 26, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 7, 'n': 19, 'learning_rate': 0.2726513635735333, 'item_alpha': 1.4891160209682287e-06, 'user_alpha': 9.716922366584673e-05, 'max_sampled': 4, 'num_epochs': 40}\n",
      "Model 2 completed 1002.8846809864044 seconds after start. Precision at k for this model: 0.0022703385911881924\n",
      "Hyperparameters for this model: {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 27, 'learning_rate': 0.27356018665070686, 'item_alpha': 9.259837751692955e-05, 'user_alpha': 7.950089746289809e-05, 'max_sampled': 9, 'num_epochs': 56}\n",
      "Model 3 completed 1916.6710376739502 seconds after start. Precision at k for this model: 2.8028871383867227e-05\n",
      "Hyperparameters for this model: {'no_components': 47, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 2, 'n': 5, 'learning_rate': 0.26127223258662235, 'item_alpha': 9.406069559858596e-05, 'user_alpha': 6.733758004897056e-05, 'max_sampled': 11, 'num_epochs': 50}\n",
      "Model 4 completed 2263.7755455970764 seconds after start. Precision at k for this model: 1.4014435691933613e-05\n",
      "Hyperparameters for this model: {'no_components': 72, 'learning_schedule': 'adagrad', 'loss': 'logistic', 'k': 1, 'n': 26, 'learning_rate': 0.21071560156411936, 'item_alpha': 3.808406377630225e-05, 'user_alpha': 6.637941434233174e-06, 'max_sampled': 10, 'num_epochs': 25}\n",
      "Model 5 completed 2706.68701004982 seconds after start. Precision at k for this model: 2.8028871383867227e-05\n",
      "Hyperparameters for this model: {'no_components': 66, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 13, 'n': 27, 'learning_rate': 0.28935348303420766, 'item_alpha': 2.6165296527782202e-05, 'user_alpha': 6.662707514605996e-05, 'max_sampled': 10, 'num_epochs': 13}\n",
      "Model 6 completed 2977.4073259830475 seconds after start. Precision at k for this model: 0.0009950249223038554\n",
      "Hyperparameters for this model: {'no_components': 50, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 4, 'n': 9, 'learning_rate': 0.13753944800482323, 'item_alpha': 5.1572557218291465e-06, 'user_alpha': 2.2566610142666978e-05, 'max_sampled': 5, 'num_epochs': 28}\n",
      "Model 7 completed 3143.7433240413666 seconds after start. Precision at k for this model: 0.000462476396933198\n",
      "Hyperparameters for this model: {'no_components': 27, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 11, 'n': 22, 'learning_rate': 0.08261716685891142, 'item_alpha': 3.582056889224047e-05, 'user_alpha': 6.188739842454494e-05, 'max_sampled': 13, 'num_epochs': 9}\n",
      "Model 8 completed 4373.424315452576 seconds after start. Precision at k for this model: 0.00023824541131034493\n",
      "Hyperparameters for this model: {'no_components': 72, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 9, 'n': 15, 'learning_rate': 0.07134587286212271, 'item_alpha': 6.135437087532854e-05, 'user_alpha': 5.451028195522474e-05, 'max_sampled': 13, 'num_epochs': 59}\n",
      "Model 9 completed 4783.140146493912 seconds after start. Precision at k for this model: 1.4014435691933613e-05\n",
      "Hyperparameters for this model: {'no_components': 56, 'learning_schedule': 'adagrad', 'loss': 'logistic', 'k': 6, 'n': 18, 'learning_rate': 0.03938619058515492, 'item_alpha': 5.1545815296092305e-05, 'user_alpha': 3.3286861674664725e-05, 'max_sampled': 14, 'num_epochs': 55}\n",
      "Model 10 completed 5029.981768846512 seconds after start. Precision at k for this model: 1.4014435691933613e-05\n",
      "Hyperparameters for this model: {'no_components': 38, 'learning_schedule': 'adagrad', 'loss': 'logistic', 'k': 5, 'n': 20, 'learning_rate': 0.10867605328050703, 'item_alpha': 5.143730381663022e-05, 'user_alpha': 8.599429278062998e-05, 'max_sampled': 12, 'num_epochs': 43}\n",
      "Model 11 completed 5470.969014167786 seconds after start. Precision at k for this model: 0.00015415878442581743\n",
      "Hyperparameters for this model: {'no_components': 44, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 15, 'n': 28, 'learning_rate': 0.2934427894330971, 'item_alpha': 8.858232054722149e-06, 'user_alpha': 8.500043575374008e-05, 'max_sampled': 5, 'num_epochs': 38}\n",
      "Model 12 completed 5736.886682987213 seconds after start. Precision at k for this model: 8.408661960856989e-05\n",
      "Hyperparameters for this model: {'no_components': 48, 'learning_schedule': 'adadelta', 'loss': 'logistic', 'k': 21, 'n': 25, 'learning_rate': 0.023443876139448892, 'item_alpha': 5.971804753754899e-05, 'user_alpha': 9.19305060743103e-05, 'max_sampled': 4, 'num_epochs': 43}\n",
      "Model 13 completed 5938.642384529114 seconds after start. Precision at k for this model: 4.2043309804284945e-05\n",
      "Hyperparameters for this model: {'no_components': 16, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 1, 'n': 5, 'learning_rate': 0.10575474625363213, 'item_alpha': 5.295230128902773e-05, 'user_alpha': 5.051417123120362e-05, 'max_sampled': 4, 'num_epochs': 68}\n",
      "Model 14 completed 6086.820004940033 seconds after start. Precision at k for this model: 7.007217936916277e-05\n",
      "Hyperparameters for this model: {'no_components': 42, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 5, 'n': 19, 'learning_rate': 0.02858499812939261, 'item_alpha': 4.871760998645271e-05, 'user_alpha': 5.1411590136996656e-05, 'max_sampled': 7, 'num_epochs': 5}\n",
      "Model 15 completed 6196.380188465118 seconds after start. Precision at k for this model: 0.0006726928986608982\n",
      "Hyperparameters for this model: {'no_components': 23, 'learning_schedule': 'adagrad', 'loss': 'warp-kos', 'k': 2, 'n': 7, 'learning_rate': 0.22624600615492, 'item_alpha': 3.773851084326998e-05, 'user_alpha': 1.8964279518655892e-05, 'max_sampled': 9, 'num_epochs': 44}\n",
      "Model 16 completed 6397.031354427338 seconds after start. Precision at k for this model: 9.81010525720194e-05\n",
      "Hyperparameters for this model: {'no_components': 48, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 3, 'n': 15, 'learning_rate': 0.08430107727403502, 'item_alpha': 6.263009659024288e-06, 'user_alpha': 4.874595715802449e-05, 'max_sampled': 5, 'num_epochs': 11}\n",
      "Model 17 completed 6524.152082681656 seconds after start. Precision at k for this model: 9.81010525720194e-05\n",
      "Hyperparameters for this model: {'no_components': 17, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 18, 'n': 20, 'learning_rate': 0.16921592073842645, 'item_alpha': 1.7028221298434832e-05, 'user_alpha': 6.499371938829109e-05, 'max_sampled': 9, 'num_epochs': 25}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    \"\"\"\n",
    "    Yield possible hyperparameter choices.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        n = np.random.randint(5,30)\n",
    "        k = np.random.randint(1,n)\n",
    "        yield {\n",
    "            \"no_components\": np.random.randint(16, 84),\n",
    "            \"learning_schedule\": np.random.choice([\"adagrad\", \"adadelta\"]),\n",
    "            \"loss\": np.random.choice([\"logistic\",\"warp\", \"warp-kos\",\"bpr\"]),\n",
    "            \"k\": k,\n",
    "            \"n\": n,\n",
    "            \"learning_rate\": np.random.exponential(0.05),\n",
    "            \"item_alpha\": np.random.exponential(1e-8),\n",
    "            \"user_alpha\": np.random.exponential(1e-8),\n",
    "            \"max_sampled\": np.random.randint(2, 15),\n",
    "            \"num_epochs\": np.random.randint(5, 70),\n",
    "        }\n",
    "\n",
    "\n",
    "def random_search(train, trainLogistic, test, testLogistic, num_samples=20, num_threads=1):\n",
    "    \"\"\"\n",
    "    Sample random hyperparameters, fit a LightFM model, and evaluate it\n",
    "    on the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    train: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Training data.\n",
    "    test: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Test data.\n",
    "    num_samples: int, optional\n",
    "        Number of hyperparameter choices to evaluate.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    generator of (auc_score, hyperparameter dict, fitted model)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    models = 1\n",
    "    \n",
    "    for hyperparams in itertools.islice(sample_hyperparameters(), num_samples):\n",
    "        num_epochs = hyperparams.pop(\"num_epochs\")\n",
    "\n",
    "        model = LightFM(**hyperparams)\n",
    "        \n",
    "        if hyperparams['loss'] == 'logistic':\n",
    "            model.fit(trainLogistic, epochs=num_epochs, num_threads=num_threads, user_features=None, item_features=tagFeatures)\n",
    "\n",
    "            score = precision_at_k(model, testLogistic, k=15, train_interactions=trainLogistic, user_features=None, item_features=tagFeatures,num_threads=num_threads).mean()\n",
    "            \n",
    "            print('Model {} completed {} seconds after start. Precision at k for this model: {}'.format(models, time.time() - start,np.average(score)))\n",
    "            \n",
    "        else:\n",
    "            model.fit(train, epochs=num_epochs, num_threads=num_threads, user_features=None, item_features=tagFeatures)\n",
    "\n",
    "            score = precision_at_k(model, test, k=15, train_interactions=train, user_features=None, item_features=tagFeatures,num_threads=num_threads).mean()\n",
    "            \n",
    "            print('Model {} completed {} seconds after start. Precision at k for this model: {}'.format(models, time.time() - start,np.average(score)))\n",
    "     \n",
    "        hyperparams[\"num_epochs\"] = num_epochs\n",
    "\n",
    "        print('Hyperparameters for this model:',hyperparams)\n",
    "        \n",
    "        yield (score, hyperparams, model)\n",
    "        \n",
    "        models += 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = reviewSparseMatrix_train\n",
    "    test = reviewSparseMatrix_validation\n",
    "    \n",
    "    trainLogistic = reviewSparseMatrixLogistic_train\n",
    "    testLogistic = reviewSparseMatrixLogistic_validation\n",
    "\n",
    "    (score, hyperparams, model) = max(random_search(train, trainLogistic, test, testLogistic, num_threads=4), key=lambda x: x[0])\n",
    "\n",
    "    print(\"Best score {} at {}\".format(score, hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0775049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set AUC score: 0.87648803\n",
      "Test set AUC score: 0.561625\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set AUC score:\",auc_score(model, reviewSparseMatrix_train, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "print(\"Test set AUC score:\",auc_score(model, reviewSparseMatrix_test, train_interactions=reviewSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43548ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization results:\n",
    "#\n",
    "#Performances on dataset with cutoff at 10 reviews:\n",
    "#\n",
    "#(Number of models = 10) Best score 0.651569664478302 at {'no_components': 52, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.1527113318869582, 'item_alpha': 1.0645979288543401e-08, 'user_alpha': 1.111435154654254e-08, 'max_sampled': 14, 'num_epochs': 20}\n",
    "#\n",
    "#(Number of models = 100) Best score 0.6798270344734192 at {'no_components': 55, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'learning_rate': 0.14499587224888172, 'item_alpha': 2.449496687288527e-08, 'user_alpha': 3.5844794576049884e-08, 'max_sampled': 6, 'num_epochs': 37}\n",
    "#\n",
    "#Performances on dataset with no cutoff:\n",
    "#\n",
    "#(Number of models = 10) Best score 0.7345967292785645 at {'no_components': 44, 'learning_schedule': 'adagrad', 'loss': 'warp-kos', 'learning_rate': 0.009298331793000566, 'item_alpha': 8.897488524832826e-09, 'user_alpha': 1.6628688874535134e-09, 'max_sampled': 13, 'num_epochs': 26}\n",
    "#\n",
    "#Performances with two datasets, one for logistic loss, one for all other loss functions; no data cutoff.\n",
    "#\n",
    "#(Number of models = 50) ---------------------------\n",
    "#\n",
    "#Aborted run; I realized 'logistic' loss is not even considered in the hyperparameter grid!!\n",
    "#\n",
    "#Retrying after including 'logistic':\n",
    "#\n",
    "#(Number of models = 10) Best score 0.7065965533256531 at {'no_components': 62, 'learning_schedule': 'adagrad', 'loss': 'warp-kos', 'learning_rate': 0.0573779126646902, 'item_alpha': 1.0038960427872043e-08, 'user_alpha': 1.0230331754491065e-09, 'max_sampled': 7, 'num_epochs': 15}\n",
    "#\n",
    "#Performances with cutoff at 2 reviews:\n",
    "#\n",
    "#(Number of models = 10) Best score 0.6448951959609985 at {'no_components': 42, 'learning_schedule': 'adadelta', 'loss': 'warp', 'learning_rate': 0.06211345003561848, 'item_alpha': 1.7683031781962732e-09, 'user_alpha': 7.90888741439592e-09, 'max_sampled': 7, 'num_epochs': 42}\n",
    "#\n",
    "#Seems that removing the single-review data entries doesn't help.\n",
    "#Performances with no cutoff:\n",
    "#\n",
    "#(Number of models = 50) Best score 0.6859049201011658 at {'no_components': 73, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'learning_rate': 0.014584564881958832, 'item_alpha': 5.394639329463036e-10, 'user_alpha': 3.1028310995598514e-08, 'max_sampled': 7, 'num_epochs': 5}\n",
    "#\n",
    "#A decent result, but still not the best. I have two ideas for improving performance:\n",
    "# 1) The 'warp-kos' loss function seems to be doing well, but the hyperparameter grid is not randomizing 'k' or 'n'. It might be worthwhile to include k and n in the grid.\n",
    "# 2) We are so far only training the model with the interaction matrix, which means we are not fully exploiting the power of LightFM. To do better, I will construct user-feature and item-feature matrices to include in training.\n",
    "#\n",
    "#Performances with no cutoff, tags included in item_features, and numReviews included in user_features; also including n and k in hyperparameter grid.\n",
    "#\n",
    "#(Number of models = 10) Best score 0.8470107913017273 at {'no_components': 65, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 6, 'n': 12, 'learning_rate': 0.02928440331763431, 'item_alpha': 7.275228854163678e-09, 'user_alpha': 2.7338318258837908e-08, 'max_sampled': 10, 'num_epochs': 37}\n",
    "#\n",
    "#warp and warp-kOS outperform all other loss functions by a wide margin (0.3)! So I'll do another run with just those loss functions.\n",
    "#\n",
    "#(Number of models = 10) Best score 0.8526289463043213 at {'no_components': 72, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 3, 'n': 11, 'learning_rate': 0.1897451476865415, 'item_alpha': 3.0092438503624385e-09, 'user_alpha': 6.33702109340142e-08, 'max_sampled': 12, 'num_epochs': 28}\n",
    "#\n",
    "#Not bad, but not a big improvement. However, up to this point, I have not been optimizing on a validation set. I will implement this to make sure I am not getting any kind of train-test leakage.\n",
    "#\n",
    "#(Number of models = 10) Best score 0.8456214070320129 at {'no_components': 64, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 4, 'n': 16, 'learning_rate': 0.047083589797465575, 'item_alpha': 8.078502532221144e-09, 'user_alpha': 7.890520987668458e-10, 'max_sampled': 6, 'num_epochs': 26}\n",
    "#\n",
    "#The above is the best-performing model scored on the validation set.\n",
    "#The final model of the 10 had the following parameters and performance on the validation set: 0.8360676765441895 with the parameters {'no_components': 65, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 2, 'n': 17, 'learning_rate': 0.10304219169462017, 'item_alpha': 1.5928283813232654e-09, 'user_alpha': 1.6330383752596355e-09, 'max_sampled': 7}\n",
    "#Its predicitions on the test set gave a score of 0.84640944. So the model generalizes well and seems to not be overfitting!\n",
    "#\n",
    "#Unfortunately, the model appears to be predicting mostly the same items for every user. I suspect this is because I am fitting\n",
    "#with user features included; my user features are the number of reviews for each user, which may be inappropriate as the model\n",
    "#is likely treating users with similar numbers of reviews as having similar taste.\n",
    "#\n",
    "#I tried training without user features and got different results for each user! The bad news, however, is my AUC score is now only ~0.66.\n",
    "#That isn't the end of the world though. I can try to re-optimize the hyperparameters in the no-user-features condition and see how well I can do!\n",
    "#\n",
    "#(Number of models = 2) Best score 0.6793850064277649 at{'no_components': 80, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 1, 'n': 17, 'learning_rate': 0.03447291023596468, 'item_alpha': 4.218587807853474e-09, 'user_alpha': 1.0118587621171197e-09, 'max_sampled': 5}\n",
    "#\n",
    "#Terminated early. warp loss seems promising again after fixing things; however, now that I have fixed some issues with the model, I wonder if restricting the dataset to users who have reviewed more than X games and games that have been reviewed more than Y times, I might be able to improve the model accuracy.\n",
    "#\n",
    "#Performances with reviews per user >= 5 and reviews per game >= 5:\n",
    "#\n",
    "#(Number of models = 2) Best score 0.8397705554962158 at {'no_components': 51, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'k': 3, 'n': 13, 'learning_rate': 0.005281583069440484, 'item_alpha': 9.858565694780535e-09, 'user_alpha': 9.744293683760443e-09, 'max_sampled': 14}\n",
    "#\n",
    "#Back to high scores! I stopped early so I could check if it is giving unique recommendations to each user.\n",
    "#The model recommended similar things for all users. Not sure what the problem is.\n",
    "#\n",
    "#(Number of models = 1) Best score 0.8866572380065918 at {'no_components': 80, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 7, 'n': 15, 'learning_rate': 0.0033877415959418754, 'item_alpha': 1.904102913607403e-09, 'user_alpha': 7.227838565219844e-09, 'max_sampled': 6, 'num_epochs': 21}\n",
    "#\n",
    "#(Number of models = 10) Best score 0.7476821541786194 at {'no_components': 51, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 8, 'n': 19, 'learning_rate': 0.06907670508127313, 'item_alpha': 9.15443639916312e-09, 'user_alpha': 8.805455946727902e-09, 'max_sampled': 8, 'num_epochs': 41}\n",
    "#\n",
    "#It seems like I should be able to do better than AUC 0.75. Some recommenders are able to achieve >0.9 AUC score.\n",
    "#Based on this intuition, I decided to check for overfitting in this model. I got the following results:\n",
    "# Train set AUC score: 0.9993617\n",
    "# Test set AUC score: 0.7465831\n",
    "#I am obviously overfitting a great deal! Need to find a solution to this... perhaps k-fold cross validation?\n",
    "#But this would not get our test AUC score much higher. The problem seems to happen at the level of model fitting, not hyperparameter selection.\n",
    "#For that reason, I will first simply try restricting the number of epochs each model trains over.\n",
    "#\n",
    "#Now I've built a game features matrix that includes only the top 50 most popular tags. Let's see if this guards against overfitting.\n",
    "#\n",
    "#(Number of models = )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d18faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a38a7be",
   "metadata": {},
   "source": [
    "## Implicit Feedback\n",
    "I tried many different avenues with the review data. Overall, the model performance is not stellar. Of the models that give sensible results (i.e., models that do not recommend the same thing to almost every user), peak performance is at an AUC score of 0.7 or precision at k of 0.1. While searching for ways to improve the model, I came across this talk https://maciejkula.github.io/2018/07/19/dont-use-explicit-feedback-recommenders/ which references this paper https://dl.acm.org/doi/pdf/10.1145/1835804.1835895; both argue that implicit feedback recommender systems generally outperform explicit feedback systems which, like the models I produced above, are based on user ratings. The reason is essentially that user ratings of games are not a random sample of user interactions with games, and so give a biased impression of how other users are likely to rate the same game. With that in mind, I have scraped Steam again, this time acquiring a list of games owned by each user ID from the above dataset. This will create a denser interactions matrix with a more representative sample of user interactions and, if the above arguments are correct, should produce a trained model with better performance.\n",
    "\n",
    "Steam is very hesitant to allow heavy scraping of its user profile pages (possibly due to European privacy laws?). Anyway, it appears to allow one user ID's owned games list to be scraped every minute. It is slow-going, but I am able to obtain a large quantity of data this way. Each user I scrape has on average 1,000 user-item interactions, which is at least 100 times greater than what I had for the review data. So I am actually getting greater data quantity in addition to quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4cdcbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of user IDs to scrape over\n",
    "# csvFile = open('SteamUsersIDs.csv', 'w+')\n",
    "# writer = csv.writer(csvFile)\n",
    "# writer.writerow(['userID'])\n",
    "\n",
    "# for userID in reviewsData['authorID'].unique():\n",
    "#     writer.writerow([userID])\n",
    "    \n",
    "# csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "3adc02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ownedGames = pd.read_csv('SteamUsersInfo_2-15-2023.csv', encoding = \"ISO-8859-1\")\n",
    "ownedGames = ownedGames[ownedGames['ownedAppIDs'] != '[]'].reset_index(drop=True)\n",
    "\n",
    "#Turn string of lists into list of strings\n",
    "import ast\n",
    "\n",
    "userIDStrings = [str(user) for user in ownedGames['userID']]\n",
    "ownedGameLists = [ast.literal_eval(stringList) for stringList in ownedGames['ownedAppIDs'].values]\n",
    "\n",
    "ownedGames['userID'] = userIDStrings\n",
    "ownedGames['ownedAppIDs'] = ownedGameLists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "7b6f6996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>ownedAppIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>[594650, 578080, 892970, 1938090, 275850, 3593...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960265942</td>\n",
       "      <td>[1147690, 570, 4920, 1468260, 1454400, 848480,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960268765</td>\n",
       "      <td>[730, 10, 310950, 1097840, 550, 1172470, 11340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960269213</td>\n",
       "      <td>[440, 230410, 363970, 238960, 251570, 564710, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960269409</td>\n",
       "      <td>[570, 8930, 316010, 220200, 1286830, 203770, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>76561197970217405</td>\n",
       "      <td>[552990, 56400, 24960, 312370, 10190, 440, 728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>76561197970218004</td>\n",
       "      <td>[440, 218620, 1435790, 381210, 8930, 392110, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>76561197970218633</td>\n",
       "      <td>[440, 570, 1046930, 620, 4550, 240, 583950, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>76561197970221907</td>\n",
       "      <td>[1468260, 1546320, 550, 730, 486310, 363970, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>76561197970222247</td>\n",
       "      <td>[47810, 39120, 578080, 1245620, 8980, 335300, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2782 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userID                                        ownedAppIDs\n",
       "0     76561197960265841  [594650, 578080, 892970, 1938090, 275850, 3593...\n",
       "1     76561197960265942  [1147690, 570, 4920, 1468260, 1454400, 848480,...\n",
       "2     76561197960268765  [730, 10, 310950, 1097840, 550, 1172470, 11340...\n",
       "3     76561197960269213  [440, 230410, 363970, 238960, 251570, 564710, ...\n",
       "4     76561197960269409  [570, 8930, 316010, 220200, 1286830, 203770, 6...\n",
       "...                 ...                                                ...\n",
       "2777  76561197970217405  [552990, 56400, 24960, 312370, 10190, 440, 728...\n",
       "2778  76561197970218004  [440, 218620, 1435790, 381210, 8930, 392110, 4...\n",
       "2779  76561197970218633  [440, 570, 1046930, 620, 4550, 240, 583950, 20...\n",
       "2780  76561197970221907  [1468260, 1546320, 550, 730, 486310, 363970, 6...\n",
       "2781  76561197970222247  [47810, 39120, 578080, 1245620, 8980, 335300, ...\n",
       "\n",
       "[2782 rows x 2 columns]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ownedGames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30999d90",
   "metadata": {},
   "source": [
    "Here I'll add my Steam library, and perhaps my friends' libraries to make recommendations for me and them. It is necessary to include my information before fitting the model if I want to predict games for myself with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "97450b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>ownedAppIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>[594650, 578080, 892970, 1938090, 275850, 3593...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960265942</td>\n",
       "      <td>[1147690, 570, 4920, 1468260, 1454400, 848480,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960268765</td>\n",
       "      <td>[730, 10, 310950, 1097840, 550, 1172470, 11340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960269213</td>\n",
       "      <td>[440, 230410, 363970, 238960, 251570, 564710, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960269409</td>\n",
       "      <td>[570, 8930, 316010, 220200, 1286830, 203770, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>76561197970222247</td>\n",
       "      <td>[47810, 39120, 578080, 1245620, 8980, 335300, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>76561198030126834</td>\n",
       "      <td>[761890, 346110, 407530, 1086940, 228280, 2573...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>76561198832487444</td>\n",
       "      <td>[1172470, 892970, 1063730, 1085660, 435150, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>76561199152870578</td>\n",
       "      <td>[892970, 435150, 559650, 1330000, 1594940, 108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>76561198042764215</td>\n",
       "      <td>[550, 892970, 435150, 413150, 1343370, 1184140...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2786 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 userID                                        ownedAppIDs\n",
       "0     76561197960265841  [594650, 578080, 892970, 1938090, 275850, 3593...\n",
       "1     76561197960265942  [1147690, 570, 4920, 1468260, 1454400, 848480,...\n",
       "2     76561197960268765  [730, 10, 310950, 1097840, 550, 1172470, 11340...\n",
       "3     76561197960269213  [440, 230410, 363970, 238960, 251570, 564710, ...\n",
       "4     76561197960269409  [570, 8930, 316010, 220200, 1286830, 203770, 6...\n",
       "...                 ...                                                ...\n",
       "2781  76561197970222247  [47810, 39120, 578080, 1245620, 8980, 335300, ...\n",
       "2782  76561198030126834  [761890, 346110, 407530, 1086940, 228280, 2573...\n",
       "2783  76561198832487444  [1172470, 892970, 1063730, 1085660, 435150, 10...\n",
       "2784  76561199152870578  [892970, 435150, 559650, 1330000, 1594940, 108...\n",
       "2785  76561198042764215  [550, 892970, 435150, 413150, 1343370, 1184140...\n",
       "\n",
       "[2786 rows x 2 columns]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add my games list to the model and recommend games for me\n",
    "import ast\n",
    "\n",
    "gamesDataLists = [ast.literal_eval(open('myGamesData.txt','r').read()),\n",
    "                ast.literal_eval(open('JayGamesData.txt','r').read()),\n",
    "                ast.literal_eval(open('MaryGamesData.txt','r').read()),\n",
    "                ast.literal_eval(open('MicahGamesData.txt','r').read())]\n",
    "\n",
    "ourIDsList = ['76561198030126834','76561198832487444','76561199152870578','76561198042764215']\n",
    "\n",
    "for myGames, userID in zip(gamesDataLists,ourIDsList):\n",
    "\n",
    "    myGamesData = pd.DataFrame({})\n",
    "\n",
    "    myGamesData['userID'] = [userID]\n",
    "    myGamesData['ownedAppIDs'] = [myGames]\n",
    "\n",
    "    ownedGames = pd.concat([ownedGames,myGamesData],ignore_index=True)\n",
    "\n",
    "ownedGames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340059fc",
   "metadata": {},
   "source": [
    "Now I'll build the dataset and features matrices with LightFM before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "234c6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of all user-item interactions\n",
    "ownedGameInteractions = [];\n",
    "\n",
    "for user in ownedGames.iterrows():\n",
    "    for app in user[1]['ownedAppIDs']:\n",
    "        ownedGameInteractions.append({'userID': user[1]['userID'], 'ownedAppIDs': app})\n",
    "        \n",
    "ownedGameInteractionsData = pd.DataFrame(ownedGameInteractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "00b32cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List unique Steam apps in this dataset\n",
    "uniqueAppIDs = pd.Series([j for i in range(len(ownedGames.ownedAppIDs)) for j in ownedGames.ownedAppIDs[i]]).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "f2652a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54739"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniqueAppIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "11f8b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create game features dataframe for generating the item features matrix\n",
    "gameFeaturesImplicit = [];\n",
    "\n",
    "for game in uniqueAppIDs:\n",
    "    game = int(game)\n",
    "    gameTags = rawGames[rawGames['appId'] == game]['tagsList'].values\n",
    "    \n",
    "    if len(gameTags) == 0:\n",
    "        gameFeaturesImplicit.append({'appID': str(game), 'tag': gameTags})\n",
    "        \n",
    "    else:\n",
    "        gameFeaturesImplicit.append({'appID': str(game), 'tag': gameTags[0]})\n",
    "        \n",
    "gameFeaturesDataImplicit = pd.DataFrame.from_dict(gameFeaturesImplicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "7d95c31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appID</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>594650</td>\n",
       "      <td>[Hunting, Dark, Tactical, FPS, Multiplayer, Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>578080</td>\n",
       "      <td>[Survival, Shooter, Multiplayer, Battle Royale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>892970</td>\n",
       "      <td>[Open World Survival Craft, Survival, Online C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1938090</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>275850</td>\n",
       "      <td>[Open World, Open World Survival Craft, Space,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54734</th>\n",
       "      <td>1940340</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54735</th>\n",
       "      <td>670060</td>\n",
       "      <td>[Action, Indie, Adventure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54736</th>\n",
       "      <td>737390</td>\n",
       "      <td>[Action, Massively Multiplayer, Indie, Early A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54737</th>\n",
       "      <td>906480</td>\n",
       "      <td>[Indie, Action, Adventure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54738</th>\n",
       "      <td>1231120</td>\n",
       "      <td>[Casual, Strategy, Indie, Puzzle, Puzzle Platf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54739 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         appID                                                tag\n",
       "0       594650  [Hunting, Dark, Tactical, FPS, Multiplayer, Ho...\n",
       "1       578080  [Survival, Shooter, Multiplayer, Battle Royale...\n",
       "2       892970  [Open World Survival Craft, Survival, Online C...\n",
       "3      1938090                                                 []\n",
       "4       275850  [Open World, Open World Survival Craft, Space,...\n",
       "...        ...                                                ...\n",
       "54734  1940340                                                 []\n",
       "54735   670060                         [Action, Indie, Adventure]\n",
       "54736   737390  [Action, Massively Multiplayer, Indie, Early A...\n",
       "54737   906480                         [Indie, Action, Adventure]\n",
       "54738  1231120  [Casual, Strategy, Indie, Puzzle, Puzzle Platf...\n",
       "\n",
       "[54739 rows x 2 columns]"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gameFeaturesDataImplicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "67fcd897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add tags to feature mapping\n",
    "from lightfm.data import Dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "dataset.fit_partial(users=ownedGames.userID.values.tolist(),\n",
    "                    user_features=None,\n",
    "                    items=uniqueAppIDs,\n",
    "                    item_features=uniqueTagNames)\n",
    "\n",
    "tagFeatures = dataset.build_item_features([(gameFeature[1]['appID'],\n",
    "                                            gameFeature[1]['tag'])\n",
    "                                            for gameFeature in gameFeaturesDataImplicit.iterrows()],normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "85d0656b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>ownedAppIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>594650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>578080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>892970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>1938090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561197960265841</td>\n",
       "      <td>275850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926009</th>\n",
       "      <td>76561198042764215</td>\n",
       "      <td>488790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926010</th>\n",
       "      <td>76561198042764215</td>\n",
       "      <td>329430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926011</th>\n",
       "      <td>76561198042764215</td>\n",
       "      <td>22320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926012</th>\n",
       "      <td>76561198042764215</td>\n",
       "      <td>292030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926013</th>\n",
       "      <td>76561198042764215</td>\n",
       "      <td>823130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2926014 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    userID ownedAppIDs\n",
       "0        76561197960265841      594650\n",
       "1        76561197960265841      578080\n",
       "2        76561197960265841      892970\n",
       "3        76561197960265841     1938090\n",
       "4        76561197960265841      275850\n",
       "...                    ...         ...\n",
       "2926009  76561198042764215      488790\n",
       "2926010  76561198042764215      329430\n",
       "2926011  76561198042764215       22320\n",
       "2926012  76561198042764215      292030\n",
       "2926013  76561198042764215      823130\n",
       "\n",
       "[2926014 rows x 2 columns]"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ownedGameInteractionsData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0443700a",
   "metadata": {},
   "source": [
    "I've had some trouble with this model recommending games more for their popularity rather than tailoring its predicitons to the user's specific taste. For that reason, I'm going to weight the interactions matrix entries by the inverse of the number of users who own each app (removing item biases can also fix this problem https://making.lyst.com/lightfm/docs/faq.html). I'll start by using pandas.value_counts() to get a Series containing the numbers of users who own each app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "ec098974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10         2638\n",
       "70         2602\n",
       "130        2584\n",
       "50         2583\n",
       "340        2579\n",
       "           ... \n",
       "1155860       1\n",
       "1055770       1\n",
       "1991950       1\n",
       "1853810       1\n",
       "1231120       1\n",
       "Name: ownedAppIDs, Length: 54739, dtype: int64"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construct weights for inverse popularity weighting\n",
    "inverseWeights = ownedGameInteractionsData['ownedAppIDs'].value_counts()\n",
    "inverseWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f634e69",
   "metadata": {},
   "source": [
    "Now that I have the value counts, it might be interesting to compare the distribution of owned games to the distribution of reviewed games. We should expect the owned games distribution to be a different shape since, as argued above, the set of reviewed games is not a random sample of the set of owned games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "96f37fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of owned games')"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Histogram of numbers of games owned by users\n",
    "userCounts = ownedGameInteractionsData['userID'].value_counts();\n",
    "\n",
    "plt.hist(userCounts.values, bins = 300);\n",
    "\n",
    "plt.xlim(0,5000)\n",
    "plt.ylabel('Number of users')\n",
    "plt.xlabel('Number of owned games')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858cb36f",
   "metadata": {},
   "source": [
    "As anticipated, we get a different distribution. Both distributions look like they could be log-normal, but the owned games distribution's mode is shifted much further to the right.\n",
    "\n",
    "Now we're gonna check for what precision at k we can reasonably expect for a given train-test split fraction. This is computationally difficult at large numbers of reviews, so I'll need to use a Gaussian distribution above a certain number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "87f2f7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('8.11367E+44')"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decimal import *\n",
    "getcontext().prec = 6\n",
    "\n",
    "Decimal(336)**Decimal(316).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "0d6e275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 1 randomly sampled users: 0.0999995\n",
      "34\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 2 randomly sampled users: 0.100000\n",
      "579\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285183\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197042\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70772E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31054E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 3 randomly sampled users: 0.100000\n",
      "331\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897791\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42255E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 4 randomly sampled users: 0.100000\n",
      "321\n",
      "New user!!\n",
      "prob_nTop: 0.270174\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 5 randomly sampled users: 0.100000\n",
      "3140\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285176\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897792\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355771\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644208\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15491E-12\n",
      "prob_nTop: 3.17883E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99995E-21\n",
      "Expected precision at k based on 6 randomly sampled users: 0.100001\n",
      "236\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285182\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197042\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 7 randomly sampled users: 0.100001\n",
      "1954\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285184\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886700\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15500E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 8 randomly sampled users: 0.100002\n",
      "518\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886707\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355779\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05989E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 9 randomly sampled users: 0.100002\n",
      "786\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886700\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50708E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70772E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31063E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 10 randomly sampled users: 0.100002\n",
      "706\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319209\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527079\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70772E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 11 randomly sampled users: 0.100002\n",
      "761\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190123\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42262E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 12 randomly sampled users: 0.100002\n",
      "1592\n",
      "New user!!\n",
      "prob_nTop: 0.270167\n",
      "prob_nTop: 0.285182\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197049\n",
      "prob_nTop: 0.000355774\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644201\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 13 randomly sampled users: 0.100003\n",
      "1091\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319210\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197048\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50707E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17876E-13\n",
      "prob_nTop: 8.31056E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 14 randomly sampled users: 0.100003\n",
      "220\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 15 randomly sampled users: 0.100003\n",
      "185\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 16 randomly sampled users: 0.100003\n",
      "530\n",
      "New user!!\n",
      "prob_nTop: 0.270174\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644201\n",
      "prob_nTop: 6.50715E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 17 randomly sampled users: 0.100004\n",
      "2794\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285174\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319210\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355782\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50708E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 18 randomly sampled users: 0.100003\n",
      "1043\n",
      "New user!!\n",
      "prob_nTop: 0.270167\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70771E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53896E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 9.99995E-21\n",
      "Expected precision at k based on 19 randomly sampled users: 0.100003\n",
      "1002\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53902E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 20 randomly sampled users: 0.100003\n",
      "510\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53896E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 21 randomly sampled users: 0.100003\n",
      "176\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50714E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15498E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80002E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 22 randomly sampled users: 0.100003\n",
      "369\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897784\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31065E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 23 randomly sampled users: 0.100003\n",
      "305\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897791\n",
      "prob_nTop: 0.0319215\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79995E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 24 randomly sampled users: 0.100003\n",
      "411\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897792\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 25 randomly sampled users: 0.100003\n",
      "432\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15498E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 26 randomly sampled users: 0.100003\n",
      "524\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897784\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70772E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 27 randomly sampled users: 0.100004\n",
      "935\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886708\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644200\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42262E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15492E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 28 randomly sampled users: 0.100004\n",
      "320\n",
      "New user!!\n",
      "prob_nTop: 0.270174\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05989E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 29 randomly sampled users: 0.100003\n",
      "688\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 30 randomly sampled users: 0.100004\n",
      "372\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644207\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05989E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 31 randomly sampled users: 0.100004\n",
      "1114\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53902E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 32 randomly sampled users: 0.100004\n",
      "326\n",
      "New user!!\n",
      "prob_nTop: 0.270173\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197042\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 33 randomly sampled users: 0.100004\n",
      "1242\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527072\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15492E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53902E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 34 randomly sampled users: 0.100004\n",
      "196\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285182\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50708E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 35 randomly sampled users: 0.100004\n",
      "781\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15498E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31056E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 36 randomly sampled users: 0.100004\n",
      "127\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53903E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 37 randomly sampled users: 0.100004\n",
      "2636\n",
      "New user!!\n",
      "prob_nTop: 0.270167\n",
      "prob_nTop: 0.285184\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897792\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644197\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15490E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31054E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 38 randomly sampled users: 0.100004\n",
      "1234\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897784\n",
      "prob_nTop: 0.0319217\n",
      "prob_nTop: 0.00886700\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644207\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 39 randomly sampled users: 0.100004\n",
      "798\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897791\n",
      "prob_nTop: 0.0319216\n",
      "prob_nTop: 0.00886707\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70780E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 40 randomly sampled users: 0.100004\n",
      "1545\n",
      "New user!!\n",
      "prob_nTop: 0.270166\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42255E-8\n",
      "prob_nTop: 3.70771E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15491E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 41 randomly sampled users: 0.100004\n",
      "309\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319209\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527080\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 42 randomly sampled users: 0.100004\n",
      "123\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80002E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 43 randomly sampled users: 0.100004\n",
      "73\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285182\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319215\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 44 randomly sampled users: 0.100004\n",
      "1041\n",
      "New user!!\n",
      "prob_nTop: 0.270174\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897791\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197048\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527079\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 45 randomly sampled users: 0.100004\n",
      "758\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 46 randomly sampled users: 0.100004\n",
      "851\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644198\n",
      "prob_nTop: 6.50714E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15499E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 47 randomly sampled users: 0.100004\n",
      "774\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319209\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197040\n",
      "prob_nTop: 0.000355772\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50707E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53902E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 48 randomly sampled users: 0.100004\n",
      "1991\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70777E-9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 49 randomly sampled users: 0.100004\n",
      "1787\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886707\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42254E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05991E-10\n",
      "prob_nTop: 9.15498E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31056E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 50 randomly sampled users: 0.100003\n",
      "675\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897784\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355772\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644207\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 51 randomly sampled users: 0.100002\n",
      "929\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319210\n",
      "prob_nTop: 0.00886708\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355772\n",
      "prob_nTop: 0.0000527068\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31056E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80002E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 52 randomly sampled users: 0.100001\n",
      "903\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319209\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527080\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 53 randomly sampled users: 0.100\n",
      "155\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 54 randomly sampled users: 0.0999991\n",
      "647\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285176\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99995E-21\n",
      "Expected precision at k based on 55 randomly sampled users: 0.0999982\n",
      "553\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285182\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80003E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 56 randomly sampled users: 0.0999973\n",
      "507\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53904E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 57 randomly sampled users: 0.0999965\n",
      "2072\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285175\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355774\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05989E-10\n",
      "prob_nTop: 9.15499E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79994E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 58 randomly sampled users: 0.0999957\n",
      "1493\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285173\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897784\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31063E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 59 randomly sampled users: 0.0999949\n",
      "49\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17881E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 60 randomly sampled users: 0.0999942\n",
      "166\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 61 randomly sampled users: 0.0999934\n",
      "852\n",
      "New user!!\n",
      "prob_nTop: 0.270173\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886707\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79996E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 62 randomly sampled users: 0.0999927\n",
      "263\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319215\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50714E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99996E-21\n",
      "Expected precision at k based on 63 randomly sampled users: 0.0999921\n",
      "1718\n",
      "New user!!\n",
      "prob_nTop: 0.270174\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197048\n",
      "prob_nTop: 0.000355779\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15493E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 64 randomly sampled users: 0.0999914\n",
      "912\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886709\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 65 randomly sampled users: 0.0999908\n",
      "289\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50708E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15499E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 66 randomly sampled users: 0.0999902\n",
      "2651\n",
      "New user!!\n",
      "prob_nTop: 0.270174\n",
      "prob_nTop: 0.285175\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886698\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15492E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53902E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99996E-21\n",
      "Expected precision at k based on 67 randomly sampled users: 0.0999896\n",
      "759\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897792\n",
      "prob_nTop: 0.0319215\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42262E-8\n",
      "prob_nTop: 3.70779E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 68 randomly sampled users: 0.0999890\n",
      "509\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 69 randomly sampled users: 0.0999884\n",
      "174\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42262E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 70 randomly sampled users: 0.0999879\n",
      "1883\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897786\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15501E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 71 randomly sampled users: 0.0999873\n",
      "277\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285181\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80003E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 72 randomly sampled users: 0.0999868\n",
      "6878\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897783\n",
      "prob_nTop: 0.0319217\n",
      "prob_nTop: 0.00886700\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355768\n",
      "prob_nTop: 0.0000527072\n",
      "prob_nTop: 0.00000644201\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70770E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15500E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53894E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99996E-21\n",
      "Expected precision at k based on 73 randomly sampled users: 0.0999863\n",
      "1936\n",
      "New user!!\n",
      "prob_nTop: 0.270175\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644206\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05989E-10\n",
      "prob_nTop: 9.15499E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 74 randomly sampled users: 0.0999858\n",
      "4728\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285173\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897792\n",
      "prob_nTop: 0.0319216\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50708E-7\n",
      "prob_nTop: 5.42256E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05982E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17883E-13\n",
      "prob_nTop: 8.31065E-15\n",
      "prob_nTop: 1.53896E-16\n",
      "prob_nTop: 1.80005E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 75 randomly sampled users: 0.0999853\n",
      "152\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319215\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 76 randomly sampled users: 0.0999849\n",
      "272\n",
      "New user!!\n",
      "prob_nTop: 0.270172\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319215\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05983E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79996E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 77 randomly sampled users: 0.0999844\n",
      "680\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644199\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15499E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31063E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 78 randomly sampled users: 0.0999840\n",
      "225\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197046\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644207\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 79 randomly sampled users: 0.0999835\n",
      "154\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15499E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 80 randomly sampled users: 0.0999831\n",
      "357\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99995E-21\n",
      "Expected precision at k based on 81 randomly sampled users: 0.0999827\n",
      "1069\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190116\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886707\n",
      "prob_nTop: 0.00197043\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50707E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53903E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 9.99995E-21\n",
      "Expected precision at k based on 82 randomly sampled users: 0.0999823\n",
      "191\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190122\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197048\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31063E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99996E-21\n",
      "Expected precision at k based on 83 randomly sampled users: 0.0999819\n",
      "353\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190121\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197041\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31057E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 84 randomly sampled users: 0.0999815\n",
      "548\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644201\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42260E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 85 randomly sampled users: 0.0999812\n",
      "510\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886702\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644203\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53896E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 86 randomly sampled users: 0.0999808\n",
      "455\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50713E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31062E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 87 randomly sampled users: 0.0999805\n",
      "662\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285182\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05985E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17875E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 88 randomly sampled users: 0.0999801\n",
      "943\n",
      "New user!!\n",
      "prob_nTop: 0.270173\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319217\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 89 randomly sampled users: 0.0999798\n",
      "632\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886705\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355776\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50707E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53901E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 90 randomly sampled users: 0.0999794\n",
      "1584\n",
      "New user!!\n",
      "prob_nTop: 0.270173\n",
      "prob_nTop: 0.285176\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897790\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886700\n",
      "prob_nTop: 0.00197049\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644207\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42257E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99999E-21\n",
      "Expected precision at k based on 91 randomly sampled users: 0.0999791\n",
      "581\n",
      "New user!!\n",
      "prob_nTop: 0.270168\n",
      "prob_nTop: 0.285177\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886703\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527076\n",
      "prob_nTop: 0.00000644207\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42263E-8\n",
      "prob_nTop: 3.70778E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17880E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.80001E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 92 randomly sampled users: 0.0999788\n",
      "330\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319214\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527073\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50712E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15497E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79996E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 93 randomly sampled users: 0.0999785\n",
      "1046\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285175\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319210\n",
      "prob_nTop: 0.00886700\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355777\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644208\n",
      "prob_nTop: 6.50708E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70777E-9\n",
      "prob_nTop: 2.05988E-10\n",
      "prob_nTop: 9.15491E-12\n",
      "prob_nTop: 3.17882E-13\n",
      "prob_nTop: 8.31059E-15\n",
      "prob_nTop: 1.53897E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 9.99996E-21\n",
      "Expected precision at k based on 94 randomly sampled users: 0.0999782\n",
      "1847\n",
      "New user!!\n",
      "prob_nTop: 0.270167\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886706\n",
      "prob_nTop: 0.00197044\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527078\n",
      "prob_nTop: 0.00000644205\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70773E-9\n",
      "prob_nTop: 2.05984E-10\n",
      "prob_nTop: 9.15496E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31054E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.79997E-18\n",
      "prob_nTop: 9.99996E-21\n",
      "Expected precision at k based on 95 randomly sampled users: 0.0999779\n",
      "4\n",
      "New user!!\n",
      "prob_nTop: 0.343900\n",
      "prob_nTop: 0.0523000\n",
      "prob_nTop: 0.00370000\n",
      "prob_nTop: 0.000100000\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "prob_nTop: 0\n",
      "Expected precision at k based on 96 randomly sampled users: 0.0991760\n",
      "622\n",
      "New user!!\n",
      "prob_nTop: 0.270169\n",
      "prob_nTop: 0.285178\n",
      "prob_nTop: 0.190118\n",
      "prob_nTop: 0.0897785\n",
      "prob_nTop: 0.0319213\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197048\n",
      "prob_nTop: 0.000355780\n",
      "prob_nTop: 0.0000527074\n",
      "prob_nTop: 0.00000644201\n",
      "prob_nTop: 6.50709E-7\n",
      "prob_nTop: 5.42262E-8\n",
      "prob_nTop: 3.70774E-9\n",
      "prob_nTop: 2.05989E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53898E-16\n",
      "prob_nTop: 1.79999E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 97 randomly sampled users: 0.0991840\n",
      "556\n",
      "New user!!\n",
      "prob_nTop: 0.270171\n",
      "prob_nTop: 0.285180\n",
      "prob_nTop: 0.190119\n",
      "prob_nTop: 0.0897787\n",
      "prob_nTop: 0.0319210\n",
      "prob_nTop: 0.00886704\n",
      "prob_nTop: 0.00197045\n",
      "prob_nTop: 0.000355773\n",
      "prob_nTop: 0.0000527077\n",
      "prob_nTop: 0.00000644201\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42259E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05986E-10\n",
      "prob_nTop: 9.15494E-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob_nTop: 3.17879E-13\n",
      "prob_nTop: 8.31058E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80000E-18\n",
      "prob_nTop: 1.00000E-20\n",
      "Expected precision at k based on 98 randomly sampled users: 0.0991918\n",
      "407\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190117\n",
      "prob_nTop: 0.0897789\n",
      "prob_nTop: 0.0319211\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355778\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644202\n",
      "prob_nTop: 6.50710E-7\n",
      "prob_nTop: 5.42258E-8\n",
      "prob_nTop: 3.70775E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15495E-12\n",
      "prob_nTop: 3.17878E-13\n",
      "prob_nTop: 8.31060E-15\n",
      "prob_nTop: 1.53900E-16\n",
      "prob_nTop: 1.80002E-18\n",
      "prob_nTop: 9.99998E-21\n",
      "Expected precision at k based on 99 randomly sampled users: 0.0991995\n",
      "378\n",
      "New user!!\n",
      "prob_nTop: 0.270170\n",
      "prob_nTop: 0.285179\n",
      "prob_nTop: 0.190120\n",
      "prob_nTop: 0.0897788\n",
      "prob_nTop: 0.0319212\n",
      "prob_nTop: 0.00886701\n",
      "prob_nTop: 0.00197047\n",
      "prob_nTop: 0.000355775\n",
      "prob_nTop: 0.0000527075\n",
      "prob_nTop: 0.00000644204\n",
      "prob_nTop: 6.50711E-7\n",
      "prob_nTop: 5.42261E-8\n",
      "prob_nTop: 3.70776E-9\n",
      "prob_nTop: 2.05987E-10\n",
      "prob_nTop: 9.15494E-12\n",
      "prob_nTop: 3.17877E-13\n",
      "prob_nTop: 8.31061E-15\n",
      "prob_nTop: 1.53899E-16\n",
      "prob_nTop: 1.79998E-18\n",
      "prob_nTop: 9.99997E-21\n",
      "Expected precision at k based on 100 randomly sampled users: 0.099207\n"
     ]
    }
   ],
   "source": [
    "from decimal import *\n",
    "import math\n",
    "\n",
    "getcontext().prec = 6\n",
    "\n",
    "kValue = 20\n",
    "splitFraction = Decimal(0.10)\n",
    "euler = Decimal(np.exp(1))\n",
    "\n",
    "#Pick random sample of user's owned game counts to average over\n",
    "randomUserCounts= userCounts.sample(n=100, random_state=42).values\n",
    "\n",
    "usersCounted = 0\n",
    "expectedPrecisionAtK = 0\n",
    "\n",
    "expected_nTop = 0\n",
    "\n",
    "for N in randomUserCounts:\n",
    "    N = N.item()\n",
    "    print(N)\n",
    "    \n",
    "    Nfac = Decimal(factorial(N))\n",
    "    print('New user!!')\n",
    "    for nTop in range(1,kValue+1):\n",
    "        \n",
    "        prob_nTop = 0\n",
    "        \n",
    "        for nC in range(nTop,N+1):\n",
    "#             print(user[1]-kValue)\n",
    "#             print(nC-nTop)\n",
    "            startTime = time.time()\n",
    "            numNotChosen = N-kValue-(nC-nTop)\n",
    "            \n",
    "            if nC > N-kValue and nTop <= nC-(N-kValue):\n",
    "                prob_nTop += Decimal(math.comb(N,nC))*splitFraction**Decimal(nC)*(1-splitFraction)**Decimal(N - nC)\n",
    "            \n",
    "            else:\n",
    "                prob_nTop += Decimal(math.comb(N-kValue,nC-nTop))*Decimal(math.comb(kValue,nTop))*splitFraction**Decimal(nC)*(1-splitFraction)**Decimal(N - nC)\n",
    "#                 if nC == nTop:\n",
    "#                     print('Hypergeometric prob:',Decimal(math.comb(N-kValue,nC-nTop))*Decimal(math.comb(kValue,nTop))/Decimal(math.comb(N,nC)))\n",
    "                \n",
    "#             print(time.time()-startTime)\n",
    "            \n",
    "#             print(prob_nTop)\n",
    "        print('prob_nTop:',prob_nTop)\n",
    "        expected_nTop += nTop*prob_nTop\n",
    "        \n",
    "    usersCounted += 1\n",
    "    \n",
    "#     print('expected_nTop:',expected_nTop)\n",
    "    \n",
    "#     print(expected_nTop)\n",
    "#     print(kValue)\n",
    "#     print(usersCounted)\n",
    "    \n",
    "    expectedPrecisionAtK = expected_nTop/kValue/usersCounted \n",
    "    print('Expected precision at k based on {} randomly sampled users:'.format(usersCounted),expectedPrecisionAtK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac99c72",
   "metadata": {},
   "source": [
    "I digress. Now I will build the interactions matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "6adc7503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('8655577598126739396236735036072208081204794589775815018544508256693025219489380097628852320463375366466345287569524796274808382414891999842312830623136802028067007430639699299020497185610570810212749031968132110813561295548441587529128294789399125630804600109428539364737024')"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decimal(4**455)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "6cc17f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.301920908769688e-41"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "336**326/336**336*0.1**0*0.9**336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "0f3ed2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now build the interaction COO matrix\n",
    "(ownedGamesSparseMatrix, weights) = dataset.build_interactions(((ownedGameInteractionsData['userID'].iloc[index],\n",
    "                                                             ownedGameInteractionsData['ownedAppIDs'].iloc[index],\n",
    "                                                             1/inverseWeights.loc[ownedGameInteractionsData['ownedAppIDs'].iloc[index]])\n",
    "                                                             for index in ownedGameInteractionsData.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "bed98f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "\n",
    "ownedGamesSparseMatrix_train, ownedGamesSparseMatrix_nontrain = random_train_test_split(ownedGamesSparseMatrix, random_state=43)\n",
    "\n",
    "ownedGamesSparseMatrix_validation, ownedGamesSparseMatrix_test = random_train_test_split(ownedGamesSparseMatrix_nontrain, random_state=43,test_percentage=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "5ecfe330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<2786x54739 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 2926014 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(ownedGamesSparseMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c6a92",
   "metadata": {},
   "source": [
    "Now to try optimizing the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f7e29334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 completed 12497.905975341797 seconds after start. Precision at k for this model: 0.09186893701553345\n",
      "Validation set AUC score: 0.9177789\n",
      "Hyperparameters for this model: {'no_components': 66, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'k': 9, 'n': 12, 'learning_rate': 0.06711781702176897, 'item_alpha': 4.470250757270699e-09, 'user_alpha': 1.821033935951774e-08, 'max_sampled': 12, 'num_epochs': 40}\n",
      "Model 2 completed 16472.970821619034 seconds after start. Precision at k for this model: 0.05129450187087059\n",
      "Validation set AUC score: 0.86928076\n",
      "Hyperparameters for this model: {'no_components': 47, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'k': 2, 'n': 20, 'learning_rate': 0.016014155903470186, 'item_alpha': 1.0072773369157902e-08, 'user_alpha': 1.10029520557898e-08, 'max_sampled': 13, 'num_epochs': 47}\n",
      "Model 3 completed 17375.496042490005 seconds after start. Precision at k for this model: 0.039279937744140625\n",
      "Validation set AUC score: 0.8673426\n",
      "Hyperparameters for this model: {'no_components': 56, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 15, 'n': 24, 'learning_rate': 0.0017932934348756338, 'item_alpha': 1.0566543728891213e-08, 'user_alpha': 1.627948431925102e-09, 'max_sampled': 5, 'num_epochs': 11}\n",
      "Model 4 completed 18984.694443941116 seconds after start. Precision at k for this model: 0.2591423988342285\n",
      "Validation set AUC score: 0.9647042\n",
      "Hyperparameters for this model: {'no_components': 50, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 4, 'n': 14, 'learning_rate': 0.039164526218823034, 'item_alpha': 2.273991987673798e-09, 'user_alpha': 8.340800036266309e-09, 'max_sampled': 12, 'num_epochs': 29}\n",
      "Model 5 completed 19928.244732618332 seconds after start. Precision at k for this model: 0.2670307457447052\n",
      "Validation set AUC score: 0.871988\n",
      "Hyperparameters for this model: {'no_components': 56, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 1, 'n': 5, 'learning_rate': 0.10012208247191079, 'item_alpha': 3.884048587512252e-09, 'user_alpha': 2.796001858369622e-09, 'max_sampled': 4, 'num_epochs': 33}\n",
      "Model 6 completed 24988.21982049942 seconds after start. Precision at k for this model: 0.10020226985216141\n",
      "Validation set AUC score: 0.91775703\n",
      "Hyperparameters for this model: {'no_components': 18, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'k': 26, 'n': 28, 'learning_rate': 0.05643767280648413, 'item_alpha': 1.526421982799207e-08, 'user_alpha': 6.5461193712107625e-09, 'max_sampled': 5, 'num_epochs': 63}\n",
      "Model 7 completed 25733.952889204025 seconds after start. Precision at k for this model: 0.2404126226902008\n",
      "Validation set AUC score: 0.9634081\n",
      "Hyperparameters for this model: {'no_components': 36, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 5, 'n': 12, 'learning_rate': 0.056517814506410274, 'item_alpha': 1.0162151313167516e-08, 'user_alpha': 4.351934165951258e-10, 'max_sampled': 8, 'num_epochs': 9}\n",
      "Model 8 completed 27428.888250112534 seconds after start. Precision at k for this model: 0.0568365715444088\n",
      "Validation set AUC score: 0.88012964\n",
      "Hyperparameters for this model: {'no_components': 83, 'learning_schedule': 'adagrad', 'loss': 'bpr', 'k': 13, 'n': 16, 'learning_rate': 0.05966690331016819, 'item_alpha': 6.431257557099882e-10, 'user_alpha': 1.41284043554206e-08, 'max_sampled': 12, 'num_epochs': 11}\n",
      "Model 9 completed 30805.81761622429 seconds after start. Precision at k for this model: 0.21994337439537048\n",
      "Validation set AUC score: 0.9254737\n",
      "Hyperparameters for this model: {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'warp-kos', 'k': 5, 'n': 11, 'learning_rate': 0.016889093570631196, 'item_alpha': 2.5637221481828903e-08, 'user_alpha': 8.098478772138341e-09, 'max_sampled': 12, 'num_epochs': 55}\n",
      "Model 10 completed 32602.524869918823 seconds after start. Precision at k for this model: 0.26456311345100403\n",
      "Validation set AUC score: 0.967414\n",
      "Hyperparameters for this model: {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 6, 'n': 10, 'learning_rate': 0.05484628899472384, 'item_alpha': 3.350108326463527e-09, 'user_alpha': 2.963937502021301e-09, 'max_sampled': 5, 'num_epochs': 51}\n",
      "Model 11 completed 34788.921419382095 seconds after start. Precision at k for this model: 0.2576861083507538\n",
      "Validation set AUC score: 0.96561897\n",
      "Hyperparameters for this model: {'no_components': 17, 'learning_schedule': 'adadelta', 'loss': 'warp', 'k': 17, 'n': 27, 'learning_rate': 0.007765735920884413, 'item_alpha': 1.5191340600452358e-08, 'user_alpha': 1.0643787789135775e-08, 'max_sampled': 11, 'num_epochs': 59}\n",
      "Model 12 completed 37612.65642237663 seconds after start. Precision at k for this model: 0.1815534085035324\n",
      "Validation set AUC score: 0.9635922\n",
      "Hyperparameters for this model: {'no_components': 47, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 4, 'n': 5, 'learning_rate': 0.02084205302935662, 'item_alpha': 9.350506222325395e-09, 'user_alpha': 6.28245603731461e-10, 'max_sampled': 5, 'num_epochs': 37}\n",
      "Model 13 completed 38177.55751347542 seconds after start. Precision at k for this model: 0.2513754069805145\n",
      "Validation set AUC score: 0.9661664\n",
      "Hyperparameters for this model: {'no_components': 38, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 4, 'n': 5, 'learning_rate': 0.07962498403600511, 'item_alpha': 1.2394005392601244e-09, 'user_alpha': 2.3934885366536403e-09, 'max_sampled': 2, 'num_epochs': 33}\n",
      "Model 14 completed 39200.71774625778 seconds after start. Precision at k for this model: 0.19025079905986786\n",
      "Validation set AUC score: 0.9595584\n",
      "Hyperparameters for this model: {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 6, 'n': 15, 'learning_rate': 0.19252850916992598, 'item_alpha': 3.5420234338010727e-09, 'user_alpha': 2.9454646362400496e-09, 'max_sampled': 8, 'num_epochs': 25}\n",
      "Model 15 completed 43192.99404883385 seconds after start. Precision at k for this model: 0.08620551228523254\n",
      "Validation set AUC score: 0.90770435\n",
      "Hyperparameters for this model: {'no_components': 35, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'k': 13, 'n': 25, 'learning_rate': 0.10336306769078563, 'item_alpha': 1.1090925165343934e-09, 'user_alpha': 1.5849999862420488e-08, 'max_sampled': 12, 'num_epochs': 26}\n",
      "Model 16 completed 45102.57892656326 seconds after start. Precision at k for this model: 0.1326456367969513\n",
      "Validation set AUC score: 0.9397589\n",
      "Hyperparameters for this model: {'no_components': 28, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 16, 'n': 17, 'learning_rate': 0.009333437782286123, 'item_alpha': 3.1898578854459894e-10, 'user_alpha': 7.88725157508071e-09, 'max_sampled': 3, 'num_epochs': 41}\n",
      "Model 17 completed 49270.27294921875 seconds after start. Precision at k for this model: 0.12030745297670364\n",
      "Validation set AUC score: 0.95778996\n",
      "Hyperparameters for this model: {'no_components': 75, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 18, 'n': 21, 'learning_rate': 0.01695496511755852, 'item_alpha': 3.6449353291238107e-09, 'user_alpha': 2.332473836837051e-08, 'max_sampled': 13, 'num_epochs': 16}\n",
      "Model 18 completed 50583.83950805664 seconds after start. Precision at k for this model: 0.22212783992290497\n",
      "Validation set AUC score: 0.94680303\n",
      "Hyperparameters for this model: {'no_components': 73, 'learning_schedule': 'adagrad', 'loss': 'warp-kos', 'k': 4, 'n': 7, 'learning_rate': 0.04010355095357089, 'item_alpha': 1.3133039710794459e-08, 'user_alpha': 2.5393900747279807e-09, 'max_sampled': 4, 'num_epochs': 26}\n",
      "Model 19 completed 53583.61300420761 seconds after start. Precision at k for this model: 0.05542071536183357\n",
      "Validation set AUC score: 0.8903453\n",
      "Hyperparameters for this model: {'no_components': 73, 'learning_schedule': 'adadelta', 'loss': 'bpr', 'k': 4, 'n': 29, 'learning_rate': 0.02049772260929092, 'item_alpha': 8.213557425715124e-09, 'user_alpha': 6.024555915453393e-08, 'max_sampled': 4, 'num_epochs': 9}\n",
      "Model 20 completed 55242.79891848564 seconds after start. Precision at k for this model: 0.17006471753120422\n",
      "Validation set AUC score: 0.93511117\n",
      "Hyperparameters for this model: {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 4, 'n': 7, 'learning_rate': 0.008692509878625694, 'item_alpha': 2.7808063870164004e-10, 'user_alpha': 1.79836126443404e-08, 'max_sampled': 14, 'num_epochs': 20}\n",
      "Best score 0.2670307457447052 at {'no_components': 56, 'learning_schedule': 'adadelta', 'loss': 'warp-kos', 'k': 1, 'n': 5, 'learning_rate': 0.10012208247191079, 'item_alpha': 3.884048587512252e-09, 'user_alpha': 2.796001858369622e-09, 'max_sampled': 4, 'num_epochs': 33}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter optimization\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "def sample_hyperparameters():\n",
    "    \"\"\"\n",
    "    Yield possible hyperparameter choices.\n",
    "    \"\"\"\n",
    "\n",
    "    while True:\n",
    "        n = np.random.randint(5,30)\n",
    "        k = np.random.randint(1,n)\n",
    "        yield {\n",
    "            \"no_components\": np.random.randint(16, 84),\n",
    "            \"learning_schedule\": np.random.choice([\"adagrad\", \"adadelta\"]),\n",
    "            \"loss\": np.random.choice([\"warp\", \"warp-kos\",\"bpr\"]),\n",
    "            \"k\": k,\n",
    "            \"n\": n,\n",
    "            \"learning_rate\": np.random.exponential(0.05),\n",
    "            \"item_alpha\": np.random.exponential(1e-8),\n",
    "            \"user_alpha\": np.random.exponential(1e-8),\n",
    "            \"max_sampled\": np.random.randint(2, 15),\n",
    "            \"num_epochs\": np.random.randint(5, 70),\n",
    "        }\n",
    "\n",
    "\n",
    "def random_search(train, trainLogistic, test, testLogistic, num_samples=20, num_threads=4):\n",
    "    \"\"\"\n",
    "    Sample random hyperparameters, fit a LightFM model, and evaluate it\n",
    "    on the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    train: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Training data.\n",
    "    test: np.float32 coo_matrix of shape [n_users, n_items]\n",
    "        Test data.\n",
    "    num_samples: int, optional\n",
    "        Number of hyperparameter choices to evaluate.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    generator of (auc_score, hyperparameter dict, fitted model)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    models = 1\n",
    "    \n",
    "    for hyperparams in itertools.islice(sample_hyperparameters(), num_samples):\n",
    "        num_epochs = hyperparams.pop(\"num_epochs\")\n",
    "\n",
    "        model = LightFM(**hyperparams)\n",
    "        \n",
    "        if hyperparams['loss'] == 'logistic':\n",
    "            model.fit(trainLogistic, epochs=num_epochs, num_threads=num_threads, user_features=None, item_features=tagFeatures)\n",
    "\n",
    "            score = precision_at_k(model, testLogistic, k=15, train_interactions=trainLogistic, user_features=None, item_features=tagFeatures,num_threads=num_threads).mean()\n",
    "            scoreAUC = auc_score(model, testLogistic, train_interactions=trainLogistic, user_features=None, item_features=tagFeatures,num_threads=4).mean()\n",
    "\n",
    "            print('Model {} completed {} seconds after start. Precision at k for this model: {}'.format(models, time.time() - start,np.average(score)))\n",
    "            print(\"Validation set AUC score:\",scoreAUC)\n",
    "            \n",
    "        else:\n",
    "            model.fit(train, epochs=num_epochs, num_threads=num_threads, user_features=None, item_features=tagFeatures)\n",
    "\n",
    "            score = precision_at_k(model, test, k=15, train_interactions=train, user_features=None, item_features=tagFeatures,num_threads=num_threads).mean()\n",
    "            scoreAUC = auc_score(model, test, train_interactions=train, user_features=None, item_features=tagFeatures,num_threads=4).mean()\n",
    "\n",
    "            print('Model {} completed {} seconds after start. Precision at k for this model: {}'.format(models, time.time() - start,np.average(score)))\n",
    "            print(\"Validation set AUC score:\",scoreAUC)\n",
    "    \n",
    "        hyperparams[\"num_epochs\"] = num_epochs\n",
    "\n",
    "        print('Hyperparameters for this model:',hyperparams)\n",
    "        \n",
    "        yield (score, hyperparams, model)\n",
    "        \n",
    "        models += 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = ownedGamesSparseMatrix_train\n",
    "    test = ownedGamesSparseMatrix_validation\n",
    "    \n",
    "    trainLogistic = None\n",
    "    testLogistic = None\n",
    "\n",
    "    (score, hyperparams, model) = max(random_search(train, trainLogistic, test, testLogistic, num_threads=4), key=lambda x: x[0])\n",
    "\n",
    "    print(\"Best score {} at {}\".format(score, hyperparams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1856f60",
   "metadata": {},
   "source": [
    "Seems like 'bpr' loss fits really slowly. As before, 'warp' is outperforming everything else. So far, the best parameters are:\n",
    "\n",
    "hyperparameters = {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 6, 'n': 10, 'learning_rate': 0.05484628899472384, 'item_alpha': 3.350108326463527e-09, 'user_alpha': 2.963937502021301e-09, 'max_sampled': 5},\n",
    "\n",
    "with 51 training epochs. These are the best hyperparameters set because it yields high AUC scores and precision at k = 20. For this model, those scores are\n",
    "\n",
    "Validation set precision at k = 20: 0.26456311345100403\n",
    "\n",
    "Validation set AUC score: 0.967414\n",
    "\n",
    "The validation set AUC score is excellent. The precision at k = 20 score is low in an absolute sense, but it is actually a little difficult to tell what this says about our model. It could be overfitting, but the AUC score on the validation set is very high and I have checked that the training set AUC score is not much higher (it is also ~0.97). The culprit could just be the sparsity of the validation set. I have chosen the validation set to be a random 10% subset of the overall data. This could result in many users having less than 20 items in their rows, or some of the items that the model recommends them could be in their owned app list but they got randomly sorted into the training set. That would ensure that the maximum achievable precision at k = 20 score on the validation set would be less than 1, with the maximum further from 1 the smaller the size of the subset chosen. One way to actually test this is to force the train-test sets to split in such a way that no user has less than 20 items. However, this could introduce a bias into the model, so I will avoid doing it for now, but perhaps try it later as a check that the model is indeed performing well.\n",
    "\n",
    "For now, the final check of the model is to score its predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "b3300ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n",
      "Train set AUC score: 0.9776567\n",
      "Test set AUC score: 0.97084844\n",
      "Train set precision at k: 0.697631\n",
      "Test set precision at k: 0.247307\n"
     ]
    }
   ],
   "source": [
    "#Check test set performance\n",
    "hyperparameters = {'no_components': 54, 'learning_schedule': 'adagrad', 'loss': 'warp', 'k': 6, 'n': 10, 'learning_rate': 0.05484628899472384, 'item_alpha': 3.350108326463527e-09, 'user_alpha': 2.963937502021301e-09, 'max_sampled': 5}\n",
    "model = LightFM(**hyperparameters)\n",
    "model = model.fit(ownedGamesSparseMatrix_train,\n",
    "                  user_features=None,\n",
    "                  item_features=tagFeatures,\n",
    "                  epochs=51,\n",
    "                  num_threads=4, verbose=True)\n",
    "\n",
    "print(\"Train set AUC score:\",auc_score(model, ownedGamesSparseMatrix_train, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "print(\"Test set AUC score:\",auc_score(model, ownedGamesSparseMatrix_test, train_interactions=ownedGamesSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "\n",
    "print(\"Train set precision at k:\",precision_at_k(model, ownedGamesSparseMatrix_train, k=20, train_interactions=None, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n",
    "print(\"Test set precision at k:\",precision_at_k(model, ownedGamesSparseMatrix_test, k=20, train_interactions=ownedGamesSparseMatrix_train, user_features=None, item_features=tagFeatures,num_threads=4).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a4f71b",
   "metadata": {},
   "source": [
    "The model seems to be doing quite well! The AUC scores are very high and do not indicate overfitting. The precision at k = 20 scores are lower, and lower still for the test set. But as I explained above, this could just be a reflection of the matrix sparsity rather than overfitting, and the high AUC scores support this explanation.\n",
    "\n",
    "Now, for fun, I'll make a script to generate recommendations for random users in the dataset. This will also serve as a check that the model is not getting a high AUC score by just recommending the same popular items to everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "5915a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n",
      "['Half-Life 2: Lost Coast', 'Tomb Raider', 'Portal', 'Half-Life 2', 'Counter-Strike: Source']\n",
      "811\n",
      "[\"Mirror's Edge\\x99\", 'Defence Alliance 2', 'AudioSurf', 'Hacknet', 'PAYDAY 2']\n",
      "928\n",
      "['Transpose', 'Fantasynth One', 'Creed: Rise to Glory\\x99', 'Chivalry: Medieval Warfare', 'POSTAL']\n",
      "745\n",
      "['Torchlight II', 'Minion Masters', 'Divinity: Original Sin 2 - Definitive Edition', 'Factorio', 'Rocket League®']\n",
      "2223\n",
      "['War Thunder', 'Defence Alliance 2', 'The Lab', '7 Days to Die', 'Alien Swarm']\n",
      "485\n",
      "['Orcs Must Die! 2', 'Borderlands Game of the Year Enhanced', 'Scanner Sombre', 'Darwinia', 'Borderlands Game of the Year']\n",
      "454\n",
      "['Counter-Strike: Source', 'ARK: Survival Evolved', 'Warhammer: Vermintide 2', 'Half-Life 2: Deathmatch', 'Counter-Strike: Global Offensive']\n",
      "2613\n",
      "['Gone Home', 'Syberia II', 'Layers of Fear', 'Amnesia: The Dark Descent', \"Mirror's Edge\\x99\"]\n",
      "743\n",
      "['STRIDER / ', 'QUAKE II Mission Pack: Ground Zero', 'BioShock\\x99 Remastered', 'DOOM II', 'Ultimate Doom']\n",
      "2710\n",
      "[\"Sid Meier's Civilization IV: Colonization\", 'Civilization IV®: Warlords', 'Civilization IV®: Warlords', \"Sid Meier's Civilization® IV\", 'Civilization IV: Beyond the Sword']\n"
     ]
    }
   ],
   "source": [
    "#Recommend some games (that the user does not already own) for some number of users\n",
    "import random\n",
    "\n",
    "user = 0\n",
    "numUsers = 10\n",
    "iteration = 0\n",
    "\n",
    "while user < numUsers:\n",
    "    \n",
    "    #Retrieve mapping between user/item IDs and LightFM internal indices\n",
    "    userIDMap = dataset.mapping()[0]\n",
    "    itemIDMap = dataset.mapping()[2]\n",
    "\n",
    "    #Pick a random user and get list of games he owns\n",
    "    userX = random.choice(list(dataset.mapping()[0].values()))\n",
    "    userX_ID = list(userIDMap.keys())[list(userIDMap.values()).index(userX)]\n",
    "    userXGames = ownedGames[ownedGames['userID'] == userX_ID]['ownedAppIDs'].values[0]\n",
    "    \n",
    "    authorID = list(userIDMap.keys())[userX]\n",
    "    \n",
    "    print(userX)\n",
    "    \n",
    "    scores = np.array(model.predict(userX,list(itemIDMap.values()), item_features=tagFeatures, user_features=None))\n",
    "\n",
    "    top5GamesBool = pd.Series(scores).sort_values(ascending=False).index\n",
    "    \n",
    "    top5List = []\n",
    "    successCount = 0\n",
    "    \n",
    "    for top5Game in top5GamesBool:\n",
    "\n",
    "        try:\n",
    "            gameID = list(itemIDMap.keys())[list(itemIDMap.values()).index(top5Game)]\n",
    "            game = rawGames[rawGames['appId'] == int(gameID)]['name'].values[0]\n",
    "            \n",
    "            if gameID not in userXGames:\n",
    "                top5List.append(game)\n",
    "                successCount += 1\n",
    "        except IndexError:\n",
    "            #print('App {} does not exist in Steam Store anymore.'.format(int(list(itemIDMap.keys())[list(itemIDMap.values()).index(top5Game)])))\n",
    "            pass\n",
    "            \n",
    "        if successCount == 5:\n",
    "            break\n",
    "    print(top5List)\n",
    "\n",
    "    user += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210efc57",
   "metadata": {},
   "source": [
    "The recommendations look pretty good. Users, for the most part, are recommended different items. Now I'll try the model on myself, and see if it recommends me items that I will like! This will serve as a good check of the model's \"face validity.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "b48901c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me\n",
      "['Path of Exile', 'Lost Ark', 'Torchlight II', 'Borderlands 2', 'Terraria', 'Team Fortress Classic', \"Don't Starve Together\", 'Monster Hunter: World', 'Destiny 2', 'Dota 2', 'Half-Life', 'Deathmatch Classic', 'Warframe', 'Half-Life 2: Deathmatch', 'Titan Quest Anniversary Edition', 'Dying Light', 'Conan Exiles', 'Counter-Strike', 'Borderlands Game of the Year', 'Grim Dawn', 'Project Zomboid', 'New World', 'Half-Life Deathmatch: Source', 'Warhammer: End Times - Vermintide', 'Dungeon Defenders', 'Counter-Strike: Source', 'Magicka', 'PlanetSide 2 - Test', 'Darkest Dungeon®', 'Borderlands Game of the Year Enhanced', \"No Man's Sky\", 'Half-Life 2: Lost Coast', 'Left 4 Dead', 'The Elder Scrolls® Online', 'Counter-Strike: Global Offensive', 'Ricochet', 'Half-Life 2', 'RIFT', 'Torchlight', 'Half-Life: Opposing Force', 'Alien Swarm', 'V Rising', 'PAYDAY 2', 'PUBG: BATTLEGROUNDS', 'Half-Life: Blue Shift', 'Saints Row: The Third', 'Middle-earth\\x99: Shadow of Mordor\\x99', 'Borderlands: The Pre-Sequel', 'Portal 2', 'DOOM'] \n",
      "\n",
      "Jayson\n",
      "['Dota 2', 'Team Fortress 2', 'PUBG: BATTLEGROUNDS', 'Fall Guys: Ultimate Knockout', 'Team Fortress Classic', 'Counter-Strike: Source', 'Counter-Strike', 'Rocket League®', 'Risk of Rain 2', 'Paladins®', 'Half-Life 2: Deathmatch', 'PlanetSide 2 - Test', 'Warframe', 'Realm Royale', \"Don't Starve Together\", 'Borderlands 2', 'Left 4 Dead', 'Alien Swarm', 'Magicka', 'Dirty Bomb®', 'Deathmatch Classic', 'Dota Underlords', 'Minion Masters', 'Dungeon Defenders', 'PlanetSide 2', 'Chivalry: Medieval Warfare', 'Half-Life', 'DARK SOULS\\x99 III', 'Golf With Your Friends', 'MORDHAU', 'Totally Accurate Battlegrounds', 'Hunt: Showdown', \"Garry's Mod\", 'Day of Defeat: Source', 'Conan Exiles', 'Battlerite', 'Dying Light', 'Torchlight II', 'Z1 Battle Royale', 'Guns of Icarus Online', 'MultiVersus', 'Half-Life 2', 'Insurgency', 'Drawful 2', 'Ring of Elysium', 'Ricochet', 'RIFT', 'Half-Life Deathmatch: Source', 'Absolver', 'V Rising'] \n",
      "\n",
      "Mary\n",
      "['Team Fortress 2', 'Dota 2', 'Fall Guys: Ultimate Knockout', 'Borderlands 2', 'Team Fortress Classic', 'Terraria', 'RIFT', 'Drawful 2', 'Minion Masters', 'New World', 'Magicka', 'Dungeon Defenders', 'Black Desert', \"Don't Starve Together\", 'The Jackbox Party Pack 3', 'Among Us', 'SMITE®', 'Paladins®', 'Realm Royale', 'Torchlight II', 'Monster Hunter: World', 'Conan Exiles', 'The Elder Scrolls® Online', 'PUBG: BATTLEGROUNDS', 'PAYDAY 2', 'Half-Life 2: Deathmatch', 'Castle Crashers®', 'The Jackbox Party Pack 2', 'Quiplash', 'Guild Wars 2', 'The Elder Scrolls V: Skyrim', 'Titan Quest Anniversary Edition', 'FINAL FANTASY XIV Online', 'Borderlands: The Pre-Sequel', 'Dota Underlords', 'Clicker Heroes', 'Trine 2: Complete Story', 'The Jackbox Party Pack 4', 'Half-Life', 'Warframe', 'Alien Swarm', 'Counter-Strike', 'MultiVersus', 'Left 4 Dead', 'The Jackbox Party Pack', 'Saints Row: The Third', 'Raft', 'Starbound', 'Magic Duels', 'Golf With Your Friends'] \n",
      "\n",
      "Micah\n",
      "['Team Fortress Classic', 'Counter-Strike', 'Deathmatch Classic', 'Dota 2', 'Half-Life 2: Deathmatch', 'Borderlands 2', 'Half-Life', 'Lost Ark', 'Counter-Strike: Source', 'PUBG: BATTLEGROUNDS', 'Half-Life Deathmatch: Source', 'Ricochet', 'Magicka', 'Half-Life: Opposing Force', 'Half-Life: Blue Shift', 'Half-Life 2', 'Dungeon Defenders', 'Among Us', \"Don't Starve Together\", 'Destiny 2', 'Torchlight II', 'Alien Swarm', 'Terraria', 'Borderlands Game of the Year Enhanced', 'Half-Life 2: Lost Coast', 'Minion Masters', 'Counter-Strike: Condition Zero', 'Borderlands Game of the Year', 'Counter-Strike: Condition Zero', 'DOOM', 'Paladins®', 'Fall Guys: Ultimate Knockout', 'Realm Royale', 'Black Desert', 'Chivalry: Medieval Warfare', 'Half-Life 2: Episode Two', 'Saints Row: The Third', 'Dying Light', 'Titan Quest Anniversary Edition', 'RIFT', 'SMITE®', 'PlanetSide 2 - Test', 'Warframe', 'Warhammer: End Times - Vermintide', 'Borderlands: The Pre-Sequel', 'Rocket League®', 'Dead by Daylight', 'Viscera Cleanup Detail: Shadow Warrior', 'Serious Sam Fusion 2017 (beta)', 'Half-Life 2: Episode One'] \n",
      "\n",
      "Games that are recommended to all of us: ['Torchlight II', 'Borderlands 2', 'Team Fortress Classic', \"Don't Starve Together\", 'Dota 2', 'Half-Life', 'Warframe', 'Half-Life 2: Deathmatch', 'Counter-Strike', 'Dungeon Defenders', 'Magicka', 'RIFT', 'Alien Swarm', 'PUBG: BATTLEGROUNDS']\n"
     ]
    }
   ],
   "source": [
    "#Recommend some new games for myself\n",
    "\n",
    "#Retrieve mapping between user/item IDs and LightFM internal indices\n",
    "userIDMap = dataset.mapping()[0]\n",
    "itemIDMap = dataset.mapping()[2]\n",
    "\n",
    "intersectionList = []\n",
    "\n",
    "#Add my Steam information\n",
    "for userX, name in zip([2782,2783,2784,2785],['Me','Jayson','Mary','Micah']):\n",
    "    userX_ID = list(userIDMap.keys())[list(userIDMap.values()).index(userX)]\n",
    "    userXGames = ownedGames[ownedGames['userID'] == userX_ID]['ownedAppIDs'].values[0]\n",
    "\n",
    "    authorID = list(userIDMap.keys())[userX]\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    scores = np.array(model.predict(userX,list(itemIDMap.values()), item_features=tagFeatures, user_features=None))\n",
    "\n",
    "    top5GamesBool = pd.Series(scores).sort_values(ascending=False).index\n",
    "\n",
    "    top5List = []\n",
    "    successCount = 0\n",
    "\n",
    "\n",
    "    for top5Game in top5GamesBool:\n",
    "\n",
    "        try:\n",
    "            gameID = list(itemIDMap.keys())[list(itemIDMap.values()).index(top5Game)]\n",
    "            game = rawGames[rawGames['appId'] == int(gameID)]['name'].values[0]\n",
    "\n",
    "\n",
    "            if gameID not in userXGames:\n",
    "                top5List.append(game)\n",
    "                successCount += 1\n",
    "\n",
    "        except IndexError:\n",
    "            #print('App {} does not exist in Steam Store anymore.'.format(int(list(itemIDMap.keys())[list(itemIDMap.values()).index(top5Game)])))\n",
    "            pass\n",
    "\n",
    "        if successCount == 50:\n",
    "            break\n",
    "\n",
    "    print(top5List,'\\n')\n",
    "    \n",
    "    #Add to list of games recommended to all of us\n",
    "    if intersectionList == []:\n",
    "        intersectionList.append(top5List)\n",
    "        intersectionList = intersectionList[0]\n",
    "        \n",
    "    else:\n",
    "        intersectionList = intersection(intersectionList,top5List)\n",
    "        \n",
    "print('Games that are recommended to all of us:',intersectionList)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06e8d1",
   "metadata": {},
   "source": [
    "For most of the entries in my recommendation list, they are games I either already want or would be interested to try. Only a few are things that seem unappealing to me. I should also note that I believe the model is recommending a bunch of Half-Life titles to me because I own Team Fortress 2 and not Half-Life, although most people in the dataset own both (probably because Steam sells a bunch of Valve bundles that package them together).\n",
    "\n",
    "I also made predictions for my friends and family. The model recommended them games that were either already on their wishlist or things they were unaware of but were eager to try. They have since added many of the games listed here to their wishlists! Only a few of the recommended games seemed uninteresting to them.\n",
    "\n",
    "This simple check looks good. I think the model is performing well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "bf43d4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2782"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset.mapping()[0].values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603fba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
